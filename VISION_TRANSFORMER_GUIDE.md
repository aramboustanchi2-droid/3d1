# Vision Transformer System for CAD Conversion

# Ø³ÛŒØ³ØªÙ… Vision Transformer Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ CAD

Ø§ÛŒÙ† Ø³ÛŒØ³ØªÙ… Ø§Ø² **Vision Transformer** Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¹Ù…ÛŒÙ‚ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚ Ù†Ù‚Ø´Ù‡â€ŒÙ‡Ø§ÛŒ CAD Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

## ğŸ¯ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§

### 1. ØªØ­Ù„ÛŒÙ„ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¹Ù…ÛŒÙ‚

- Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø¯Ù‚ÛŒÙ‚ Ø§Ø¬Ø²Ø§Ø¡ Ø³Ø§Ø®ØªÙ…Ø§Ù†ÛŒ (Ø¯ÛŒÙˆØ§Ø±ØŒ Ø¯Ø±ØŒ Ù¾Ù†Ø¬Ø±Ù‡ØŒ Ø³ØªÙˆÙ†ØŒ ØªÛŒØ±ØŒ Ø³Ù‚ÙØŒ Ù¾Ù„Ù‡)
- Ø¯Ø±Ú© Ø±ÙˆØ§Ø¨Ø· Ø¨ÛŒÙ† Ø§Ø¬Ø²Ø§Ø¡
- ØªØ´Ø®ÛŒØµ Ø§Ù„Ù…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø¯Ø± Ù†Ù‚Ø´Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù†Ø¯Ø³ÛŒ

### 2. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø±ØªÙØ§Ø¹ Ùˆ Ø¹Ù…Ù‚

- ØªØ®Ù…ÛŒÙ† Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø±ØªÙØ§Ø¹ Ù‡Ø± Ø§Ù„Ù…Ø§Ù†
- Ù†Ù‚Ø´Ù‡ Ø¹Ù…Ù‚ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ø³Ù‡â€ŒØ¨Ø¹Ø¯ÛŒ
- ØªØ´Ø®ÛŒØµ Ù…ÙˆØ§Ø¯ Ùˆ Ø¶Ø®Ø§Ù…Øªâ€ŒÙ‡Ø§

### 3. Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ø³Ù‡â€ŒØ¨Ø¹Ø¯ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡

- ØªØ¨Ø¯ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚ 2D Ø¨Ù‡ 3D
- Ø­ÙØ¸ Ù…Ø¹Ù†Ø§ÛŒ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ùˆ Ù…Ù‡Ù†Ø¯Ø³ÛŒ
- Ù„Ø§ÛŒÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø§Ù†
- Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯

### 4. ØªØ´Ø®ÛŒØµ Ù…Ù‚ÛŒØ§Ø³ Ø®ÙˆØ¯Ú©Ø§Ø±

- ÛŒØ§ÙØªÙ† Ø§Ø¨Ø¹Ø§Ø¯ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ (Ø¯Ø±Ù‡Ø§ 2100mm)
- Ø®ÙˆØ§Ù†Ø¯Ù† scale bar
- OCR Ø¨Ø±Ø§ÛŒ Ù…ØªÙ† Ø§Ø¨Ø¹Ø§Ø¯

## ğŸ“¦ Ù†ØµØ¨

### Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²Ù‡Ø§

```bash
# Ù†ØµØ¨ PyTorch (CPU version)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu

# Ø¨Ø±Ø§ÛŒ GPU (Ø§Ø®ØªÛŒØ§Ø±ÛŒ - Ø³Ø±Ø¹Øª Ø¨Ø§Ù„Ø§ØªØ±)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø±
pip install opencv-python matplotlib scipy
pip install ezdxf
```

## ğŸš€ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø³Ø±ÛŒØ¹

### 1. ØªØ¨Ø¯ÛŒÙ„ Ø³Ø§Ø¯Ù‡ ØªØµÙˆÛŒØ± Ø¨Ù‡ 3D DXF

```python
from cad3d.vit_integration import get_vit_service

# Ø³Ø±ÙˆÛŒØ³ Ø±Ø§ ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯
service = get_vit_service(device="cpu")  # ÛŒØ§ "cuda" Ø¨Ø±Ø§ÛŒ GPU

if service:
    # ØªØ¨Ø¯ÛŒÙ„ ØªØµÙˆÛŒØ± Ø¨Ù‡ 3D DXF
    stats = service.convert_image_to_3d_dxf(
        image_path="floor_plan.jpg",
        output_dxf="floor_plan_3d.dxf",
        auto_scale=True,
        min_confidence=0.5
    )
    
    print(f"âœ“ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯ {stats['total_entities']} entity")
    print(f"âœ“ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§: {stats['total_layers']}")
    print(f"âœ“ Ø§Ø¬Ø²Ø§Ø¡ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡: {stats['elements_by_class']}")
```

### 2. ØªØ­Ù„ÛŒÙ„ Ø¹Ù…ÛŒÙ‚ ØªØµÙˆÛŒØ±

```python
from cad3d.vit_integration import get_vit_service

service = get_vit_service()

# ØªØ­Ù„ÛŒÙ„ Ø¨Ø¯ÙˆÙ† ØªØ¨Ø¯ÛŒÙ„
analysis = service.analyze_image("drawing.png")

print(f"ØªØ¹Ø¯Ø§Ø¯ Ø§Ø¬Ø²Ø§Ø¡: {analysis['num_elements']}")
print(f"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {analysis['confidence_stats']['mean']:.2f}")

for elem in analysis['elements'][:10]:  # Ø§ÙˆÙ„ÛŒÙ† 10 Ø§Ù„Ù…Ø§Ù†
    print(f"  {elem['class']}: {elem['confidence']:.2%}")
```

### 3. ØªØµÙˆÛŒØ±Ø³Ø§Ø²ÛŒ Ù†ØªØ§ÛŒØ¬

```python
service = get_vit_service()

# Ø§ÛŒØ¬Ø§Ø¯ ØªØµÙˆÛŒØ± ØªØ­Ù„ÛŒÙ„ Ø´Ø§Ù…Ù„:
# - Ù†Ù‚Ø´Ù‡ Ù…Ø¹Ù†Ø§ÛŒÛŒ (semantic segmentation)
# - Ù†Ù‚Ø´Ù‡ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† (confidence map)
# - Ù†Ù‚Ø´Ù‡ Ø§Ø±ØªÙØ§Ø¹ (height map)
# - Ù†Ù‚Ø´Ù‡ Ø¹Ù…Ù‚ (depth map)
# - Ù†Ù‚Ø´Ù‡ attention
service.create_visualization(
    image_path="floor_plan.jpg",
    output_path="analysis_visualization.png"
)
```

## ğŸ”§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù¾ÛŒØ´Ø±ÙØªÙ‡

### Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø±ÙˆÛŒ Ø¯ÛŒØªØ§Ø³Øª Ø®ÙˆØ¯

```python
from cad3d.vit_trainer import VisionTransformerTrainer, TrainingConfig, CADDataset
from cad3d.vision_transformer_cad import VisionTransformerConfig

# Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù…Ø¯Ù„
model_config = VisionTransformerConfig(
    image_size=512,
    patch_size=16,
    num_classes=50,  # ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø´Ù…Ø§
    dim=768,
    depth=12,
    heads=12
)

# Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø¢Ù…ÙˆØ²Ø´
train_config = TrainingConfig(
    train_data_dir="data/train",
    val_data_dir="data/val",
    batch_size=4,
    num_epochs=50,
    learning_rate=1e-4,
    device="cuda"  # ÛŒØ§ "cpu"
)

# Ø§ÛŒØ¬Ø§Ø¯ Ø¯ÛŒØªØ§Ø³Øª
train_dataset = CADDataset("data/train", augment=True)
val_dataset = CADDataset("data/val", augment=False)

# Ø¢Ù…ÙˆØ²Ø´
trainer = VisionTransformerTrainer(model_config, train_config)
trainer.train(train_dataset, val_dataset)

# Ù…Ø¯Ù„ Ø¯Ø± checkpoints/best_model.pth Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
```

### Ø³Ø§Ø®ØªØ§Ø± Ø¯ÛŒØªØ§Ø³Øª

```
data/
  train/
    images/
      drawing_001.png
      drawing_002.png
      ...
    annotations/
      drawing_001.json
      drawing_002.json
      ...
  val/
    images/
    annotations/
```

### ÙØ±Ù…Øª Annotation (JSON)

```json
{
  "semantic_map": [
    [0, 1, 1, 2, 2, ...],
    [0, 1, 1, 2, 2, ...],
    ...
  ],
  "height_map": [
    [0, 3000, 3000, 2100, 2100, ...],
    [0, 3000, 3000, 2100, 2100, ...],
    ...
  ],
  "depth_map": [
    [0, 0.5, 0.5, 0.3, 0.3, ...],
    [0, 0.5, 0.5, 0.3, 0.3, ...],
    ...
  ],
  "material_map": [
    [0, 1, 1, 2, 2, ...],
    [0, 1, 1, 2, 2, ...],
    ...
  ],
  "metadata": {
    "scale": 10.0,
    "drawing_type": "architectural",
    "units": "mm"
  }
}
```

### Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶

```python
# 50 Ú©Ù„Ø§Ø³ Ø´Ø§Ù…Ù„:
classes = [
    "background",      # 0
    "wall",            # 1
    "door",            # 2
    "window",          # 3
    "column",          # 4
    "beam",            # 5
    "slab",            # 6
    "stair",           # 7
    "railing",         # 8
    "furniture",       # 9
    # Ùˆ 40 Ú©Ù„Ø§Ø³ Ø¯ÛŒÚ¯Ø± Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø²Ø§Ø¡ Ø³Ø§Ø®ØªÙ…Ø§Ù†ÛŒØŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ØŒ Ùˆ annotations
]
```

## ğŸ“ Ø§Ø¯ØºØ§Ù… Ø¨Ø§ Ø³Ø±ÙˆØ±

```python
from cad3d.vit_integration import get_vit_service, is_vit_available

# Ø¯Ø± Ø³Ø±ÙˆØ± FastAPI
if is_vit_available():
    vit_service = get_vit_service(device="cpu")
    print("âœ“ Vision Transformer ÙØ¹Ø§Ù„ Ø§Ø³Øª")
else:
    vit_service = None
    print("âš ï¸ Vision Transformer ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª")

# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± endpoint
@app.post("/convert_advanced")
async def convert_advanced(file: UploadFile):
    if vit_service:
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Vision Transformer
        stats = vit_service.convert_image_to_3d_dxf(
            image_path=temp_file,
            output_dxf=output_file,
            auto_scale=True
        )
        return {"status": "success", "stats": stats}
    else:
        # Fallback Ø¨Ù‡ Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡
        return {"status": "vit_not_available"}
```

## âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø¯Ù„

### Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ø¯Ù„

```python
VisionTransformerConfig(
    image_size=512,    # Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙˆØ±ÙˆØ¯ÛŒ (512x512)
    patch_size=16,     # Ø§Ù†Ø¯Ø§Ø²Ù‡ patch (16x16) = 32x32 patches
    dim=768,           # Ø¨Ø¹Ø¯ embedding
    depth=12,          # ØªØ¹Ø¯Ø§Ø¯ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ transformer
    heads=12,          # ØªØ¹Ø¯Ø§Ø¯ attention heads
)

# ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§: ~86M (million)
```

### Ù…Ø¯Ù„ Ø³Ø¨Ú©â€ŒØªØ± (Ø¨Ø±Ø§ÛŒ CPU)

```python
VisionTransformerConfig(
    image_size=256,
    patch_size=16,
    dim=384,
    depth=6,
    heads=6
)

# ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§: ~22M
```

### Ù…Ø¯Ù„ Ø³Ù†Ú¯ÛŒÙ†â€ŒØªØ± (Ø¨Ø±Ø§ÛŒ GPU)

```python
VisionTransformerConfig(
    image_size=768,
    patch_size=16,
    dim=1024,
    depth=24,
    heads=16
)

# ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§: ~300M
```

## ğŸ“Š Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯

```python
from cad3d.vit_trainer import VisionTransformerTrainer

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ checkpoint
trainer.load_checkpoint("checkpoints/best_model.pth")

# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø±ÙˆÛŒ validation set
val_losses = trainer.validate(val_loader)

print(f"Validation Loss: {val_losses['total']:.4f}")
print(f"  Semantic Loss: {val_losses['semantic']:.4f}")
print(f"  Height Loss: {val_losses['height']:.4f}")
print(f"  Depth Loss: {val_losses['depth']:.4f}")
```

## ğŸ¨ Ù…Ø«Ø§Ù„ Ú©Ø§Ù…Ù„: Pipeline Ù¾ÛŒØ´Ø±ÙØªÙ‡

```python
import cv2
from cad3d.vit_integration import get_vit_service

# 1. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ±
image = cv2.imread("complex_floor_plan.jpg")

# 2. Ø³Ø±ÙˆÛŒØ³ Vision Transformer
service = get_vit_service(
    model_path="checkpoints/best_model.pth",  # Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡
    device="cuda"  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² GPU
)

# 3. ØªØ­Ù„ÛŒÙ„
print("ğŸ” Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ù†Ù‚Ø´Ù‡...")
analysis = service.analyze_image("complex_floor_plan.jpg")

print(f"âœ“ {analysis['num_elements']} Ø§Ù„Ù…Ø§Ù† Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯")
print(f"âœ“ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {analysis['confidence_stats']['mean']:.2%}")

# 4. Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ 3D
print("ğŸ—ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ù…Ø¯Ù„ Ø³Ù‡â€ŒØ¨Ø¹Ø¯ÛŒ...")
stats = service.convert_image_to_3d_dxf(
    image_path="complex_floor_plan.jpg",
    output_dxf="complex_floor_plan_3d.dxf",
    auto_scale=True,
    min_confidence=0.6
)

print(f"âœ“ {stats['total_entities']} entity Ø³Ù‡â€ŒØ¨Ø¹Ø¯ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯")
print(f"âœ“ {stats['total_layers']} Ù„Ø§ÛŒÙ‡ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
print("âœ“ Ø§Ø¬Ø²Ø§Ø¡ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡:")
for class_name, count in stats['elements_by_class'].items():
    print(f"    {class_name}: {count}")

# 5. ØªØµÙˆÛŒØ±Ø³Ø§Ø²ÛŒ Ù†ØªØ§ÛŒØ¬
print("ğŸ“Š Ø§ÛŒØ¬Ø§Ø¯ ØªØµÙˆÛŒØ±Ø³Ø§Ø²ÛŒ...")
service.create_visualization(
    image_path="complex_floor_plan.jpg",
    output_path="analysis_result.png"
)

print("âœ… ØªÙ…Ø§Ù…!")
```

## ğŸ”¬ Ù…Ø¹Ù…Ø§Ø±ÛŒ Vision Transformer

```
Input Image (512x512x3)
  â†“
Patch Embedding (32x32 patches Ã— 768 dim)
  â†“
Add Positional Encoding
  â†“
[CLS] Token + Patch Tokens
  â†“
Transformer Encoder (12 layers)
  â”œâ”€ Multi-Head Self-Attention (12 heads)
  â”œâ”€ Layer Normalization
  â”œâ”€ Feed-Forward Network
  â””â”€ Residual Connections
  â†“
Output Embeddings (1024 tokens Ã— 768 dim)
  â†“
Prediction Heads:
  â”œâ”€ Semantic Segmentation (50 classes)
  â”œâ”€ Height Prediction (mm)
  â”œâ”€ Depth Prediction (normalized)
  â””â”€ Material Classification (10 types)
```

## ğŸ“ˆ Ù…Ø²Ø§ÛŒØ§ÛŒ Vision Transformer

âœ… **Ø¯Ø±Ú© Ø¬Ø§Ù…Ø¹**: ØªØ­Ù„ÛŒÙ„ ØªÙ…Ø§Ù… Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ù†Ù‚Ø´Ù‡ Ø¨Ù‡â€ŒØ·ÙˆØ± Ù‡Ù…Ø²Ù…Ø§Ù†
âœ… **Ø±ÙˆØ§Ø¨Ø· ÙØ¶Ø§ÛŒÛŒ**: attention mechanism Ø±ÙˆØ§Ø¨Ø· Ø¨ÛŒÙ† Ø§Ø¬Ø²Ø§Ø¡ Ø±Ø§ Ù…ÛŒâ€ŒÙÙ‡Ù…Ø¯
âœ… **Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§**: Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§Ù„Ù…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ùˆ Ú©ÙˆÚ†Ú©
âœ… **Ø§Ù†Ø¹Ø·Ø§Ùâ€ŒÙ¾Ø°ÛŒØ±ÛŒ**: Ù‚Ø§Ø¨Ù„ÛŒØª Ø¢Ù…ÙˆØ²Ø´ Ø±ÙˆÛŒ Ø§Ù†ÙˆØ§Ø¹ Ù†Ù‚Ø´Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù†Ø¯Ø³ÛŒ
âœ… **Ù…Ù‚ÛŒØ§Ø³â€ŒÙ¾Ø°ÛŒØ±ÛŒ**: Ø§Ø² Ù…Ø¯Ù„ Ø³Ø¨Ú© ØªØ§ Ù…Ø¯Ù„ Ø¨Ø³ÛŒØ§Ø± Ø¨Ø²Ø±Ú¯

## âš¡ Ù†Ú©Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ

### 1. Ø³Ø±Ø¹Øª (CPU)

```python
# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ú©ÙˆÚ†Ú©â€ŒØªØ±
service = get_vit_service(device="cpu")
# Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ batch
# Ú©Ø´ Ú©Ø±Ø¯Ù† Ù†ØªØ§ÛŒØ¬
```

### 2. Ø¯Ù‚Øª (GPU)

```python
# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø¨Ø²Ø±Ú¯â€ŒØªØ±
service = get_vit_service(device="cuda")
# Ø¢Ù…ÙˆØ²Ø´ Ø±ÙˆÛŒ Ø¯ÛŒØªØ§Ø³Øª Ø³ÙØ§Ø±Ø´ÛŒ
# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ensemble
```

### 3. Ø­Ø§ÙØ¸Ù‡

```python
# Ú©Ø§Ù‡Ø´ batch size
# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² gradient checkpointing
# Mixed precision training
```

## ğŸ› Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ

### PyTorch Ù†ØµØ¨ Ù†ÛŒØ³Øª

```bash
pip install torch torchvision
```

### Out of Memory (GPU)

```python
# Ú©Ø§Ù‡Ø´ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ø¯Ù„
config.dim = 384
config.depth = 6
# ÛŒØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² CPU
service = get_vit_service(device="cpu")
```

### Ø¯Ù‚Øª Ù¾Ø§ÛŒÛŒÙ†

```python
# Ø§ÙØ²Ø§ÛŒØ´ confidence threshold
min_confidence=0.7
# Ø¢Ù…ÙˆØ²Ø´ Ø±ÙˆÛŒ Ø¯ÛŒØªØ§Ø³Øª Ø¨ÛŒØ´ØªØ±
# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø¨Ø²Ø±Ú¯â€ŒØªØ±
```

## ğŸ“š Ù…Ù†Ø§Ø¨Ø¹

- [Vision Transformer Paper](https://arxiv.org/abs/2010.11929)
- [DETR (Detection Transformer)](https://arxiv.org/abs/2005.12872)
- [Segment Anything Model (SAM)](https://arxiv.org/abs/2304.02643)

## ğŸ“ License

MIT License - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¢Ø²Ø§Ø¯ Ø¨Ø±Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ¬Ø§Ø±ÛŒ Ùˆ ØºÛŒØ±ØªØ¬Ø§Ø±ÛŒ

---

**Ù†Ø³Ø®Ù‡**: 1.0.0
**ØªØ§Ø±ÛŒØ®**: 2025-01-16
**ØªÙˆØ³Ø¹Ù‡â€ŒØ¯Ù‡Ù†Ø¯Ù‡**: CAD3D Team
