"""
Agent Security & Compliance System
Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ Ùˆ Ø§Ù†Ø·Ø¨Ø§Ù‚ Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§

Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø±Ø¹Ø§ÛŒØª Ù‚ÙˆØ§Ù†ÛŒÙ† Ùˆ Ø¶ÙˆØ§Ø¨Ø· ØªÙˆØ³Ø· Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ
"""

import logging
from typing import Dict, List, Optional, Set
from datetime import datetime
from enum import Enum
import json
from pathlib import Path

logger = logging.getLogger(__name__)

class ComplianceLevel(Enum):
    """Ø³Ø·Ø­ Ø§Ù†Ø·Ø¨Ø§Ù‚"""
    COMPLIANT = "compliant"           # Ù…Ø·Ø§Ø¨Ù‚
    WARNING = "warning"               # Ù‡Ø´Ø¯Ø§Ø±
    VIOLATION = "violation"           # ØªØ®Ù„Ù
    BLOCKED = "blocked"               # Ù…Ø³Ø¯ÙˆØ¯ Ø´Ø¯Ù‡

class ContentCategory(Enum):
    """Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø­ØªÙˆØ§"""
    EDUCATIONAL = "educational"       # Ø¢Ù…ÙˆØ²Ø´ÛŒ
    RESEARCH = "research"             # ØªØ­Ù‚ÛŒÙ‚Ø§ØªÛŒ
    TECHNICAL = "technical"           # ÙÙ†ÛŒ
    ADMINISTRATIVE = "administrative" # Ø§Ø¯Ø§Ø±ÛŒ
    PROHIBITED = "prohibited"         # Ù…Ù…Ù†ÙˆØ¹Ù‡

class AgentSecuritySystem:
    """
    Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ Ùˆ Ù†Ø¸Ø§Ø±ØªÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ
    
    Ù…Ø³Ø¦ÙˆÙ„ÛŒØªâ€ŒÙ‡Ø§:
    - Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­ØªÙˆØ§ Ù‚Ø¨Ù„ Ø§Ø² Ø°Ø®ÛŒØ±Ù‡
    - Ù†Ø¸Ø§Ø±Øª Ø¨Ø± Ø±ÙØªØ§Ø± Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§
    - Ø§Ø¹Ù…Ø§Ù„ Ù‚ÙˆØ§Ù†ÛŒÙ† Ùˆ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§
    - Ú¯Ø²Ø§Ø±Ø´â€ŒØ¯Ù‡ÛŒ Ùˆ Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ
    """
    
    def __init__(self, config_path: Optional[Path] = None):
        self.config = self._load_config(config_path)
        
        # Ù‚ÙˆØ§Ù†ÛŒÙ† Ùˆ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§
        self.rules = {
            'allowed_domains': self._get_allowed_domains(),
            'prohibited_keywords': self._get_prohibited_keywords(),
            'allowed_categories': [
                ContentCategory.EDUCATIONAL,
                ContentCategory.RESEARCH,
                ContentCategory.TECHNICAL,
                ContentCategory.ADMINISTRATIVE
            ],
            'max_content_length': 1000000,  # Ø­Ø¯Ø§Ú©Ø«Ø± Ø·ÙˆÙ„ Ù…Ø­ØªÙˆØ§ (Ú©Ø§Ø±Ø§Ú©ØªØ±)
            'required_fields': ['university', 'resource', 'url', 'content']
        }
        
        # Ø¢Ù…Ø§Ø± Ù†Ø¸Ø§Ø±ØªÛŒ
        self.monitoring_stats = {
            'total_checks': 0,
            'compliant': 0,
            'warnings': 0,
            'violations': 0,
            'blocked': 0
        }
        
        # Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ
        self.security_logs = []
        self.logs_dir = Path('university_cache/security_logs')
        self.logs_dir.mkdir(exist_ok=True, parents=True)
    
    def _load_config(self, config_path: Optional[Path]) -> Dict:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª"""
        if config_path and config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶
        return {
            'strict_mode': True,
            'auto_block_violations': True,
            'log_all_checks': False,
            'notify_on_violation': True
        }
    
    def _get_allowed_domains(self) -> Set[str]:
        """Ø¯Ø§Ù…Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¬Ø§Ø² Ø¨Ø±Ø§ÛŒ scraping"""
        return {
            # MIT
            'ocw.mit.edu', 'dspace.mit.edu', 'csail.mit.edu',
            # Stanford
            'online.stanford.edu', 'ai.stanford.edu', 'engineering.stanford.edu',
            # Cambridge
            'repository.cam.ac.uk', 'cam.ac.uk',
            # Oxford
            'ora.ox.ac.uk', 'ox.ac.uk',
            # Berkeley
            'eecs.berkeley.edu', 'bair.berkeley.edu', 'berkeley.edu',
            # ETH Zurich
            'ethz.ch',
            # Caltech
            'caltech.edu',
            # Imperial
            'imperial.ac.uk',
            # Carnegie Mellon
            'cmu.edu',
            # TU Delft
            'tudelft.nl'
        }
    
    def _get_prohibited_keywords(self) -> Set[str]:
        """Ú©Ù„Ù…Ø§Øª Ù…Ù…Ù†ÙˆØ¹Ù‡"""
        return {
            # Ù…Ø­ØªÙˆØ§ÛŒ Ù†Ø§Ù…Ù†Ø§Ø³Ø¨
            'illegal', 'hack', 'crack', 'pirate', 'torrent',
            # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø´Ø®ØµÛŒ
            'password', 'credit card', 'ssn', 'social security',
            # Ù…Ø­ØªÙˆØ§ÛŒ Ø®Ø·Ø±Ù†Ø§Ú©
            'weapon', 'explosive', 'malware', 'virus',
            # Ø³ÛŒØ§Ø³ÛŒ/Ø¬Ù†Ø¬Ø§Ù„ÛŒ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
            # Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÛŒØ§Ø² Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯
        }
    
    def check_url_compliance(self, url: str) -> ComplianceLevel:
        """
        Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù†Ø·Ø¨Ø§Ù‚ URL
        
        Args:
            url: Ø¢Ø¯Ø±Ø³ URL
        
        Returns:
            Ø³Ø·Ø­ Ø§Ù†Ø·Ø¨Ø§Ù‚
        """
        # Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø§Ù…Ù†Ù‡
        from urllib.parse import urlparse
        parsed = urlparse(url)
        domain = parsed.netloc
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø§Ù…Ù†Ù‡ Ø¯Ø± Ù„ÛŒØ³Øª Ù…Ø¬Ø§Ø²
        is_allowed = any(allowed in domain for allowed in self.rules['allowed_domains'])
        
        if not is_allowed:
            self._log_security_event(
                'url_violation',
                f"Unauthorized domain: {domain}",
                {'url': url, 'domain': domain}
            )
            return ComplianceLevel.VIOLATION
        
        return ComplianceLevel.COMPLIANT
    
    def check_content_compliance(self, content: str, metadata: Dict) -> ComplianceLevel:
        """
        Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù†Ø·Ø¨Ø§Ù‚ Ù…Ø­ØªÙˆØ§
        
        Args:
            content: Ù…ØªÙ† Ù…Ø­ØªÙˆØ§
            metadata: Ù…ØªØ§Ø¯ÛŒØªØ§
        
        Returns:
            Ø³Ø·Ø­ Ø§Ù†Ø·Ø¨Ø§Ù‚
        """
        self.monitoring_stats['total_checks'] += 1
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø·ÙˆÙ„ Ù…Ø­ØªÙˆØ§
        if len(content) > self.rules['max_content_length']:
            self._log_security_event(
                'content_length_warning',
                f"Content too long: {len(content)} chars",
                metadata
            )
            self.monitoring_stats['warnings'] += 1
            return ComplianceLevel.WARNING
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„Ù…Ø§Øª Ù…Ù…Ù†ÙˆØ¹Ù‡
        content_lower = content.lower()
        found_prohibited = []
        
        for keyword in self.rules['prohibited_keywords']:
            if keyword in content_lower:
                found_prohibited.append(keyword)
        
        if found_prohibited:
            self._log_security_event(
                'prohibited_content',
                f"Prohibited keywords found: {', '.join(found_prohibited)}",
                metadata
            )
            self.monitoring_stats['violations'] += 1
            
            if self.config['auto_block_violations']:
                self.monitoring_stats['blocked'] += 1
                return ComplianceLevel.BLOCKED
            
            return ComplianceLevel.VIOLATION
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ
        for field in self.rules['required_fields']:
            if field not in metadata and field != 'content':
                self._log_security_event(
                    'missing_field',
                    f"Required field missing: {field}",
                    metadata
                )
                self.monitoring_stats['warnings'] += 1
                return ComplianceLevel.WARNING
        
        # Ù‡Ù…Ù‡ Ú†ÛŒØ² Ù…Ø·Ø§Ø¨Ù‚ Ø§Ø³Øª
        self.monitoring_stats['compliant'] += 1
        return ComplianceLevel.COMPLIANT
    
    def validate_document(self, document: Dict) -> tuple[bool, ComplianceLevel, str]:
        """
        Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ú©Ø§Ù…Ù„ ÛŒÚ© Ø³Ù†Ø¯
        
        Args:
            document: Ø³Ù†Ø¯ Ø´Ø§Ù…Ù„ content Ùˆ metadata
        
        Returns:
            (is_valid, compliance_level, reason)
        """
        # Ø¨Ø±Ø±Ø³ÛŒ URL
        if 'url' in document.get('metadata', {}):
            url_compliance = self.check_url_compliance(document['metadata']['url'])
            if url_compliance in [ComplianceLevel.VIOLATION, ComplianceLevel.BLOCKED]:
                return False, url_compliance, "Invalid URL domain"
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­ØªÙˆØ§
        content = document.get('content', '')
        metadata = document.get('metadata', {})
        
        content_compliance = self.check_content_compliance(content, metadata)
        
        if content_compliance == ComplianceLevel.BLOCKED:
            return False, content_compliance, "Prohibited content detected"
        
        if content_compliance == ComplianceLevel.VIOLATION:
            return False, content_compliance, "Content violation"
        
        if content_compliance == ComplianceLevel.WARNING:
            # Ù‡Ø´Ø¯Ø§Ø± Ø§Ù…Ø§ Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„
            return True, content_compliance, "Content accepted with warnings"
        
        return True, ComplianceLevel.COMPLIANT, "Document is compliant"
    
    def _log_security_event(self, event_type: str, message: str, metadata: Dict):
        """Ø«Ø¨Øª Ø±ÙˆÛŒØ¯Ø§Ø¯ Ø§Ù…Ù†ÛŒØªÛŒ"""
        event = {
            'timestamp': datetime.now().isoformat(),
            'type': event_type,
            'message': message,
            'metadata': metadata
        }
        
        self.security_logs.append(event)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„
        log_file = self.logs_dir / f"{datetime.now().strftime('%Y%m%d')}_security.jsonl"
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(event, ensure_ascii=False) + '\n')
        
        # Ù„Ø§Ú¯ Ø¯Ø± console
        if self.config['notify_on_violation'] and event_type in ['prohibited_content', 'url_violation']:
            logger.warning(f"ðŸš¨ Security Event: {message}")
    
    def get_monitoring_report(self) -> Dict:
        """Ú¯Ø²Ø§Ø±Ø´ Ù†Ø¸Ø§Ø±ØªÛŒ"""
        total = self.monitoring_stats['total_checks']
        
        return {
            'statistics': self.monitoring_stats,
            'compliance_rate': (
                f"{100 * self.monitoring_stats['compliant'] / total:.1f}%"
                if total > 0 else "0%"
            ),
            'recent_logs': self.security_logs[-10:],  # 10 Ø±ÙˆÛŒØ¯Ø§Ø¯ Ø¢Ø®Ø±
            'config': self.config
        }
    
    def get_agent_score(self, agent_name: str) -> float:
        """
        Ø§Ù…ØªÛŒØ§Ø² Ø§Ù†Ø·Ø¨Ø§Ù‚ ÛŒÚ© Ø§ÛŒØ¬Ù†Øª
        
        Returns:
            Ø§Ù…ØªÛŒØ§Ø² Ø¨ÛŒÙ† 0 ØªØ§ 100
        """
        # Ø¯Ø± Ù†Ø³Ø®Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø¢Ù…Ø§Ø± Ù‡Ø± Ø§ÛŒØ¬Ù†Øª Ø±Ø§ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ù†Ú¯Ù‡ Ø¯Ø§Ø´Øª
        total = self.monitoring_stats['total_checks']
        if total == 0:
            return 100.0
        
        compliant = self.monitoring_stats['compliant']
        warnings = self.monitoring_stats['warnings']
        violations = self.monitoring_stats['violations']
        
        score = 100 * (compliant + 0.5 * warnings) / total
        return max(0.0, min(100.0, score))


class SpecializationManager:
    """
    Ù…Ø¯ÛŒØ±ÛŒØª ØªØ®ØµØµâ€ŒÙ‡Ø§ÛŒ Ø¹Ù„Ù…ÛŒ
    
    Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªØ®ØµØµÛŒ Ø¯Ø± Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
    """
    
    def __init__(self):
        # Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ
        self.specializations = {
            'engineering': {
                'civil': ['structural', 'geotechnical', 'transportation', 'hydraulic'],
                'mechanical': ['thermodynamics', 'fluid mechanics', 'manufacturing', 'robotics'],
                'electrical': ['power systems', 'electronics', 'signal processing', 'control'],
                'computer': ['algorithms', 'software engineering', 'AI', 'networks'],
                'chemical': ['process engineering', 'materials', 'thermodynamics'],
                'industrial': ['optimization', 'operations research', 'supply chain'],
                'architecture': ['design', 'urban planning', 'sustainable architecture']
            },
            'management': {
                'business': ['strategy', 'marketing', 'finance', 'operations'],
                'project': ['planning', 'scheduling', 'risk management', 'agile'],
                'hr': ['recruitment', 'training', 'performance', 'organizational behavior'],
                'quality': ['QA/QC', 'six sigma', 'lean', 'ISO standards']
            },
            'economics': {
                'micro': ['consumer theory', 'market structures', 'game theory'],
                'macro': ['monetary policy', 'fiscal policy', 'growth', 'unemployment'],
                'financial': ['investments', 'portfolio theory', 'derivatives', 'risk'],
                'development': ['growth models', 'poverty', 'inequality']
            }
        }
        
        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø±Ø´ØªÙ‡
        self.keywords = self._build_keywords()
    
    def _build_keywords(self) -> Dict[str, List[str]]:
        """Ø³Ø§Ø®Øª Ù„ÛŒØ³Øª Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ"""
        keywords = {}
        
        for field, subfields in self.specializations.items():
            keywords[field] = []
            for subfield, topics in subfields.items():
                keywords[field].extend([subfield] + topics)
        
        return keywords
    
    def detect_specialization(self, content: str) -> Dict[str, float]:
        """
        ØªØ´Ø®ÛŒØµ ØªØ®ØµØµ Ù…Ø­ØªÙˆØ§
        
        Args:
            content: Ù…ØªÙ† Ù…Ø­ØªÙˆØ§
        
        Returns:
            Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ {field: relevance_score}
        """
        content_lower = content.lower()
        scores = {}
        
        for field, field_keywords in self.keywords.items():
            count = sum(1 for keyword in field_keywords if keyword in content_lower)
            scores[field] = count / len(field_keywords) if field_keywords else 0.0
        
        return scores
    
    def get_missing_specializations(self, collected_docs: List[Dict]) -> List[str]:
        """
        Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ú©Ù…ØªØ± Ù¾ÙˆØ´Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯
        
        Args:
            collected_docs: Ù„ÛŒØ³Øª Ø§Ø³Ù†Ø§Ø¯ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒâ€ŒØ´Ø¯Ù‡
        
        Returns:
            Ù„ÛŒØ³Øª Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ù¾ÙˆØ´Ø´ Ú©Ù…
        """
        specialization_counts = {field: 0 for field in self.specializations.keys()}
        
        for doc in collected_docs:
            content = doc.get('content', '')
            scores = self.detect_specialization(content)
            
            # Ø§Ú¯Ø± Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§Ù„Ø§ÛŒ 0.1 Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ØŒ Ø¨Ù‡ Ø¢Ù† Ø±Ø´ØªÙ‡ ØªØ¹Ù„Ù‚ Ø¯Ø§Ø±Ø¯
            for field, score in scores.items():
                if score > 0.1:
                    specialization_counts[field] += 1
        
        # Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§ÛŒÛŒ Ø¨Ø§ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù…
        avg_count = sum(specialization_counts.values()) / len(specialization_counts)
        missing = [
            field for field, count in specialization_counts.items()
            if count < avg_count * 0.5
        ]
        
        return missing
