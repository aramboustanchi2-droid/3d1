#!/usr/bin/env python3
"""
KURDO-AI RAG System + Four Methods Integration Test
Tests RAG and hybrid combinations with Fine-Tuning, LoRA, and Prompt Engineering
"""

import sys
import os

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from cad3d.super_ai.brain import SuperAIBrain
import json


def print_section(title):
    """Print formatted section header."""
    print("\n" + "=" * 80)
    print(f"  {title}")
    print("=" * 80 + "\n")


def print_result(result):
    """Pretty print result."""
    if isinstance(result, str):
        print(result)
    else:
        print(json.dumps(result, indent=2, ensure_ascii=False))
    print()


def test_rag_basics():
    """Test basic RAG functionality."""
    print_section("1. RAG SYSTEM - BASIC FUNCTIONALITY")
    
    brain = SuperAIBrain()
    
    # Check RAG statistics
    print("ğŸ“Š RAG Statistics:")
    stats = brain.get_rag_statistics()
    print_result(stats)
    
    # Test retrieval
    print("\nğŸ” Test Query: 'Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø³Ø§Ø­Øª Ø§ØªØ§Ù‚'")
    print("-" * 60)
    
    results = brain.retrieve_knowledge(
        query="Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø³Ø§Ø­Øª Ø§ØªØ§Ù‚",
        top_k=3
    )
    
    print(f"âœ… Retrieved {len(results)} documents:\n")
    for i, (doc, score) in enumerate(results, 1):
        print(f"ğŸ“„ Document {i} (Relevance: {score:.3f})")
        print(f"   ID: {doc.doc_id}")
        print(f"   Content: {doc.content[:100]}...")
        print(f"   Metadata: {doc.metadata}")
        print()


def test_rag_prompts():
    """Test RAG prompt generation."""
    print_section("2. RAG PROMPT GENERATION")
    
    brain = SuperAIBrain()
    
    query = "Ú†Ù†Ø¯ Ø¢Ø¬Ø± Ø¨Ø±Ø§ÛŒ Ø¯ÛŒÙˆØ§Ø± 15 Ù…ØªØ±ÛŒ Ø¨Ø§ Ø§Ø±ØªÙØ§Ø¹ 3 Ù…ØªØ± Ù†ÛŒØ§Ø² Ø§Ø³ØªØŸ"
    
    print(f"ğŸ¯ Query: {query}")
    print("\n" + "-" * 60 + "\n")
    
    # Generate RAG prompt
    prompt = brain.generate_rag_prompt(
        query=query,
        top_k=3
    )
    
    print("ğŸ“ Generated RAG Prompt:")
    print(prompt)


def test_rag_query():
    """Test complete RAG query."""
    print_section("3. COMPLETE RAG QUERY")
    
    brain = SuperAIBrain()
    
    query = "Ø­Ø¯Ø§Ù‚Ù„ Ø§Ø±ØªÙØ§Ø¹ Ø³Ù‚Ù Ø§ØªØ§Ù‚ Ø®ÙˆØ§Ø¨ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ"
    
    print(f"ğŸ¯ Query: {query}")
    print("\n" + "-" * 60 + "\n")
    
    response = brain.rag_query(
        query=query,
        top_k=3,
        generation_method="prompt_engineering"
    )
    
    print("ğŸ“‹ RAG Response:")
    print(f"\n  Query: {response['query']}")
    print(f"  Method: {response['generation_method']}")
    print(f"  Retrieved: {response['num_documents_retrieved']} documents\n")
    
    print("  ğŸ“š Retrieved Documents:")
    for i, doc in enumerate(response['retrieved_documents'], 1):
        print(f"\n  [{i}] {doc['doc_id']} (Relevance: {doc['relevance_score']:.3f})")
        print(f"      {doc['content'][:150]}...")
    
    print("\n" + "-" * 60 + "\n")
    print("  ğŸ’¬ Generated Prompt Preview:")
    print(f"  {response['prompt'][:300]}...")


def test_add_custom_knowledge():
    """Test adding custom knowledge."""
    print_section("4. ADDING CUSTOM KNOWLEDGE")
    
    brain = SuperAIBrain()
    
    # Add custom document
    custom_doc = """
    ØªØ®Ù…ÛŒÙ† Ù‡Ø²ÛŒÙ†Ù‡ Ø³Ø§Ø®Øª Ø³Ø§Ø®ØªÙ…Ø§Ù† Ù…Ø³Ú©ÙˆÙ†ÛŒ Ø¯Ø± ØªÙ‡Ø±Ø§Ù† (1403):
    - Ø§Ø³Ú©Ù„Øª Ø¨ØªÙ†ÛŒ: 8-10 Ù…ÛŒÙ„ÛŒÙˆÙ† ØªÙˆÙ…Ø§Ù†/Ù…ØªØ±
    - Ø§Ø³Ú©Ù„Øª ÙÙ„Ø²ÛŒ: 9-11 Ù…ÛŒÙ„ÛŒÙˆÙ† ØªÙˆÙ…Ø§Ù†/Ù…ØªØ±
    - Ù†Ø§Ø²Ú©â€ŒÚ©Ø§Ø±ÛŒ (Ú©Ø§Ù…Ù„): 4-5 Ù…ÛŒÙ„ÛŒÙˆÙ† ØªÙˆÙ…Ø§Ù†/Ù…ØªØ±
    - Ù†Ù…Ø§ (Ø³Ù†Ú¯): 2-3 Ù…ÛŒÙ„ÛŒÙˆÙ† ØªÙˆÙ…Ø§Ù†/Ù…ØªØ±
    Ø¬Ù…Ø¹ Ú©Ù„ Ø¨Ø±Ø§ÛŒ 100 Ù…ØªØ±: Ø­Ø¯ÙˆØ¯ 1.5-2 Ù…ÛŒÙ„ÛŒØ§Ø±Ø¯ ØªÙˆÙ…Ø§Ù†
    """
    
    print("ğŸ“ Adding Custom Document:")
    print(custom_doc.strip())
    print("\n" + "-" * 60 + "\n")
    
    doc = brain.add_knowledge_document(
        content=custom_doc.strip(),
        doc_id="custom_cost_001",
        metadata={"category": "cost", "year": "1403", "language": "fa"}
    )
    
    if doc:
        print(f"âœ… Document Added: {doc.doc_id}")
        print(f"   Metadata: {doc.metadata}")
    
    # Test retrieval of custom document
    print("\nğŸ” Testing Retrieval:")
    results = brain.retrieve_knowledge(
        query="ØªØ®Ù…ÛŒÙ† Ù‡Ø²ÛŒÙ†Ù‡ Ø³Ø§Ø®Øª Ø¢Ù¾Ø§Ø±ØªÙ…Ø§Ù†",
        top_k=2
    )
    
    for i, (doc, score) in enumerate(results, 1):
        print(f"\n  [{i}] {doc.doc_id} (Score: {score:.3f})")
        print(f"      {doc.content[:100]}...")


def test_hybrid_rag_prompt_engineering():
    """Test RAG + Prompt Engineering hybrid."""
    print_section("5. HYBRID: RAG + PROMPT ENGINEERING")
    
    brain = SuperAIBrain()
    
    query = "Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø³Ø§Ø­Øª Ø§ØªØ§Ù‚ 9Ã—7 Ù…ØªØ±"
    
    # Few-shot examples
    examples = [
        {"input": "Ù…Ø³Ø§Ø­Øª 5Ã—4", "output": "20 Ù…ØªØ± Ù…Ø±Ø¨Ø¹"},
        {"input": "Ù…Ø³Ø§Ø­Øª 8Ã—6", "output": "48 Ù…ØªØ± Ù…Ø±Ø¨Ø¹"}
    ]
    
    print(f"ğŸ¯ Query: {query}")
    print(f"ğŸ“š Few-Shot Examples: {len(examples)}")
    print(f"ğŸ” RAG Documents: top 2")
    print("\n" + "-" * 60 + "\n")
    
    prompt = brain.hybrid_rag_prompt_engineering(
        query=query,
        few_shot_examples=examples,
        top_k=2
    )
    
    print("ğŸš€ Hybrid Prompt (RAG + Few-Shot):")
    print(prompt[:500] + "...\n")
    
    print("âœ… This combines:")
    print("  â€¢ RAG: Retrieved relevant context from knowledge base")
    print("  â€¢ Prompt Engineering: Added few-shot examples")
    print("  â€¢ Result: Best of both worlds!")


def test_all_four_methods_comparison():
    """Compare all four methods."""
    print_section("6. COMPARISON: ALL FOUR METHODS")
    
    brain = SuperAIBrain()
    
    comparison = brain.compare_all_four_methods()
    
    print("ğŸ“Š Complete Comparison:")
    print_result(comparison)
    
    # Print summary table
    print("\n" + "=" * 100)
    print("QUICK COMPARISON TABLE")
    print("=" * 100)
    print(f"{'Method':<25} {'Time':<15} {'Cost':<15} {'GPU':<15} {'Best For':<30}")
    print("-" * 100)
    
    methods_summary = [
        ("RAG", "Minutes", "$0", "No", "Knowledge bases, facts"),
        ("Prompt Engineering", "Instant", "$0", "No", "Prototyping, quick start"),
        ("LoRA", "1-3 hours", "$0", "Yes (6GB+)", "Multiple tasks, limited GPU"),
        ("Fine-Tuning", "4-10 hours", "$10-50", "Yes (40GB+)", "Production, best quality")
    ]
    
    for method, time, cost, gpu, best_for in methods_summary:
        print(f"{method:<25} {time:<15} {cost:<15} {gpu:<15} {best_for:<30}")
    
    print("=" * 100)


def test_hybrid_strategies():
    """Test different hybrid strategies."""
    print_section("7. HYBRID STRATEGIES")
    
    brain = SuperAIBrain()
    
    comparison = brain.compare_all_four_methods()
    
    print("ğŸ”„ Available Hybrid Strategies:\n")
    
    strategies = comparison.get("hybrid_strategies", {})
    
    for strategy_name, details in strategies.items():
        print(f"ğŸ“Œ {strategy_name.upper().replace('_', ' ')}")
        print(f"   Description: {details['description']}")
        print(f"   Best For: {details['best_for']}")
        print(f"   Setup Time: {details['setup_time']}")
        print(f"   Cost: {details['cost']}")
        print()


def test_practical_use_case():
    """Test practical architectural use case."""
    print_section("8. PRACTICAL USE CASE: ARCHITECTURAL ASSISTANT")
    
    brain = SuperAIBrain()
    
    print("ğŸ—ï¸  Scenario: Architectural consultant answering client questions\n")
    
    queries = [
        "Ø¹Ù…Ù‚ Ù¾ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®ØªÙ…Ø§Ù† 5 Ø·Ø¨Ù‚Ù‡ Ø¯Ø± ØªÙ‡Ø±Ø§Ù†ØŸ",
        "Ú†Ù†Ø¯ Ø¢Ø¬Ø± Ø¨Ø±Ø§ÛŒ Ø¯ÛŒÙˆØ§Ø± 20 Ù…ØªØ±ÛŒ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ù…ØŸ",
        "Ø§Ø¨Ø¹Ø§Ø¯ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ù¾Ø§Ø±Ú©ÛŒÙ†Ú¯ Ú†ÛŒØ³ØªØŸ",
        "Ù†Ø³Ø¨Øª Ù¾Ù†Ø¬Ø±Ù‡ Ø¨Ù‡ Ú©Ù Ø§ØªØ§Ù‚ØŸ"
    ]
    
    for i, query in enumerate(queries, 1):
        print(f"ğŸ”¹ Query {i}: {query}")
        print("-" * 60)
        
        # Use RAG to answer
        results = brain.retrieve_knowledge(query, top_k=1)
        
        if results:
            doc, score = results[0]
            print(f"   ğŸ“š Retrieved (Relevance: {score:.3f}):")
            print(f"   {doc.content[:200]}...")
            print()
        else:
            print("   âŒ No relevant documents found\n")


def test_save_load_knowledge_base():
    """Test saving and loading knowledge base."""
    print_section("9. SAVE/LOAD KNOWLEDGE BASE")
    
    brain = SuperAIBrain()
    
    # Get current stats
    stats_before = brain.get_rag_statistics()
    print("ğŸ“Š Current Knowledge Base:")
    print(f"   Documents: {stats_before.get('vector_store_size', 0)}")
    print(f"   Total Retrievals: {stats_before.get('total_retrievals', 0)}")
    
    # Save
    print("\nğŸ’¾ Saving knowledge base...")
    result = brain.save_rag_knowledge_base(name="test_kb")
    print(f"   Status: {result.get('status', 'unknown')}")
    
    # Load
    print("\nğŸ“‚ Loading knowledge base...")
    result = brain.load_rag_knowledge_base(name="test_kb")
    print(f"   Status: {result.get('status', 'unknown')}")
    
    # Verify
    stats_after = brain.get_rag_statistics()
    print("\nâœ… Verification:")
    print(f"   Documents: {stats_after.get('vector_store_size', 0)}")
    print(f"   Match: {'Yes' if stats_before.get('vector_store_size') == stats_after.get('vector_store_size') else 'No'}")


def demo_four_methods_workflow():
    """Demonstrate complete workflow with all four methods."""
    print_section("10. COMPLETE WORKFLOW: ALL FOUR METHODS")
    
    print("""
ğŸ¯ REAL-WORLD SCENARIO: Building an Architectural AI Assistant

Phase 1: IMMEDIATE START (Day 1)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Method: RAG + Prompt Engineering                            â”‚
â”‚ Time: 1-2 hours                                             â”‚
â”‚ Cost: $0                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Index architectural standards (Ù…Ø¨Ø­Ø« 19ØŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ 2800)  â”‚
â”‚ â€¢ Add calculation formulas                                  â”‚
â”‚ â€¢ Create few-shot prompts                                   â”‚
â”‚ â€¢ Launch MVP!                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 2: COLLECT DATA (Weeks 1-2)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ Log all user queries                                      â”‚
â”‚ â€¢ Collect expert responses                                  â”‚
â”‚ â€¢ Build dataset: 50-100 examples                           â”‚
â”‚ â€¢ RAG handles 80% of queries successfully                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 3: TRAIN LoRA (Week 3)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Method: RAG + LoRA                                          â”‚
â”‚ Time: 2-3 hours training                                    â”‚
â”‚ Cost: $0 (local GPU)                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Train LoRA adapter on collected data                      â”‚
â”‚ â€¢ Keep RAG for facts and standards                          â”‚
â”‚ â€¢ Use LoRA for reasoning and calculations                   â”‚
â”‚ â€¢ Accuracy improves to 90%                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 4: SCALE UP (Month 2)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ Collect 500+ examples                                     â”‚
â”‚ â€¢ Multiple LoRA adapters for different tasks:               â”‚
â”‚   - Calculations (Ù…Ø³Ø§Ø­ØªØŒ Ø­Ø¬Ù…ØŒ Ø¢Ø¬Ø±)                         â”‚
â”‚   - Standards (Ù…Ø¨Ø­Ø« 19ØŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ 2800)                   â”‚
â”‚   - Cost estimation                                         â”‚
â”‚   - Design review                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 5: PRODUCTION (Month 3+)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Method: RAG + Fine-Tuning + LoRA + Prompt Engineering      â”‚
â”‚ Time: One-time 8-hour training                             â”‚
â”‚ Cost: $50 (cloud) or $0 (local A100)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Fine-tune base model on 1000+ examples                    â”‚
â”‚ â€¢ Keep RAG for dynamic knowledge                            â”‚
â”‚ â€¢ Keep LoRA adapters for specific tasks                     â”‚
â”‚ â€¢ Keep Prompt Engineering for edge cases                    â”‚
â”‚ â€¢ Accuracy: 95%+                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

FINAL ARCHITECTURE:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    User Query
                        â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     Query Router              â”‚
        â”‚  (Classify query type)        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           RAG                 â”‚
        â”‚  (Retrieve relevant context)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    Generation Method          â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ â€¢ Simple facts â†’ RAG only     â”‚
        â”‚ â€¢ Calculations â†’ LoRA         â”‚
        â”‚ â€¢ Complex â†’ Fine-Tuned        â”‚
        â”‚ â€¢ Edge cases â†’ Few-Shot       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
                    Response

âœ… BENEFITS:
â€¢ Start immediately with RAG
â€¢ Iterate quickly with LoRA
â€¢ Scale to production with Fine-Tuning
â€¢ Handle everything with combined approach
â€¢ Total cost: $0-50 (vs $500+ for traditional approach)
    """)


def interactive_menu():
    """Interactive test menu."""
    print_section("KURDO-AI RAG + FOUR METHODS - INTERACTIVE DEMO")
    
    menu = """
    Choose a test to run:
    
    1. ğŸ“š RAG System - Basic Functionality
    2. ğŸ“ RAG Prompt Generation
    3. ğŸ’¬ Complete RAG Query
    4. â• Add Custom Knowledge
    5. ğŸ”„ Hybrid: RAG + Prompt Engineering
    6. ğŸ“Š Compare All Four Methods
    7. ğŸ¯ Hybrid Strategies
    8. ğŸ—ï¸  Practical Use Case
    9. ğŸ’¾ Save/Load Knowledge Base
    10. ğŸš€ Complete Workflow Demo
    11. ğŸ”¥ Run All Tests
    12. âŒ Exit
    
    Enter choice (1-12): """
    
    tests = {
        '1': test_rag_basics,
        '2': test_rag_prompts,
        '3': test_rag_query,
        '4': test_add_custom_knowledge,
        '5': test_hybrid_rag_prompt_engineering,
        '6': test_all_four_methods_comparison,
        '7': test_hybrid_strategies,
        '8': test_practical_use_case,
        '9': test_save_load_knowledge_base,
        '10': demo_four_methods_workflow,
    }
    
    while True:
        try:
            choice = input(menu).strip()
            
            if choice == '12':
                print("\nğŸ‘‹ Goodbye!")
                break
            elif choice == '11':
                print("\nğŸš€ Running all tests...\n")
                for test_func in tests.values():
                    try:
                        test_func()
                    except Exception as e:
                        print(f"âŒ Test failed: {e}\n")
                print("\nâœ… All tests complete!")
            elif choice in tests:
                try:
                    tests[choice]()
                except Exception as e:
                    print(f"\nâŒ Error: {e}\n")
                    import traceback
                    traceback.print_exc()
            else:
                print("\nâŒ Invalid choice. Please enter 1-12.\n")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Interrupted by user. Goodbye!")
            break
        except EOFError:
            break


def main():
    """Main entry point."""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘    ğŸ¯ KURDO-AI: RAG + FOUR METHODS INTEGRATION TEST ğŸ¯                      â•‘
â•‘                                                                              â•‘
â•‘  Four Complementary Methods:                                                 â•‘
â•‘    1ï¸âƒ£  RAG - Retrieval-Augmented Generation (Knowledge Base)               â•‘
â•‘    2ï¸âƒ£  Prompt Engineering - Zero/Few-Shot Learning                         â•‘
â•‘    3ï¸âƒ£  LoRA - Parameter-Efficient Fine-Tuning                              â•‘
â•‘    4ï¸âƒ£  Fine-Tuning - Complete Model Adaptation                             â•‘
â•‘                                                                              â•‘
â•‘  Hybrid Strategies:                                                          â•‘
â•‘    âœ… RAG + Prompt Engineering (Instant, $0)                                â•‘
â•‘    âœ… RAG + LoRA (Fast, Accurate)                                           â•‘
â•‘    âœ… RAG + Fine-Tuning (Production-Grade)                                  â•‘
â•‘    âœ… All Four Combined (Enterprise AI)                                     â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    if len(sys.argv) > 1:
        arg = sys.argv[1].lower()
        
        if arg == '--rag-basics':
            test_rag_basics()
        elif arg == '--rag-prompts':
            test_rag_prompts()
        elif arg == '--rag-query':
            test_rag_query()
        elif arg == '--add-knowledge':
            test_add_custom_knowledge()
        elif arg == '--hybrid':
            test_hybrid_rag_prompt_engineering()
        elif arg == '--compare':
            test_all_four_methods_comparison()
        elif arg == '--strategies':
            test_hybrid_strategies()
        elif arg == '--use-case':
            test_practical_use_case()
        elif arg == '--save-load':
            test_save_load_knowledge_base()
        elif arg == '--workflow':
            demo_four_methods_workflow()
        elif arg == '--all':
            print("\nğŸš€ Running all tests...\n")
            test_rag_basics()
            test_rag_prompts()
            test_rag_query()
            test_add_custom_knowledge()
            test_hybrid_rag_prompt_engineering()
            test_all_four_methods_comparison()
            test_hybrid_strategies()
            test_practical_use_case()
            test_save_load_knowledge_base()
            demo_four_methods_workflow()
            print("\nâœ… All tests complete!")
        else:
            print(f"Unknown argument: {arg}")
            print("\nAvailable arguments:")
            print("  --rag-basics    : Test RAG basics")
            print("  --rag-prompts   : Test RAG prompts")
            print("  --rag-query     : Test RAG query")
            print("  --add-knowledge : Test adding knowledge")
            print("  --hybrid        : Test RAG + Prompt Eng")
            print("  --compare       : Compare all methods")
            print("  --strategies    : Show hybrid strategies")
            print("  --use-case      : Practical example")
            print("  --save-load     : Save/load KB")
            print("  --workflow      : Complete workflow")
            print("  --all           : Run all tests")
            print("  (no args)       : Interactive menu")
    else:
        # Interactive mode
        interactive_menu()


if __name__ == "__main__":
    main()
