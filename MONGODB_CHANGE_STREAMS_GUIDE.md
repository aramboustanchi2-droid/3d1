# MongoDB Change Streams Guide

## Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Change Streams Ø¯Ø± MongoDB

### Overview | Ù†Ù…Ø§ÛŒ Ú©Ù„ÛŒ

**MongoDB Change Streams** provide real-time notifications when data changes in your database. Perfect for building reactive applications, live dashboards, and event-driven architectures.

**Use Cases**:

- ğŸ“Š Live dashboards (show new predictions as they arrive)
- ğŸ”„ Data synchronization (replicate changes to other systems)
- ğŸ”” Event notifications (trigger actions on specific changes)
- ğŸ“ Audit logging (track all data modifications)
- â™»ï¸ Cache invalidation (update caches when source data changes)

### Architecture | Ù…Ø¹Ù…Ø§Ø±ÛŒ

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Application Layer                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  Writer    â”‚      â”‚  Watcher   â”‚                 â”‚
â”‚  â”‚  Process   â”‚      â”‚  Process   â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                   â”‚
          â–¼                   â”‚ Change Events
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
    â”‚ MongoDB  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚ (Replica â”‚   insert/update/delete
    â”‚  Set)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Requirements | Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²Ù‡Ø§

**Critical**: Change Streams only work on:

- âœ… MongoDB **Replica Set**
- âœ… MongoDB **Sharded Cluster**
- âŒ NOT standalone MongoDB instance

**Version**: MongoDB 3.6+

### Installation | Ù†ØµØ¨

```bash
pip install pymongo
```

### Setup MongoDB Replica Set (Local Development) | Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ

#### Windows

```powershell
# 1. Stop MongoDB if running
taskkill /F /IM mongod.exe

# 2. Start MongoDB as replica set
mongod --replSet rs0 --port 27017 --dbpath C:\data\db --bind_ip localhost

# 3. In another PowerShell terminal, initialize replica set
mongo --eval "rs.initiate()"

# 4. Wait 10 seconds, verify status
Start-Sleep -Seconds 10
mongo --eval "rs.status()"

# 5. Set environment variable
$env:MONGO_URL='mongodb://localhost:27017/?replicaSet=rs0'
```

#### Linux/Mac

```bash
# Start MongoDB as replica set
mongod --replSet rs0 --port 27017 --dbpath /data/db --bind_ip localhost &

# Initialize replica set
mongo --eval "rs.initiate()"

# Verify
sleep 10
mongo --eval "rs.status()"

# Set environment
export MONGO_URL='mongodb://localhost:27017/?replicaSet=rs0'
```

### Usage | Ø§Ø³ØªÙØ§Ø¯Ù‡

#### Command Line

```powershell
# Watch all changes on predictions collection
python -m cad3d.super_ai.mongodb_change_streams --collection predictions

# Watch specific operations only
python -m cad3d.super_ai.mongodb_change_streams --collection models --operations insert update

# Watch entire database
python -m cad3d.super_ai.mongodb_change_streams

# Run demo
python demo_mongodb_change_streams.py
```

#### Python API

##### Basic Usage

```python
from cad3d.super_ai.ai_db_factory import create_ai_database
from cad3d.super_ai.mongodb_change_streams import MongoChangeStreams

# Connect to MongoDB
db = create_ai_database(
    backend='mongodb',
    connection_string='mongodb://localhost:27017/?replicaSet=rs0'
)

# Create watcher
watcher = MongoChangeStreams(db)

# Watch collection (blocking)
watcher.watch_collection('predictions')
```

##### Custom Callback

```python
def on_new_prediction(change):
    """Called whenever a new prediction is inserted"""
    if change['operationType'] == 'insert':
        doc = change['fullDocument']
        print(f"New prediction: {doc['output']}, confidence: {doc['confidence']}")
        
        # Trigger action (send notification, update cache, etc.)
        notify_dashboard(doc)

watcher = MongoChangeStreams(db, callback=on_new_prediction)
watcher.watch_collection('predictions', operation_types=['insert'])
```

##### Background Watching (Non-blocking)

```python
# Start watcher in background thread
thread = watcher.watch_collection_async('predictions')

# Do other work...
db.log_prediction(version_id, input_data, output_data)

# Stop watcher when done
watcher.stop()
thread.join()
```

##### Watch Multiple Collections

```python
# Watch models, predictions, and metrics simultaneously
watcher.watch_multiple_collections(
    collection_names=['models', 'predictions', 'metrics'],
    operation_types=['insert', 'update']
)
```

##### Queue-Based Processing

```python
# Use queue instead of callback (useful for decoupling)
watcher = MongoChangeStreams(db, use_queue=True, queue_size=1000)

# Start watcher in background
thread = watcher.watch_collection_async('predictions')

# Process changes from queue
while True:
    change = watcher.get_changes_from_queue(timeout=1.0)
    if change:
        process_change(change)
    else:
        # No changes, do other work
        time.sleep(0.1)
```

### Change Event Structure | Ø³Ø§Ø®ØªØ§Ø± Ø±ÙˆÛŒØ¯Ø§Ø¯

```python
{
    'operationType': 'insert',  # or 'update', 'delete', 'replace'
    'fullDocument': {           # Complete document (if available)
        'id': 1,
        'model_version_id': 5,
        'output': {'class': 'cat', 'score': 0.95},
        'confidence': 0.92,
        'timestamp': '2025-11-22T10:30:00'
    },
    'ns': {                     # Namespace
        'db': 'aidb',
        'coll': 'predictions'
    },
    'documentKey': {            # Document identifier
        '_id': ObjectId('...')
    },
    'updateDescription': {      # For updates: what changed
        'updatedFields': {'confidence': 0.98},
        'removedFields': []
    },
    'clusterTime': Timestamp(...),
    '_id': {                    # Resume token (for fault tolerance)
        '_data': '...'
    }
}
```

### Operation Types | Ø§Ù†ÙˆØ§Ø¹ Ø¹Ù…Ù„ÛŒØ§Øª

| Type | Description |
|------|-------------|
| `insert` | New document inserted |
| `update` | Existing document updated |
| `delete` | Document deleted |
| `replace` | Document replaced entirely |
| `drop` | Collection dropped |
| `rename` | Collection renamed |
| `dropDatabase` | Database dropped |
| `invalidate` | Stream invalidated (e.g., collection dropped) |

### Filtering Changes | ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† ØªØºÛŒÛŒØ±Ø§Øª

#### By Operation Type

```python
# Watch only inserts
watcher.watch_collection('predictions', operation_types=['insert'])

# Watch inserts and updates
watcher.watch_collection('models', operation_types=['insert', 'update'])
```

#### By Custom Criteria (Pipeline)

```python
# Watch high-confidence predictions only
pipeline = [
    {'$match': {'operationType': 'insert'}},
    {'$match': {'fullDocument.confidence': {'$gte': 0.9}}}
]

with db._db['predictions'].watch(pipeline, full_document='updateLookup') as stream:
    for change in stream:
        print(f"High confidence prediction: {change['fullDocument']}")
```

### Full Document Modes | Ø­Ø§Ù„Øªâ€ŒÙ‡Ø§ÛŒ Ø³Ù†Ø¯ Ú©Ø§Ù…Ù„

```python
# 'updateLookup': Fetch full document after update (recommended)
watcher.watch_collection('predictions', full_document='updateLookup')

# 'default': Only include changed fields (faster but incomplete)
watcher.watch_collection('predictions', full_document='default')
```

### Fault Tolerance | ØªØ­Ù…Ù„ Ø®Ø·Ø§

Change Streams support **resume tokens** for recovering from failures:

```python
resume_token = None

try:
    watcher.watch_collection('predictions', resume_after=resume_token)
except Exception as e:
    # Save resume token for next attempt
    resume_token = stream.resume_token
    
    # Restart with resume token
    watcher.watch_collection('predictions', resume_after=resume_token)
```

### Real-World Examples | Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ

#### Example 1: Live Dashboard

```python
def update_dashboard(change):
    """Update dashboard on new predictions"""
    if change['operationType'] == 'insert':
        doc = change['fullDocument']
        
        # Send to WebSocket clients
        websocket.broadcast({
            'type': 'new_prediction',
            'model_id': doc['model_version_id'],
            'output': doc['output'],
            'confidence': doc['confidence'],
            'timestamp': doc['timestamp']
        })

watcher = MongoChangeStreams(db, callback=update_dashboard)
watcher.watch_collection('predictions', operation_types=['insert'])
```

#### Example 2: Cache Invalidation

```python
def invalidate_cache(change):
    """Clear cache when model updated"""
    if change['operationType'] == 'update':
        model_id = change['fullDocument']['id']
        redis_cache.delete(f"model:{model_id}")
        print(f"Cache cleared for model {model_id}")

watcher = MongoChangeStreams(db, callback=invalidate_cache)
watcher.watch_collection('models', operation_types=['update'])
```

#### Example 3: Audit Log

```python
def audit_log(change):
    """Log all changes to audit table"""
    audit_db.insert({
        'timestamp': datetime.utcnow(),
        'collection': change['ns']['coll'],
        'operation': change['operationType'],
        'document_id': change['documentKey'],
        'user': current_user_id
    })

watcher = MongoChangeStreams(db, callback=audit_log)
watcher.watch_database()  # Watch entire database
```

#### Example 4: Data Sync to PostgreSQL

```python
def sync_to_postgres(change):
    """Replicate changes to PostgreSQL"""
    op = change['operationType']
    doc = change.get('fullDocument', {})
    
    if op == 'insert':
        postgres_db.create_model(
            name=doc['name'],
            architecture=doc['architecture'],
            # ... other fields
        )
    elif op == 'update':
        postgres_db.update_model(doc['id'], doc)
    elif op == 'delete':
        postgres_db.delete_model(change['documentKey']['_id'])

watcher = MongoChangeStreams(db, callback=sync_to_postgres)
watcher.watch_collection('models')
```

### Performance | Ø¹Ù…Ù„Ú©Ø±Ø¯

**Throughput**: Up to 10,000 change events/second per watcher (depends on network, payload size)

**Latency**: Typically 1-10ms from write to notification

**Resource Usage**:

- Memory: ~10MB per active watcher
- CPU: Minimal (event-driven, not polling)
- Network: Proportional to change volume

### Troubleshooting | Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ

#### Error: "The $changeStream stage is only supported on replica sets"

**Solution**: MongoDB is not configured as replica set. Follow setup instructions above.

```powershell
# Verify replica set status
mongo --eval "rs.status()"
```

#### Error: "Connection refused"

**Solution**: MongoDB not running or wrong host/port.

```powershell
# Check if MongoDB is running
Get-Process mongod

# Start MongoDB
mongod --replSet rs0 --port 27017 --dbpath C:\data\db
```

#### No Change Events

**Possible causes**:

1. Watching wrong collection
2. Filter too restrictive (operation_types)
3. MongoDB not in replica set mode
4. No writes happening (test with manual insert)

**Debug**:

```python
# Watch entire database to see all changes
watcher.watch_database()
```

#### Resume Token Expired

If you pause watching for >24 hours, resume token may expire.

**Solution**: Catch error and restart without resume token:

```python
try:
    watcher.watch_collection('predictions', resume_after=old_token)
except pymongo.errors.OperationFailure as e:
    if 'resume' in str(e).lower():
        # Token expired, start fresh
        watcher.watch_collection('predictions')
```

### Deployment | Ø§Ø³ØªÙ‚Ø±Ø§Ø±

#### Systemd Service (Linux)

```ini
[Unit]
Description=MongoDB Change Streams Watcher
After=network.target mongod.service

[Service]
Type=simple
User=your_user
WorkingDirectory=/path/to/project
Environment="MONGO_URL=mongodb://localhost:27017/?replicaSet=rs0"
ExecStart=/path/to/venv/bin/python -m cad3d.super_ai.mongodb_change_streams --collection predictions
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

#### Docker Compose

```yaml
version: '3.8'

services:
  mongo:
    image: mongo:6
    command: mongod --replSet rs0
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db
    
  mongo-init:
    image: mongo:6
    depends_on:
      - mongo
    command: >
      bash -c "
        sleep 5;
        mongo --host mongo --eval 'rs.initiate()';
      "
  
  watcher:
    build: .
    depends_on:
      - mongo-init
    environment:
      - MONGO_URL=mongodb://mongo:27017/?replicaSet=rs0
    command: python -m cad3d.super_ai.mongodb_change_streams --collection predictions

volumes:
  mongo_data:
```

### Best Practices | Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´â€ŒÙ‡Ø§

1. **Filter Early**: Use operation_types and pipeline filters to reduce unnecessary events
2. **Handle Errors**: Wrap callback in try/except to prevent watcher crashes
3. **Resume Tokens**: Store resume tokens for fault tolerance in production
4. **Resource Limits**: Limit number of concurrent watchers (each uses resources)
5. **Monitoring**: Track stats (watcher.get_stats()) and log errors
6. **Testing**: Test with mock data before production deployment
7. **Cleanup**: Always call watcher.stop() to release resources

### Comparison with Other Systems | Ù…Ù‚Ø§ÛŒØ³Ù‡

| Feature | MongoDB Change Streams | Redis Pub/Sub | PostgreSQL LISTEN/NOTIFY |
|---------|----------------------|---------------|--------------------------|
| **Durability** | âœ… Durable (replicated) | âŒ Not durable | âš ï¸ Best-effort |
| **Order** | âœ… Guaranteed | âš ï¸ Not guaranteed | âš ï¸ Not guaranteed |
| **Resume** | âœ… Resume tokens | âŒ No | âŒ No |
| **Filtering** | âœ… Rich (aggregation) | âš ï¸ Pattern match | âš ï¸ Channel-based |
| **Payload** | âœ… Full document | âš ï¸ Message only | âš ï¸ Message only |
| **Scalability** | âœ… Excellent | âœ… Excellent | âš ï¸ Good |

### Limitations | Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§

1. **Replica Set Required**: Not available on standalone MongoDB
2. **Retention**: Events retained for ~24 hours (configurable via oplog size)
3. **Resource Usage**: Each watcher consumes connection + memory
4. **Not for Polling**: Not a replacement for regular queries (use for events only)
5. **No Historical Data**: Only shows changes after watcher starts (use find() for existing data)

### Related Files | ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·

- `cad3d/super_ai/mongodb_change_streams.py` - Change Streams implementation
- `demo_mongodb_change_streams.py` - Demo script
- `cad3d/super_ai/ai_model_database_mongo.py` - MongoDB backend
- `cad3d/super_ai/ai_db_factory.py` - Database factory

### Summary | Ø®Ù„Ø§ØµÙ‡

âœ… **Real-time**: Instant notifications on data changes  
âœ… **Durable**: Guaranteed delivery with resume tokens  
âœ… **Flexible**: Rich filtering via aggregation pipelines  
âœ… **Scalable**: Handle high-volume change streams  
âœ… **Unified API**: Same interface as other backends  

**Best For**: Live dashboards, event-driven architectures, data sync, audit logging, cache invalidation.

---

**Ù¾Ø§ÛŒØ§Ù† Ø±Ø§Ù‡Ù†Ù…Ø§** | End of Guide
