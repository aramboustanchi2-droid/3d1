[
  {
    "timestamp": "2025-11-21T22:36:11.337Z",
    "fileName": "cad3d\\super_ai\\prompt_engineering.py",
    "content": "\"\"\"\r\nPrompt Engineering & Instruction Tuning Module for KURDO-AI\r\nThird complementary training method alongside Fine-Tuning and LoRA\r\n\r\nThis module provides:\r\n- Prompt templates and optimization\r\n- Few-shot learning without training\r\n- Instruction tuning strategies\r\n- System prompt caching (Anthropic style)\r\n- Prompt chaining and composition\r\n- Zero-shot and few-shot techniques\r\n\"\"\"\r\n\r\nimport logging\r\nfrom typing import Dict, List, Optional, Any, Tuple\r\nfrom datetime import datetime\r\nimport json\r\nimport os\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\nclass PromptTemplate:\r\n    \"\"\"A reusable prompt template with variables.\"\"\"\r\n    \r\n    def __init__(self, name: str, template: str, variables: List[str], category: str = \"general\"):\r\n        self.name = name\r\n        self.template = template\r\n        self.variables = variables\r\n        self.category = category\r\n        self.usage_count = 0\r\n        self.created_at = datetime.now().isoformat()\r\n    \r\n    def format(self, **kwargs) -> str:\r\n        \"\"\"Format the template with given variables.\"\"\"\r\n        self.usage_count += 1\r\n        return self.template.format(**kwargs)\r\n    \r\n    def to_dict(self) -> dict:\r\n        \"\"\"Convert to dictionary.\"\"\"\r\n        return {\r\n            \"name\": self.name,\r\n            \"template\": self.template,\r\n            \"variables\": self.variables,\r\n            \"category\": self.category,\r\n            \"usage_count\": self.usage_count,\r\n            \"created_at\": self.created_at\r\n        }\r\n\r\n\r\nclass InstructionSet:\r\n    \"\"\"A set of instructions for task-specific behavior.\"\"\"\r\n    \r\n    def __init__(self, name: str, instructions: List[str], examples: List[Dict] = None):\r\n        self.name = name\r\n        self.instructions = instructions\r\n        self.examples = examples or []\r\n        self.created_at = datetime.now().isoformat()\r\n    \r\n    def to_prompt(self, include_examples: bool = True, max_examples: int = 5) -> str:\r\n        \"\"\"Convert to a full prompt.\"\"\"\r\n        prompt = \"# Instructions\\n\\n\"\r\n        for i, instruction in enumerate(self.instructions, 1):\r\n            prompt += f\"{i}. {instruction}\\n\"\r\n        \r\n        if include_examples and self.examples:\r\n            prompt += \"\\n# Examples\\n\\n\"\r\n            for i, example in enumerate(self.examples[:max_examples], 1):\r\n                prompt += f\"Example {i}:\\n\"\r\n                if \"input\" in example:\r\n                    prompt += f\"Input: {example['input']}\\n\"\r\n                if \"output\" in example:\r\n                    prompt += f\"Output: {example['output']}\\n\"\r\n                prompt += \"\\n\"\r\n        \r\n        return prompt\r\n\r\n\r\nclass PromptEngineeringManager:\r\n    \"\"\"\r\n    Manages prompt engineering and instruction tuning.\r\n    \r\n    This is a training-free method that relies on:\r\n    - Well-crafted prompts\r\n    - Few-shot learning\r\n    - System instructions\r\n    - Cached examples\r\n    \"\"\"\r\n    \r\n    def __init__(self, storage_dir: str = \"models/prompts\"):\r\n        self.storage_dir = storage_dir\r\n        os.makedirs(storage_dir, exist_ok=True)\r\n        \r\n        self.templates: Dict[str, PromptTemplate] = {}\r\n        self.instruction_sets: Dict[str, InstructionSet] = {}\r\n        self.cached_prompts: Dict[str, str] = {}\r\n        \r\n        # Load built-in templates\r\n        self._initialize_builtin_templates()\r\n        self._initialize_architectural_instructions()\r\n        \r\n        logger.info(\"Prompt Engineering Manager initialized\")\r\n    \r\n    def _initialize_builtin_templates(self):\r\n        \"\"\"Initialize built-in prompt templates.\"\"\"\r\n        \r\n        # Architectural calculation template\r\n        self.add_template(\r\n            name=\"arch_calculation\",\r\n            template=\"\"\"You are KURDO-AI, an expert architectural calculator.\r\n\r\nTask: {task}\r\nGiven: {given_values}\r\nRequired: {required_output}\r\n\r\nShow your calculation steps clearly.\r\nUse appropriate units (metric: meters, square meters, cubic meters).\r\nProvide practical recommendations when relevant.\r\n\r\nAnswer:\"\"\",\r\n            variables=[\"task\", \"given_values\", \"required_output\"],\r\n            category=\"architecture\"\r\n        )\r\n        \r\n        # Code generation template\r\n        self.add_template(\r\n            name=\"code_generation\",\r\n            template=\"\"\"You are KURDO-AI, an expert programmer.\r\n\r\nLanguage: {language}\r\nTask: {task}\r\nRequirements:\r\n{requirements}\r\n\r\nGenerate clean, well-commented code that follows best practices.\r\n\r\nCode:\"\"\",\r\n            variables=[\"language\", \"task\", \"requirements\"],\r\n            category=\"programming\"\r\n        )\r\n        \r\n        # Analysis template\r\n        self.add_template(\r\n            name=\"technical_analysis\",\r\n            template=\"\"\"You are KURDO-AI, a technical analysis expert.\r\n\r\nSubject: {subject}\r\nContext: {context}\r\nAnalysis Type: {analysis_type}\r\n\r\nProvide a detailed, structured analysis with:\r\n1. Key findings\r\n2. Technical details\r\n3. Recommendations\r\n4. Potential issues\r\n\r\nAnalysis:\"\"\",\r\n            variables=[\"subject\", \"context\", \"analysis_type\"],\r\n            category=\"analysis\"\r\n        )\r\n        \r\n        # Design review template\r\n        self.add_template(\r\n            name=\"design_review\",\r\n            template=\"\"\"You are KURDO-AI, an architectural design reviewer.\r\n\r\nProject: {project_name}\r\nDesign Element: {design_element}\r\nStandards: {applicable_standards}\r\n\r\nReview for:\r\n- Code compliance\r\n- Structural integrity\r\n- Practicality\r\n- Cost-effectiveness\r\n- Safety\r\n\r\nReview:\"\"\",\r\n            variables=[\"project_name\", \"design_element\", \"applicable_standards\"],\r\n            category=\"architecture\"\r\n        )\r\n        \r\n        # Translation template\r\n        self.add_template(\r\n            name=\"technical_translation\",\r\n            template=\"\"\"You are KURDO-AI, a technical translator.\r\n\r\nSource Language: {source_lang}\r\nTarget Language: {target_lang}\r\nDomain: {domain}\r\n\r\nTranslate the following technical content accurately, preserving:\r\n- Technical terms\r\n- Measurements and units\r\n- Structural meaning\r\n\r\nText to translate:\r\n{text}\r\n\r\nTranslation:\"\"\",\r\n            variables=[\"source_lang\", \"target_lang\", \"domain\", \"text\"],\r\n            category=\"translation\"\r\n        )\r\n    \r\n    def _initialize_architectural_instructions(self):\r\n        \"\"\"Initialize architectural instruction sets.\"\"\"\r\n        \r\n        # Room calculation instructions\r\n        room_calc_instructions = InstructionSet(\r\n            name=\"room_calculations\",\r\n            instructions=[\r\n                \"Always specify units (meters, square meters, cubic meters)\",\r\n                \"Show calculation steps: formula → substitution → result\",\r\n                \"For area: A = length × width\",\r\n                \"For volume: V = length × width × height\",\r\n                \"Round to 2 decimal places for practical use\",\r\n                \"Provide context (e.g., 'adequate for bedroom', 'requires ventilation')\"\r\n            ],\r\n            examples=[\r\n                {\r\n                    \"input\": \"محاسبه مساحت اتاق 5x4 متر\",\r\n                    \"output\": \"مساحت = طول × عرض\\nمساحت = 5 × 4 = 20 متر مربع\\n\\nاین مساحت برای یک اتاق خواب استاندارد مناسب است.\"\r\n                },\r\n                {\r\n                    \"input\": \"Calculate volume of room 6m × 4m with 2.8m height\",\r\n                    \"output\": \"Volume = length × width × height\\nVolume = 6 × 4 × 2.8 = 67.2 cubic meters\\n\\nThis volume requires adequate ventilation for residential use.\"\r\n                }\r\n            ]\r\n        )\r\n        self.add_instruction_set(room_calc_instructions)\r\n        \r\n        # Material estimation instructions\r\n        material_instructions = InstructionSet(\r\n            name=\"material_estimation\",\r\n            instructions=[\r\n                \"State standard ratios (e.g., 60 bricks per square meter)\",\r\n                \"Calculate base requirement first\",\r\n                \"Add 5-10% waste factor\",\r\n                \"Provide practical ordering advice\",\r\n                \"Consider standard package sizes\"\r\n            ],\r\n            examples=[\r\n                {\r\n                    \"input\": \"چند آجر برای دیوار 10 متری با ارتفاع 3 متر؟\",\r\n                    \"output\": \"مساحت دیوار = 10 × 3 = 30 متر مربع\\nآجر استاندارد = 60 عدد در هر متر مربع\\nآجر مورد نیاز = 30 × 60 = 1,800 عدد\\nبا ضریب اتلاف 10% = 1,980 عدد\\n\\nتوصیه: سفارش 2,000 آجر\"\r\n                }\r\n            ]\r\n        )\r\n        self.add_instruction_set(material_instructions)\r\n        \r\n        # Code compliance instructions\r\n        code_instructions = InstructionSet(\r\n            name=\"building_codes\",\r\n            instructions=[\r\n                \"Reference specific code sections (e.g., مبحث 19)\",\r\n                \"State minimum and recommended values\",\r\n                \"Explain reasoning behind requirements\",\r\n                \"Mention variations by region if applicable\",\r\n                \"Always prioritize safety\"\r\n            ],\r\n            examples=[\r\n                {\r\n                    \"input\": \"حداقل ارتفاع سقف آپارتمان مسکونی؟\",\r\n                    \"output\": \"طبق مبحث 19 مقررات ملی ساختمان:\\n- اتاق‌های اصلی: حداقل 2.4 متر\\n- راهرو: حداقل 2.1 متر\\n- سرویس‌های بهداشتی: حداقل 2.1 متر\\n\\nتوصیه: ارتفاع 2.6-2.8 متر برای احساس فضای بهتر\"\r\n                }\r\n            ]\r\n        )\r\n        self.add_instruction_set(code_instructions)\r\n    \r\n    def add_template(self, name: str, template: str, variables: List[str], category: str = \"general\") -> PromptTemplate:\r\n        \"\"\"Add a new prompt template.\"\"\"\r\n        pt = PromptTemplate(name, template, variables, category)\r\n        self.templates[name] = pt\r\n        self._save_template(pt)\r\n        logger.info(f\"Added template: {name}\")\r\n        return pt\r\n    \r\n    def add_instruction_set(self, instruction_set: InstructionSet):\r\n        \"\"\"Add a new instruction set.\"\"\"\r\n        self.instruction_sets[instruction_set.name] = instruction_set\r\n        logger.info(f\"Added instruction set: {instruction_set.name}\")\r\n    \r\n    def get_template(self, name: str) -> Optional[PromptTemplate]:\r\n        \"\"\"Get a template by name.\"\"\"\r\n        return self.templates.get(name)\r\n    \r\n    def list_templates(self, category: Optional[str] = None) -> List[str]:\r\n        \"\"\"List all templates, optionally filtered by category.\"\"\"\r\n        if category:\r\n            return [name for name, tmpl in self.templates.items() if tmpl.category == category]\r\n        return list(self.templates.keys())\r\n    \r\n    def create_few_shot_prompt(\r\n        self,\r\n        task_description: str,\r\n        examples: List[Dict[str, str]],\r\n        current_input: str,\r\n        max_examples: int = 5,\r\n        include_reasoning: bool = False\r\n    ) -> str:\r\n        \"\"\"\r\n        Create a few-shot learning prompt.\r\n        \r\n        Args:\r\n            task_description: What the AI should do\r\n            examples: List of {\"input\": \"...\", \"output\": \"...\"}\r\n            current_input: The new input to process\r\n            max_examples: Maximum number of examples to include\r\n            include_reasoning: Include chain-of-thought reasoning\r\n        \r\n        Returns:\r\n            Formatted few-shot prompt\r\n        \"\"\"\r\n        prompt = f\"# Task\\n{task_description}\\n\\n\"\r\n        \r\n        if include_reasoning:\r\n            prompt += \"Show your reasoning step-by-step.\\n\\n\"\r\n        \r\n        prompt += \"# Examples\\n\\n\"\r\n        \r\n        for i, example in enumerate(examples[:max_examples], 1):\r\n            prompt += f\"Example {i}:\\n\"\r\n            prompt += f\"Input: {example['input']}\\n\"\r\n            \r\n            if include_reasoning and \"reasoning\" in example:\r\n                prompt += f\"Reasoning: {example['reasoning']}\\n\"\r\n            \r\n            prompt += f\"Output: {example['output']}\\n\\n\"\r\n        \r\n        prompt += \"# Your Turn\\n\\n\"\r\n        prompt += f\"Input: {current_input}\\n\"\r\n        \r\n        if include_reasoning:\r\n            prompt += \"Reasoning: \"\r\n        else:\r\n            prompt += \"Output: \"\r\n        \r\n        return prompt\r\n    \r\n    def create_chain_of_thought_prompt(\r\n        self,\r\n        problem: str,\r\n        domain: str = \"general\"\r\n    ) -> str:\r\n        \"\"\"\r\n        Create a chain-of-thought prompt for complex reasoning.\r\n        \r\n        Args:\r\n            problem: The problem to solve\r\n            domain: Problem domain\r\n        \r\n        Returns:\r\n            CoT prompt\r\n        \"\"\"\r\n        prompt = f\"\"\"You are KURDO-AI, an expert in {domain}.\r\n\r\nProblem: {problem}\r\n\r\nSolve this step-by-step:\r\n1. Understand: What is being asked?\r\n2. Identify: What information do we have?\r\n3. Plan: What approach should we use?\r\n4. Calculate: Work through the solution\r\n5. Verify: Does the answer make sense?\r\n6. Conclude: State the final answer clearly\r\n\r\nLet's work through this:\r\n\r\n\"\"\"\r\n        return prompt\r\n    \r\n    def create_role_based_prompt(\r\n        self,\r\n        role: str,\r\n        expertise: List[str],\r\n        task: str,\r\n        constraints: Optional[List[str]] = None\r\n    ) -> str:\r\n        \"\"\"\r\n        Create a role-based prompt.\r\n        \r\n        Args:\r\n            role: AI role (e.g., \"structural engineer\")\r\n            expertise: List of expertise areas\r\n            task: The task to perform\r\n            constraints: Optional constraints\r\n        \r\n        Returns:\r\n            Role-based prompt\r\n        \"\"\"\r\n        prompt = f\"You are KURDO-AI, a professional {role}.\\n\\n\"\r\n        prompt += \"Your expertise includes:\\n\"\r\n        for exp in expertise:\r\n            prompt += f\"- {exp}\\n\"\r\n        prompt += \"\\n\"\r\n        \r\n        if constraints:\r\n            prompt += \"Important constraints:\\n\"\r\n            for constraint in constraints:\r\n                prompt += f\"- {constraint}\\n\"\r\n            prompt += \"\\n\"\r\n        \r\n        prompt += f\"Task: {task}\\n\\n\"\r\n        prompt += \"Provide a professional, detailed response:\\n\\n\"\r\n        \r\n        return prompt\r\n    \r\n    def create_cached_system_prompt(\r\n        self,\r\n        system_role: str,\r\n        training_examples: List[Dict],\r\n        max_examples: int = 20\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Create a cached system prompt (Anthropic style).\r\n        \r\n        This is cost-effective for repeated use with similar tasks.\r\n        \r\n        Args:\r\n            system_role: System role description\r\n            training_examples: Examples to cache\r\n            max_examples: Maximum examples to include\r\n        \r\n        Returns:\r\n            Cached prompt structure\r\n        \"\"\"\r\n        cached_content = f\"System Role: {system_role}\\n\\n\"\r\n        cached_content += \"# Training Examples\\n\\n\"\r\n        cached_content += \"Learn from these examples:\\n\\n\"\r\n        \r\n        for i, example in enumerate(training_examples[:max_examples], 1):\r\n            cached_content += f\"Example {i}:\\n\"\r\n            if \"input\" in example:\r\n                cached_content += f\"Q: {example['input']}\\n\"\r\n            elif \"prompt\" in example:\r\n                cached_content += f\"Q: {example['prompt']}\\n\"\r\n            \r\n            if \"output\" in example:\r\n                cached_content += f\"A: {example['output']}\\n\"\r\n            elif \"completion\" in example:\r\n                cached_content += f\"A: {example['completion']}\\n\"\r\n            cached_content += \"\\n\"\r\n        \r\n        cached_content += \"Now respond to user queries following these patterns.\\n\"\r\n        \r\n        cache_id = f\"cached_prompt_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\r\n        self.cached_prompts[cache_id] = cached_content\r\n        \r\n        return {\r\n            \"cache_id\": cache_id,\r\n            \"cached_content\": cached_content,\r\n            \"num_examples\": min(len(training_examples), max_examples),\r\n            \"estimated_tokens\": len(cached_content.split()),\r\n            \"usage\": \"Use this cached content as system message in API calls\"\r\n        }\r\n    \r\n    def optimize_prompt(\r\n        self,\r\n        original_prompt: str,\r\n        optimization_strategy: str = \"concise\"\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Optimize a prompt for better performance.\r\n        \r\n        Strategies:\r\n        - concise: Remove redundancy\r\n        - detailed: Add more context\r\n        - structured: Improve formatting\r\n        - directive: Make instructions clearer\r\n        \r\n        Args:\r\n            original_prompt: The prompt to optimize\r\n            optimization_strategy: Strategy to use\r\n        \r\n        Returns:\r\n            Optimized prompt and metadata\r\n        \"\"\"\r\n        optimizations = {\r\n            \"concise\": self._optimize_concise,\r\n            \"detailed\": self._optimize_detailed,\r\n            \"structured\": self._optimize_structured,\r\n            \"directive\": self._optimize_directive\r\n        }\r\n        \r\n        if optimization_strategy not in optimizations:\r\n            return {\r\n                \"status\": \"error\",\r\n                \"message\": f\"Unknown strategy: {optimization_strategy}\",\r\n                \"available_strategies\": list(optimizations.keys())\r\n            }\r\n        \r\n        optimized = optimizations[optimization_strategy](original_prompt)\r\n        \r\n        return {\r\n            \"original\": original_prompt,\r\n            \"optimized\": optimized,\r\n            \"strategy\": optimization_strategy,\r\n            \"original_length\": len(original_prompt),\r\n            \"optimized_length\": len(optimized),\r\n            \"reduction\": f\"{(1 - len(optimized) / len(original_prompt)) * 100:.1f}%\"\r\n        }\r\n    \r\n    def _optimize_concise(self, prompt: str) -> str:\r\n        \"\"\"Make prompt more concise.\"\"\"\r\n        # Remove excessive whitespace\r\n        lines = [line.strip() for line in prompt.split('\\n') if line.strip()]\r\n        return '\\n'.join(lines)\r\n    \r\n    def _optimize_detailed(self, prompt: str) -> str:\r\n        \"\"\"Add more detail to prompt.\"\"\"\r\n        detailed = f\"\"\"Task Context:\r\n{prompt}\r\n\r\nRequirements:\r\n- Be accurate and precise\r\n- Show your work/reasoning\r\n- Use appropriate units and formatting\r\n- Provide practical recommendations\r\n\r\nResponse:\"\"\"\r\n        return detailed\r\n    \r\n    def _optimize_structured(self, prompt: str) -> str:\r\n        \"\"\"Improve prompt structure.\"\"\"\r\n        structured = f\"\"\"# Task\r\n{prompt}\r\n\r\n# Instructions\r\n1. Analyze the requirements carefully\r\n2. Provide a structured response\r\n3. Include relevant details and examples\r\n4. Format output clearly\r\n\r\n# Response\r\n\"\"\"\r\n        return structured\r\n    \r\n    def _optimize_directive(self, prompt: str) -> str:\r\n        \"\"\"Make instructions more directive.\"\"\"\r\n        directive = f\"\"\"INSTRUCTION: {prompt}\r\n\r\nYou must:\r\n- Follow the instruction exactly\r\n- Provide complete information\r\n- Use clear, professional language\r\n- Format output appropriately\r\n\r\nBEGIN RESPONSE:\r\n\"\"\"\r\n        return directive\r\n    \r\n    def compare_with_training_methods(self) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Compare prompt engineering with other training methods.\r\n        \r\n        Returns:\r\n            Detailed comparison\r\n        \"\"\"\r\n        return {\r\n            \"prompt_engineering\": {\r\n                \"type\": \"Training-Free\",\r\n                \"setup_time\": \"Minutes\",\r\n                \"cost\": \"$0 (inference only)\",\r\n                \"gpu_required\": False,\r\n                \"quality\": \"Good (depends on prompt quality)\",\r\n                \"flexibility\": \"Very High\",\r\n                \"best_for\": [\r\n                    \"Quick prototypes\",\r\n                    \"No training data\",\r\n                    \"Rapid iteration\",\r\n                    \"Zero-shot tasks\",\r\n                    \"Cost-sensitive applications\"\r\n                ],\r\n                \"limitations\": [\r\n                    \"Token limits (context window)\",\r\n                    \"Repetitive examples increase cost\",\r\n                    \"Less consistent than fine-tuning\",\r\n                    \"Requires prompt engineering skills\"\r\n                ],\r\n                \"techniques\": [\r\n                    \"Zero-shot prompting\",\r\n                    \"Few-shot learning\",\r\n                    \"Chain-of-thought\",\r\n                    \"Role-based prompts\",\r\n                    \"Instruction tuning\",\r\n                    \"Prompt caching\"\r\n                ]\r\n            },\r\n            \"fine_tuning\": {\r\n                \"type\": \"Full Training\",\r\n                \"setup_time\": \"Hours to Days\",\r\n                \"cost\": \"$10-100+\",\r\n                \"gpu_required\": True,\r\n                \"quality\": \"Excellent\",\r\n                \"flexibility\": \"Low (requires retraining)\",\r\n                \"best_for\": [\r\n                    \"Production deployments\",\r\n                    \"Consistent behavior\",\r\n                    \"Large-scale applications\",\r\n                    \"Specialized domains\"\r\n                ]\r\n            },\r\n            \"lora\": {\r\n                \"type\": \"Parameter-Efficient Training\",\r\n                \"setup_time\": \"30min-3hours\",\r\n                \"cost\": \"$0 (local)\",\r\n                \"gpu_required\": True,\r\n                \"quality\": \"Very Good\",\r\n                \"flexibility\": \"Medium (multiple adapters)\",\r\n                \"best_for\": [\r\n                    \"Multiple tasks\",\r\n                    \"Limited GPU\",\r\n                    \"Fast iteration\",\r\n                    \"Cost-effective training\"\r\n                ]\r\n            },\r\n            \"recommendation\": {\r\n                \"use_prompt_engineering_when\": [\r\n                    \"No training data available\",\r\n                    \"Need immediate results\",\r\n                    \"Budget is limited\",\r\n                    \"Task changes frequently\",\r\n                    \"Prototyping phase\"\r\n                ],\r\n                \"use_fine_tuning_when\": [\r\n                    \"Have quality training data (500+ examples)\",\r\n                    \"Need consistent behavior\",\r\n                    \"Production deployment\",\r\n                    \"Budget allows\"\r\n                ],\r\n                \"use_lora_when\": [\r\n                    \"Have training data (50-500 examples)\",\r\n                    \"Need multiple task-specific models\",\r\n                    \"Limited GPU memory\",\r\n                    \"Want fast training\"\r\n                ],\r\n                \"hybrid_approach\": [\r\n                    \"Start with prompt engineering for prototyping\",\r\n                    \"Collect real-world data\",\r\n                    \"Train LoRA adapter for common tasks\",\r\n                    \"Use prompt engineering for edge cases\",\r\n                    \"Fall back to fine-tuning for production\"\r\n                ]\r\n            }\r\n        }\r\n    \r\n    def _save_template(self, template: PromptTemplate):\r\n        \"\"\"Save template to disk.\"\"\"\r\n        filepath = os.path.join(self.storage_dir, f\"{template.name}.json\")\r\n        with open(filepath, 'w', encoding='utf-8') as f:\r\n            json.dump(template.to_dict(), f, indent=2, ensure_ascii=False)\r\n    \r\n    def get_statistics(self) -> Dict[str, Any]:\r\n        \"\"\"Get usage statistics.\"\"\"\r\n        return {\r\n            \"total_templates\": len(self.templates),\r\n            \"templates_by_category\": self._count_by_category(),\r\n            \"total_instruction_sets\": len(self.instruction_sets),\r\n            \"cached_prompts\": len(self.cached_prompts),\r\n            \"most_used_templates\": self._get_most_used_templates(5)\r\n        }\r\n    \r\n    def _count_by_category(self) -> Dict[str, int]:\r\n        \"\"\"Count templates by category.\"\"\"\r\n        counts = {}\r\n        for template in self.templates.values():\r\n            counts[template.category] = counts.get(template.category, 0) + 1\r\n        return counts\r\n    \r\n    def _get_most_used_templates(self, limit: int = 5) -> List[Dict]:\r\n        \"\"\"Get most frequently used templates.\"\"\"\r\n        sorted_templates = sorted(\r\n            self.templates.values(),\r\n            key=lambda t: t.usage_count,\r\n            reverse=True\r\n        )\r\n        return [\r\n            {\"name\": t.name, \"usage_count\": t.usage_count, \"category\": t.category}\r\n            for t in sorted_templates[:limit]\r\n    \r\n            def generate_prompt(\r\n                self,\r\n                query: str,\r\n                task_type: Optional[str] = None,\r\n                template_name: Optional[str] = None,\r\n                **kwargs\r\n            ) -> Dict[str, Any]:\r\n                \"\"\"\r\n                Generate a structured prompt for a query.\r\n        \r\n                Args:\r\n                    query: The user query\r\n                    task_type: Type of task (architectural, structural, etc.)\r\n                    template_name: Optional specific template to use\r\n                    **kwargs: Additional parameters for template\r\n        \r\n                Returns:\r\n                    Dictionary with prompt and metadata\r\n                \"\"\"\r\n                # Select template\r\n                if template_name and template_name in self.templates:\r\n                    template = self.templates[template_name]\r\n                elif task_type:\r\n                    # Try to find template by task type\r\n                    category_map = {\r\n                        \"architectural\": \"arch_calculation\",\r\n                        \"structural\": \"technical_analysis\",\r\n                        \"code\": \"code_generation\",\r\n                        \"design\": \"design_review\"\r\n                    }\r\n                    template_name = category_map.get(task_type.lower(), \"technical_analysis\")\r\n                    template = self.templates.get(template_name)\r\n                else:\r\n                    template = None\r\n        \r\n                # Generate prompt\r\n                if template:\r\n                    try:\r\n                        # Fill template with query and kwargs\r\n                        template_vars = {k: kwargs.get(k, query) for k in template.variables}\r\n                        if \"task\" in template_vars and template_vars[\"task\"] == query:\r\n                            template_vars[\"task\"] = query\r\n                        prompt = template.format(**template_vars)\r\n                    except Exception as e:\r\n                        # Fallback if template fails\r\n                        prompt = f\"Task: {query}\\n\\nProvide a detailed response:\"\r\n                else:\r\n                    # Simple prompt without template\r\n                    prompt = f\"Task: {query}\\n\\nProvide a detailed, structured response:\"\r\n        \r\n                return {\r\n                    \"status\": \"success\",\r\n                    \"prompt\": prompt,\r\n                    \"template_used\": template.name if template else \"default\",\r\n                    \"prompt_length\": len(prompt),\r\n                    \"query\": query\r\n                }\r\n        ]\r\n\r\n\r\n# Global instance\r\nprompt_engineering_manager = PromptEngineeringManager()\r\n",
    "format": "py"
  },
  {
    "timestamp": "2025-11-21T22:36:25.383Z",
    "fileName": "cad3d\\super_ai\\prompt_engineering.py",
    "content": "\"\"\"\r\nPrompt Engineering & Instruction Tuning Module for KURDO-AI\r\nThird complementary training method alongside Fine-Tuning and LoRA\r\n\r\nThis module provides:\r\n- Prompt templates and optimization\r\n- Few-shot learning without training\r\n- Instruction tuning strategies\r\n- System prompt caching (Anthropic style)\r\n- Prompt chaining and composition\r\n- Zero-shot and few-shot techniques\r\n\"\"\"\r\n\r\nimport logging\r\nfrom typing import Dict, List, Optional, Any, Tuple\r\nfrom datetime import datetime\r\nimport json\r\nimport os\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\nclass PromptTemplate:\r\n    \"\"\"A reusable prompt template with variables.\"\"\"\r\n    \r\n    def __init__(self, name: str, template: str, variables: List[str], category: str = \"general\"):\r\n        self.name = name\r\n        self.template = template\r\n        self.variables = variables\r\n        self.category = category\r\n        self.usage_count = 0\r\n        self.created_at = datetime.now().isoformat()\r\n    \r\n    def format(self, **kwargs) -> str:\r\n        \"\"\"Format the template with given variables.\"\"\"\r\n        self.usage_count += 1\r\n        return self.template.format(**kwargs)\r\n    \r\n    def to_dict(self) -> dict:\r\n        \"\"\"Convert to dictionary.\"\"\"\r\n        return {\r\n            \"name\": self.name,\r\n            \"template\": self.template,\r\n            \"variables\": self.variables,\r\n            \"category\": self.category,\r\n            \"usage_count\": self.usage_count,\r\n            \"created_at\": self.created_at\r\n        }\r\n\r\n\r\nclass InstructionSet:\r\n    \"\"\"A set of instructions for task-specific behavior.\"\"\"\r\n    \r\n    def __init__(self, name: str, instructions: List[str], examples: List[Dict] = None):\r\n        self.name = name\r\n        self.instructions = instructions\r\n        self.examples = examples or []\r\n        self.created_at = datetime.now().isoformat()\r\n    \r\n    def to_prompt(self, include_examples: bool = True, max_examples: int = 5) -> str:\r\n        \"\"\"Convert to a full prompt.\"\"\"\r\n        prompt = \"# Instructions\\n\\n\"\r\n        for i, instruction in enumerate(self.instructions, 1):\r\n            prompt += f\"{i}. {instruction}\\n\"\r\n        \r\n        if include_examples and self.examples:\r\n            prompt += \"\\n# Examples\\n\\n\"\r\n            for i, example in enumerate(self.examples[:max_examples], 1):\r\n                prompt += f\"Example {i}:\\n\"\r\n                if \"input\" in example:\r\n                    prompt += f\"Input: {example['input']}\\n\"\r\n                if \"output\" in example:\r\n                    prompt += f\"Output: {example['output']}\\n\"\r\n                prompt += \"\\n\"\r\n        \r\n        return prompt\r\n\r\n\r\nclass PromptEngineeringManager:\r\n    \"\"\"\r\n    Manages prompt engineering and instruction tuning.\r\n    \r\n    This is a training-free method that relies on:\r\n    - Well-crafted prompts\r\n    - Few-shot learning\r\n    - System instructions\r\n    - Cached examples\r\n    \"\"\"\r\n    \r\n    def __init__(self, storage_dir: str = \"models/prompts\"):\r\n        self.storage_dir = storage_dir\r\n        os.makedirs(storage_dir, exist_ok=True)\r\n        \r\n        self.templates: Dict[str, PromptTemplate] = {}\r\n        self.instruction_sets: Dict[str, InstructionSet] = {}\r\n        self.cached_prompts: Dict[str, str] = {}\r\n        \r\n        # Load built-in templates\r\n        self._initialize_builtin_templates()\r\n        self._initialize_architectural_instructions()\r\n        \r\n        logger.info(\"Prompt Engineering Manager initialized\")\r\n    \r\n    def _initialize_builtin_templates(self):\r\n        \"\"\"Initialize built-in prompt templates.\"\"\"\r\n        \r\n        # Architectural calculation template\r\n        self.add_template(\r\n            name=\"arch_calculation\",\r\n            template=\"\"\"You are KURDO-AI, an expert architectural calculator.\r\n\r\nTask: {task}\r\nGiven: {given_values}\r\nRequired: {required_output}\r\n\r\nShow your calculation steps clearly.\r\nUse appropriate units (metric: meters, square meters, cubic meters).\r\nProvide practical recommendations when relevant.\r\n\r\nAnswer:\"\"\",\r\n            variables=[\"task\", \"given_values\", \"required_output\"],\r\n            category=\"architecture\"\r\n        )\r\n        \r\n        # Code generation template\r\n        self.add_template(\r\n            name=\"code_generation\",\r\n            template=\"\"\"You are KURDO-AI, an expert programmer.\r\n\r\nLanguage: {language}\r\nTask: {task}\r\nRequirements:\r\n{requirements}\r\n\r\nGenerate clean, well-commented code that follows best practices.\r\n\r\nCode:\"\"\",\r\n            variables=[\"language\", \"task\", \"requirements\"],\r\n            category=\"programming\"\r\n        )\r\n        \r\n        # Analysis template\r\n        self.add_template(\r\n            name=\"technical_analysis\",\r\n            template=\"\"\"You are KURDO-AI, a technical analysis expert.\r\n\r\nSubject: {subject}\r\nContext: {context}\r\nAnalysis Type: {analysis_type}\r\n\r\nProvide a detailed, structured analysis with:\r\n1. Key findings\r\n2. Technical details\r\n3. Recommendations\r\n4. Potential issues\r\n\r\nAnalysis:\"\"\",\r\n            variables=[\"subject\", \"context\", \"analysis_type\"],\r\n            category=\"analysis\"\r\n        )\r\n        \r\n        # Design review template\r\n        self.add_template(\r\n            name=\"design_review\",\r\n            template=\"\"\"You are KURDO-AI, an architectural design reviewer.\r\n\r\nProject: {project_name}\r\nDesign Element: {design_element}\r\nStandards: {applicable_standards}\r\n\r\nReview for:\r\n- Code compliance\r\n- Structural integrity\r\n- Practicality\r\n- Cost-effectiveness\r\n- Safety\r\n\r\nReview:\"\"\",\r\n            variables=[\"project_name\", \"design_element\", \"applicable_standards\"],\r\n            category=\"architecture\"\r\n        )\r\n        \r\n        # Translation template\r\n        self.add_template(\r\n            name=\"technical_translation\",\r\n            template=\"\"\"You are KURDO-AI, a technical translator.\r\n\r\nSource Language: {source_lang}\r\nTarget Language: {target_lang}\r\nDomain: {domain}\r\n\r\nTranslate the following technical content accurately, preserving:\r\n- Technical terms\r\n- Measurements and units\r\n- Structural meaning\r\n\r\nText to translate:\r\n{text}\r\n\r\nTranslation:\"\"\",\r\n            variables=[\"source_lang\", \"target_lang\", \"domain\", \"text\"],\r\n            category=\"translation\"\r\n        )\r\n    \r\n    def _initialize_architectural_instructions(self):\r\n        \"\"\"Initialize architectural instruction sets.\"\"\"\r\n        \r\n        # Room calculation instructions\r\n        room_calc_instructions = InstructionSet(\r\n            name=\"room_calculations\",\r\n            instructions=[\r\n                \"Always specify units (meters, square meters, cubic meters)\",\r\n                \"Show calculation steps: formula → substitution → result\",\r\n                \"For area: A = length × width\",\r\n                \"For volume: V = length × width × height\",\r\n                \"Round to 2 decimal places for practical use\",\r\n                \"Provide context (e.g., 'adequate for bedroom', 'requires ventilation')\"\r\n            ],\r\n            examples=[\r\n                {\r\n                    \"input\": \"محاسبه مساحت اتاق 5x4 متر\",\r\n                    \"output\": \"مساحت = طول × عرض\\nمساحت = 5 × 4 = 20 متر مربع\\n\\nاین مساحت برای یک اتاق خواب استاندارد مناسب است.\"\r\n                },\r\n                {\r\n                    \"input\": \"Calculate volume of room 6m × 4m with 2.8m height\",\r\n                    \"output\": \"Volume = length × width × height\\nVolume = 6 × 4 × 2.8 = 67.2 cubic meters\\n\\nThis volume requires adequate ventilation for residential use.\"\r\n                }\r\n            ]\r\n        )\r\n        self.add_instruction_set(room_calc_instructions)\r\n        \r\n        # Material estimation instructions\r\n        material_instructions = InstructionSet(\r\n            name=\"material_estimation\",\r\n            instructions=[\r\n                \"State standard ratios (e.g., 60 bricks per square meter)\",\r\n                \"Calculate base requirement first\",\r\n                \"Add 5-10% waste factor\",\r\n                \"Provide practical ordering advice\",\r\n                \"Consider standard package sizes\"\r\n            ],\r\n            examples=[\r\n                {\r\n                    \"input\": \"چند آجر برای دیوار 10 متری با ارتفاع 3 متر؟\",\r\n                    \"output\": \"مساحت دیوار = 10 × 3 = 30 متر مربع\\nآجر استاندارد = 60 عدد در هر متر مربع\\nآجر مورد نیاز = 30 × 60 = 1,800 عدد\\nبا ضریب اتلاف 10% = 1,980 عدد\\n\\nتوصیه: سفارش 2,000 آجر\"\r\n                }\r\n            ]\r\n        )\r\n        self.add_instruction_set(material_instructions)\r\n        \r\n        # Code compliance instructions\r\n        code_instructions = InstructionSet(\r\n            name=\"building_codes\",\r\n            instructions=[\r\n                \"Reference specific code sections (e.g., مبحث 19)\",\r\n                \"State minimum and recommended values\",\r\n                \"Explain reasoning behind requirements\",\r\n                \"Mention variations by region if applicable\",\r\n                \"Always prioritize safety\"\r\n            ],\r\n            examples=[\r\n                {\r\n                    \"input\": \"حداقل ارتفاع سقف آپارتمان مسکونی؟\",\r\n                    \"output\": \"طبق مبحث 19 مقررات ملی ساختمان:\\n- اتاق‌های اصلی: حداقل 2.4 متر\\n- راهرو: حداقل 2.1 متر\\n- سرویس‌های بهداشتی: حداقل 2.1 متر\\n\\nتوصیه: ارتفاع 2.6-2.8 متر برای احساس فضای بهتر\"\r\n                }\r\n            ]\r\n        )\r\n        self.add_instruction_set(code_instructions)\r\n    \r\n    def add_template(self, name: str, template: str, variables: List[str], category: str = \"general\") -> PromptTemplate:\r\n        \"\"\"Add a new prompt template.\"\"\"\r\n        pt = PromptTemplate(name, template, variables, category)\r\n        self.templates[name] = pt\r\n        self._save_template(pt)\r\n        logger.info(f\"Added template: {name}\")\r\n        return pt\r\n    \r\n    def add_instruction_set(self, instruction_set: InstructionSet):\r\n        \"\"\"Add a new instruction set.\"\"\"\r\n        self.instruction_sets[instruction_set.name] = instruction_set\r\n        logger.info(f\"Added instruction set: {instruction_set.name}\")\r\n    \r\n    def get_template(self, name: str) -> Optional[PromptTemplate]:\r\n        \"\"\"Get a template by name.\"\"\"\r\n        return self.templates.get(name)\r\n    \r\n    def list_templates(self, category: Optional[str] = None) -> List[str]:\r\n        \"\"\"List all templates, optionally filtered by category.\"\"\"\r\n        if category:\r\n            return [name for name, tmpl in self.templates.items() if tmpl.category == category]\r\n        return list(self.templates.keys())\r\n    \r\n    def create_few_shot_prompt(\r\n        self,\r\n        task_description: str,\r\n        examples: List[Dict[str, str]],\r\n        current_input: str,\r\n        max_examples: int = 5,\r\n        include_reasoning: bool = False\r\n    ) -> str:\r\n        \"\"\"\r\n        Create a few-shot learning prompt.\r\n        \r\n        Args:\r\n            task_description: What the AI should do\r\n            examples: List of {\"input\": \"...\", \"output\": \"...\"}\r\n            current_input: The new input to process\r\n            max_examples: Maximum number of examples to include\r\n            include_reasoning: Include chain-of-thought reasoning\r\n        \r\n        Returns:\r\n            Formatted few-shot prompt\r\n        \"\"\"\r\n        prompt = f\"# Task\\n{task_description}\\n\\n\"\r\n        \r\n        if include_reasoning:\r\n            prompt += \"Show your reasoning step-by-step.\\n\\n\"\r\n        \r\n        prompt += \"# Examples\\n\\n\"\r\n        \r\n        for i, example in enumerate(examples[:max_examples], 1):\r\n            prompt += f\"Example {i}:\\n\"\r\n            prompt += f\"Input: {example['input']}\\n\"\r\n            \r\n            if include_reasoning and \"reasoning\" in example:\r\n                prompt += f\"Reasoning: {example['reasoning']}\\n\"\r\n            \r\n            prompt += f\"Output: {example['output']}\\n\\n\"\r\n        \r\n        prompt += \"# Your Turn\\n\\n\"\r\n        prompt += f\"Input: {current_input}\\n\"\r\n        \r\n        if include_reasoning:\r\n            prompt += \"Reasoning: \"\r\n        else:\r\n            prompt += \"Output: \"\r\n        \r\n        return prompt\r\n    \r\n    def create_chain_of_thought_prompt(\r\n        self,\r\n        problem: str,\r\n        domain: str = \"general\"\r\n    ) -> str:\r\n        \"\"\"\r\n        Create a chain-of-thought prompt for complex reasoning.\r\n        \r\n        Args:\r\n            problem: The problem to solve\r\n            domain: Problem domain\r\n        \r\n        Returns:\r\n            CoT prompt\r\n        \"\"\"\r\n        prompt = f\"\"\"You are KURDO-AI, an expert in {domain}.\r\n\r\nProblem: {problem}\r\n\r\nSolve this step-by-step:\r\n1. Understand: What is being asked?\r\n2. Identify: What information do we have?\r\n3. Plan: What approach should we use?\r\n4. Calculate: Work through the solution\r\n5. Verify: Does the answer make sense?\r\n6. Conclude: State the final answer clearly\r\n\r\nLet's work through this:\r\n\r\n\"\"\"\r\n        return prompt\r\n    \r\n    def create_role_based_prompt(\r\n        self,\r\n        role: str,\r\n        expertise: List[str],\r\n        task: str,\r\n        constraints: Optional[List[str]] = None\r\n    ) -> str:\r\n        \"\"\"\r\n        Create a role-based prompt.\r\n        \r\n        Args:\r\n            role: AI role (e.g., \"structural engineer\")\r\n            expertise: List of expertise areas\r\n            task: The task to perform\r\n            constraints: Optional constraints\r\n        \r\n        Returns:\r\n            Role-based prompt\r\n        \"\"\"\r\n        prompt = f\"You are KURDO-AI, a professional {role}.\\n\\n\"\r\n        prompt += \"Your expertise includes:\\n\"\r\n        for exp in expertise:\r\n            prompt += f\"- {exp}\\n\"\r\n        prompt += \"\\n\"\r\n        \r\n        if constraints:\r\n            prompt += \"Important constraints:\\n\"\r\n            for constraint in constraints:\r\n                prompt += f\"- {constraint}\\n\"\r\n            prompt += \"\\n\"\r\n        \r\n        prompt += f\"Task: {task}\\n\\n\"\r\n        prompt += \"Provide a professional, detailed response:\\n\\n\"\r\n        \r\n        return prompt\r\n    \r\n    def create_cached_system_prompt(\r\n        self,\r\n        system_role: str,\r\n        training_examples: List[Dict],\r\n        max_examples: int = 20\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Create a cached system prompt (Anthropic style).\r\n        \r\n        This is cost-effective for repeated use with similar tasks.\r\n        \r\n        Args:\r\n            system_role: System role description\r\n            training_examples: Examples to cache\r\n            max_examples: Maximum examples to include\r\n        \r\n        Returns:\r\n            Cached prompt structure\r\n        \"\"\"\r\n        cached_content = f\"System Role: {system_role}\\n\\n\"\r\n        cached_content += \"# Training Examples\\n\\n\"\r\n        cached_content += \"Learn from these examples:\\n\\n\"\r\n        \r\n        for i, example in enumerate(training_examples[:max_examples], 1):\r\n            cached_content += f\"Example {i}:\\n\"\r\n            if \"input\" in example:\r\n                cached_content += f\"Q: {example['input']}\\n\"\r\n            elif \"prompt\" in example:\r\n                cached_content += f\"Q: {example['prompt']}\\n\"\r\n            \r\n            if \"output\" in example:\r\n                cached_content += f\"A: {example['output']}\\n\"\r\n            elif \"completion\" in example:\r\n                cached_content += f\"A: {example['completion']}\\n\"\r\n            cached_content += \"\\n\"\r\n        \r\n        cached_content += \"Now respond to user queries following these patterns.\\n\"\r\n        \r\n        cache_id = f\"cached_prompt_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\r\n        self.cached_prompts[cache_id] = cached_content\r\n        \r\n        return {\r\n            \"cache_id\": cache_id,\r\n            \"cached_content\": cached_content,\r\n            \"num_examples\": min(len(training_examples), max_examples),\r\n            \"estimated_tokens\": len(cached_content.split()),\r\n            \"usage\": \"Use this cached content as system message in API calls\"\r\n        }\r\n    \r\n    def optimize_prompt(\r\n        self,\r\n        original_prompt: str,\r\n        optimization_strategy: str = \"concise\"\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Optimize a prompt for better performance.\r\n        \r\n        Strategies:\r\n        - concise: Remove redundancy\r\n        - detailed: Add more context\r\n        - structured: Improve formatting\r\n        - directive: Make instructions clearer\r\n        \r\n        Args:\r\n            original_prompt: The prompt to optimize\r\n            optimization_strategy: Strategy to use\r\n        \r\n        Returns:\r\n            Optimized prompt and metadata\r\n        \"\"\"\r\n        optimizations = {\r\n            \"concise\": self._optimize_concise,\r\n            \"detailed\": self._optimize_detailed,\r\n            \"structured\": self._optimize_structured,\r\n            \"directive\": self._optimize_directive\r\n        }\r\n        \r\n        if optimization_strategy not in optimizations:\r\n            return {\r\n                \"status\": \"error\",\r\n                \"message\": f\"Unknown strategy: {optimization_strategy}\",\r\n                \"available_strategies\": list(optimizations.keys())\r\n            }\r\n        \r\n        optimized = optimizations[optimization_strategy](original_prompt)\r\n        \r\n        return {\r\n            \"original\": original_prompt,\r\n            \"optimized\": optimized,\r\n            \"strategy\": optimization_strategy,\r\n            \"original_length\": len(original_prompt),\r\n            \"optimized_length\": len(optimized),\r\n            \"reduction\": f\"{(1 - len(optimized) / len(original_prompt)) * 100:.1f}%\"\r\n        }\r\n    \r\n    def _optimize_concise(self, prompt: str) -> str:\r\n        \"\"\"Make prompt more concise.\"\"\"\r\n        # Remove excessive whitespace\r\n        lines = [line.strip() for line in prompt.split('\\n') if line.strip()]\r\n        return '\\n'.join(lines)\r\n    \r\n    def _optimize_detailed(self, prompt: str) -> str:\r\n        \"\"\"Add more detail to prompt.\"\"\"\r\n        detailed = f\"\"\"Task Context:\r\n{prompt}\r\n\r\nRequirements:\r\n- Be accurate and precise\r\n- Show your work/reasoning\r\n- Use appropriate units and formatting\r\n- Provide practical recommendations\r\n\r\nResponse:\"\"\"\r\n        return detailed\r\n    \r\n    def _optimize_structured(self, prompt: str) -> str:\r\n        \"\"\"Improve prompt structure.\"\"\"\r\n        structured = f\"\"\"# Task\r\n{prompt}\r\n\r\n# Instructions\r\n1. Analyze the requirements carefully\r\n2. Provide a structured response\r\n3. Include relevant details and examples\r\n4. Format output clearly\r\n\r\n# Response\r\n\"\"\"\r\n        return structured\r\n    \r\n    def _optimize_directive(self, prompt: str) -> str:\r\n        \"\"\"Make instructions more directive.\"\"\"\r\n        directive = f\"\"\"INSTRUCTION: {prompt}\r\n\r\nYou must:\r\n- Follow the instruction exactly\r\n- Provide complete information\r\n- Use clear, professional language\r\n- Format output appropriately\r\n\r\nBEGIN RESPONSE:\r\n\"\"\"\r\n        return directive\r\n    \r\n    def compare_with_training_methods(self) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Compare prompt engineering with other training methods.\r\n        \r\n        Returns:\r\n            Detailed comparison\r\n        \"\"\"\r\n        return {\r\n            \"prompt_engineering\": {\r\n                \"type\": \"Training-Free\",\r\n                \"setup_time\": \"Minutes\",\r\n                \"cost\": \"$0 (inference only)\",\r\n                \"gpu_required\": False,\r\n                \"quality\": \"Good (depends on prompt quality)\",\r\n                \"flexibility\": \"Very High\",\r\n                \"best_for\": [\r\n                    \"Quick prototypes\",\r\n                    \"No training data\",\r\n                    \"Rapid iteration\",\r\n                    \"Zero-shot tasks\",\r\n                    \"Cost-sensitive applications\"\r\n                ],\r\n                \"limitations\": [\r\n                    \"Token limits (context window)\",\r\n                    \"Repetitive examples increase cost\",\r\n                    \"Less consistent than fine-tuning\",\r\n                    \"Requires prompt engineering skills\"\r\n                ],\r\n                \"techniques\": [\r\n                    \"Zero-shot prompting\",\r\n                    \"Few-shot learning\",\r\n                    \"Chain-of-thought\",\r\n                    \"Role-based prompts\",\r\n                    \"Instruction tuning\",\r\n                    \"Prompt caching\"\r\n                ]\r\n            },\r\n            \"fine_tuning\": {\r\n                \"type\": \"Full Training\",\r\n                \"setup_time\": \"Hours to Days\",\r\n                \"cost\": \"$10-100+\",\r\n                \"gpu_required\": True,\r\n                \"quality\": \"Excellent\",\r\n                \"flexibility\": \"Low (requires retraining)\",\r\n                \"best_for\": [\r\n                    \"Production deployments\",\r\n                    \"Consistent behavior\",\r\n                    \"Large-scale applications\",\r\n                    \"Specialized domains\"\r\n                ]\r\n            },\r\n            \"lora\": {\r\n                \"type\": \"Parameter-Efficient Training\",\r\n                \"setup_time\": \"30min-3hours\",\r\n                \"cost\": \"$0 (local)\",\r\n                \"gpu_required\": True,\r\n                \"quality\": \"Very Good\",\r\n                \"flexibility\": \"Medium (multiple adapters)\",\r\n                \"best_for\": [\r\n                    \"Multiple tasks\",\r\n                    \"Limited GPU\",\r\n                    \"Fast iteration\",\r\n                    \"Cost-effective training\"\r\n                ]\r\n            },\r\n            \"recommendation\": {\r\n                \"use_prompt_engineering_when\": [\r\n                    \"No training data available\",\r\n                    \"Need immediate results\",\r\n                    \"Budget is limited\",\r\n                    \"Task changes frequently\",\r\n                    \"Prototyping phase\"\r\n                ],\r\n                \"use_fine_tuning_when\": [\r\n                    \"Have quality training data (500+ examples)\",\r\n                    \"Need consistent behavior\",\r\n                    \"Production deployment\",\r\n                    \"Budget allows\"\r\n                ],\r\n                \"use_lora_when\": [\r\n                    \"Have training data (50-500 examples)\",\r\n                    \"Need multiple task-specific models\",\r\n                    \"Limited GPU memory\",\r\n                    \"Want fast training\"\r\n                ],\r\n                \"hybrid_approach\": [\r\n                    \"Start with prompt engineering for prototyping\",\r\n                    \"Collect real-world data\",\r\n                    \"Train LoRA adapter for common tasks\",\r\n                    \"Use prompt engineering for edge cases\",\r\n                    \"Fall back to fine-tuning for production\"\r\n                ]\r\n            }\r\n        }\r\n    \r\n    def _save_template(self, template: PromptTemplate):\r\n        \"\"\"Save template to disk.\"\"\"\r\n        filepath = os.path.join(self.storage_dir, f\"{template.name}.json\")\r\n        with open(filepath, 'w', encoding='utf-8') as f:\r\n            json.dump(template.to_dict(), f, indent=2, ensure_ascii=False)\r\n    \r\n    def get_statistics(self) -> Dict[str, Any]:\r\n        \"\"\"Get usage statistics.\"\"\"\r\n        return {\r\n            \"total_templates\": len(self.templates),\r\n            \"templates_by_category\": self._count_by_category(),\r\n            \"total_instruction_sets\": len(self.instruction_sets),\r\n            \"cached_prompts\": len(self.cached_prompts),\r\n            \"most_used_templates\": self._get_most_used_templates(5)\r\n        }\r\n    \r\n    def _count_by_category(self) -> Dict[str, int]:\r\n        \"\"\"Count templates by category.\"\"\"\r\n        counts = {}\r\n        for template in self.templates.values():\r\n            counts[template.category] = counts.get(template.category, 0) + 1\r\n        return counts\r\n    \r\n    def _get_most_used_templates(self, limit: int = 5) -> List[Dict]:\r\n        \"\"\"Get most frequently used templates.\"\"\"\r\n        sorted_templates = sorted(\r\n            self.templates.values(),\r\n            key=lambda t: t.usage_count,\r\n            reverse=True\r\n        )\r\n        return [\r\n            {\"name\": t.name, \"usage_count\": t.usage_count, \"category\": t.category}\r\n            for t in sorted_templates[:limit]\r\n    \r\n            def generate_prompt(\r\n                self,\r\n                query: str,\r\n                task_type: Optional[str] = None,\r\n                template_name: Optional[str] = None,\r\n                **kwargs\r\n            ) -> Dict[str, Any]:\r\n                \"\"\"\r\n                Generate a structured prompt for a query.\r\n        \r\n                Args:\r\n                    query: The user query\r\n                    task_type: Type of task (architectural, structural, etc.)\r\n                    template_name: Optional specific template to use\r\n                    **kwargs: Additional parameters for template\r\n        \r\n                Returns:\r\n                    Dictionary with prompt and metadata\r\n                \"\"\"\r\n                # Select template\r\n                if template_name and template_name in self.templates:\r\n                    template = self.templates[template_name]\r\n                elif task_type:\r\n                    # Try to find template by task type\r\n                    category_map = {\r\n                        \"architectural\": \"arch_calculation\",\r\n                        \"structural\": \"technical_analysis\",\r\n                        \"code\": \"code_generation\",\r\n                        \"design\": \"design_review\"\r\n                    }\r\n                    template_name = category_map.get(task_type.lower(), \"technical_analysis\")\r\n                    template = self.templates.get(template_name)\r\n                else:\r\n                    template = None\r\n        \r\n                # Generate prompt\r\n                if template:\r\n                    try:\r\n                        # Fill template with query and kwargs\r\n                        template_vars = {k: kwargs.get(k, query) for k in template.variables}\r\n                        if \"task\" in template_vars and template_vars[\"task\"] == query:\r\n                            template_vars[\"task\"] = query\r\n                        prompt = template.format(**template_vars)\r\n                    except Exception as e:\r\n                        # Fallback if template fails\r\n                        prompt = f\"Task: {query}\\n\\nProvide a detailed response:\"\r\n                else:\r\n                    # Simple prompt without template\r\n                    prompt = f\"Task: {query}\\n\\nProvide a detailed, structured response:\"\r\n        \r\n                return {\r\n                    \"status\": \"success\",\r\n                    \"prompt\": prompt,\r\n                    \"template_used\": template.name if template else \"default\",\r\n                    \"prompt_length\": len(prompt),\r\n                    \"query\": query\r\n                }\r\n        ]\r\n\r\n\r\n# Global instance\r\nprompt_engineering_manager = PromptEngineeringManager()\r\n",
    "format": "py"
  },
  {
    "timestamp": "2025-11-21T22:37:40.843Z",
    "fileName": "cad3d\\super_ai\\prompt_engineering.py",
    "content": "\"\"\"\r\nPrompt Engineering & Instruction Tuning Module for KURDO-AI\r\nThird complementary training method alongside Fine-Tuning and LoRA\r\n\r\nThis module provides:\r\n- Prompt templates and optimization\r\n- Few-shot learning without training\r\n- Instruction tuning strategies\r\n- System prompt caching (Anthropic style)\r\n- Prompt chaining and composition\r\n- Zero-shot and few-shot techniques\r\n\"\"\"\r\n\r\nimport logging\r\nfrom typing import Dict, List, Optional, Any, Tuple\r\nfrom datetime import datetime\r\nimport json\r\nimport os\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\nclass PromptTemplate:\r\n    \"\"\"A reusable prompt template with variables.\"\"\"\r\n    \r\n    def __init__(self, name: str, template: str, variables: List[str], category: str = \"general\"):\r\n        self.name = name\r\n        self.template = template\r\n        self.variables = variables\r\n        self.category = category\r\n        self.usage_count = 0\r\n        self.created_at = datetime.now().isoformat()\r\n    \r\n    def format(self, **kwargs) -> str:\r\n        \"\"\"Format the template with given variables.\"\"\"\r\n        self.usage_count += 1\r\n        return self.template.format(**kwargs)\r\n    \r\n    def to_dict(self) -> dict:\r\n        \"\"\"Convert to dictionary.\"\"\"\r\n        return {\r\n            \"name\": self.name,\r\n            \"template\": self.template,\r\n            \"variables\": self.variables,\r\n            \"category\": self.category,\r\n            \"usage_count\": self.usage_count,\r\n            \"created_at\": self.created_at\r\n        }\r\n\r\n\r\nclass InstructionSet:\r\n    \"\"\"A set of instructions for task-specific behavior.\"\"\"\r\n    \r\n    def __init__(self, name: str, instructions: List[str], examples: List[Dict] = None):\r\n        self.name = name\r\n        self.instructions = instructions\r\n        self.examples = examples or []\r\n        self.created_at = datetime.now().isoformat()\r\n    \r\n    def to_prompt(self, include_examples: bool = True, max_examples: int = 5) -> str:\r\n        \"\"\"Convert to a full prompt.\"\"\"\r\n        prompt = \"# Instructions\\n\\n\"\r\n        for i, instruction in enumerate(self.instructions, 1):\r\n            prompt += f\"{i}. {instruction}\\n\"\r\n        \r\n        if include_examples and self.examples:\r\n            prompt += \"\\n# Examples\\n\\n\"\r\n            for i, example in enumerate(self.examples[:max_examples], 1):\r\n                prompt += f\"Example {i}:\\n\"\r\n                if \"input\" in example:\r\n                    prompt += f\"Input: {example['input']}\\n\"\r\n                if \"output\" in example:\r\n                    prompt += f\"Output: {example['output']}\\n\"\r\n                prompt += \"\\n\"\r\n        \r\n        return prompt\r\n\r\n\r\nclass PromptEngineeringManager:\r\n    \"\"\"\r\n    Manages prompt engineering and instruction tuning.\r\n    \r\n    This is a training-free method that relies on:\r\n    - Well-crafted prompts\r\n    - Few-shot learning\r\n    - System instructions\r\n    - Cached examples\r\n    \"\"\"\r\n    \r\n    def __init__(self, storage_dir: str = \"models/prompts\"):\r\n        self.storage_dir = storage_dir\r\n        os.makedirs(storage_dir, exist_ok=True)\r\n        \r\n        self.templates: Dict[str, PromptTemplate] = {}\r\n        self.instruction_sets: Dict[str, InstructionSet] = {}\r\n        self.cached_prompts: Dict[str, str] = {}\r\n        \r\n        # Load built-in templates\r\n        self._initialize_builtin_templates()\r\n        self._initialize_architectural_instructions()\r\n        \r\n        logger.info(\"Prompt Engineering Manager initialized\")\r\n    \r\n    def _initialize_builtin_templates(self):\r\n        \"\"\"Initialize built-in prompt templates.\"\"\"\r\n        \r\n        # Architectural calculation template\r\n        self.add_template(\r\n            name=\"arch_calculation\",\r\n            template=\"\"\"You are KURDO-AI, an expert architectural calculator.\r\n\r\nTask: {task}\r\nGiven: {given_values}\r\nRequired: {required_output}\r\n\r\nShow your calculation steps clearly.\r\nUse appropriate units (metric: meters, square meters, cubic meters).\r\nProvide practical recommendations when relevant.\r\n\r\nAnswer:\"\"\",\r\n            variables=[\"task\", \"given_values\", \"required_output\"],\r\n            category=\"architecture\"\r\n        )\r\n        \r\n        # Code generation template\r\n        self.add_template(\r\n            name=\"code_generation\",\r\n            template=\"\"\"You are KURDO-AI, an expert programmer.\r\n\r\nLanguage: {language}\r\nTask: {task}\r\nRequirements:\r\n{requirements}\r\n\r\nGenerate clean, well-commented code that follows best practices.\r\n\r\nCode:\"\"\",\r\n            variables=[\"language\", \"task\", \"requirements\"],\r\n            category=\"programming\"\r\n        )\r\n        \r\n        # Analysis template\r\n        self.add_template(\r\n            name=\"technical_analysis\",\r\n            template=\"\"\"You are KURDO-AI, a technical analysis expert.\r\n\r\nSubject: {subject}\r\nContext: {context}\r\nAnalysis Type: {analysis_type}\r\n\r\nProvide a detailed, structured analysis with:\r\n1. Key findings\r\n2. Technical details\r\n3. Recommendations\r\n4. Potential issues\r\n\r\nAnalysis:\"\"\",\r\n            variables=[\"subject\", \"context\", \"analysis_type\"],\r\n            category=\"analysis\"\r\n        )\r\n        \r\n        # Design review template\r\n        self.add_template(\r\n            name=\"design_review\",\r\n            template=\"\"\"You are KURDO-AI, an architectural design reviewer.\r\n\r\nProject: {project_name}\r\nDesign Element: {design_element}\r\nStandards: {applicable_standards}\r\n\r\nReview for:\r\n- Code compliance\r\n- Structural integrity\r\n- Practicality\r\n- Cost-effectiveness\r\n- Safety\r\n\r\nReview:\"\"\",\r\n            variables=[\"project_name\", \"design_element\", \"applicable_standards\"],\r\n            category=\"architecture\"\r\n        )\r\n        \r\n        # Translation template\r\n        self.add_template(\r\n            name=\"technical_translation\",\r\n            template=\"\"\"You are KURDO-AI, a technical translator.\r\n\r\nSource Language: {source_lang}\r\nTarget Language: {target_lang}\r\nDomain: {domain}\r\n\r\nTranslate the following technical content accurately, preserving:\r\n- Technical terms\r\n- Measurements and units\r\n- Structural meaning\r\n\r\nText to translate:\r\n{text}\r\n\r\nTranslation:\"\"\",\r\n            variables=[\"source_lang\", \"target_lang\", \"domain\", \"text\"],\r\n            category=\"translation\"\r\n        )\r\n    \r\n    def _initialize_architectural_instructions(self):\r\n        \"\"\"Initialize architectural instruction sets.\"\"\"\r\n        \r\n        # Room calculation instructions\r\n        room_calc_instructions = InstructionSet(\r\n            name=\"room_calculations\",\r\n            instructions=[\r\n                \"Always specify units (meters, square meters, cubic meters)\",\r\n                \"Show calculation steps: formula → substitution → result\",\r\n                \"For area: A = length × width\",\r\n                \"For volume: V = length × width × height\",\r\n                \"Round to 2 decimal places for practical use\",\r\n                \"Provide context (e.g., 'adequate for bedroom', 'requires ventilation')\"\r\n            ],\r\n            examples=[\r\n                {\r\n                    \"input\": \"محاسبه مساحت اتاق 5x4 متر\",\r\n                    \"output\": \"مساحت = طول × عرض\\nمساحت = 5 × 4 = 20 متر مربع\\n\\nاین مساحت برای یک اتاق خواب استاندارد مناسب است.\"\r\n                },\r\n                {\r\n                    \"input\": \"Calculate volume of room 6m × 4m with 2.8m height\",\r\n                    \"output\": \"Volume = length × width × height\\nVolume = 6 × 4 × 2.8 = 67.2 cubic meters\\n\\nThis volume requires adequate ventilation for residential use.\"\r\n                }\r\n            ]\r\n        )\r\n        self.add_instruction_set(room_calc_instructions)\r\n        \r\n        # Material estimation instructions\r\n        material_instructions = InstructionSet(\r\n            name=\"material_estimation\",\r\n            instructions=[\r\n                \"State standard ratios (e.g., 60 bricks per square meter)\",\r\n                \"Calculate base requirement first\",\r\n                \"Add 5-10% waste factor\",\r\n                \"Provide practical ordering advice\",\r\n                \"Consider standard package sizes\"\r\n            ],\r\n            examples=[\r\n                {\r\n                    \"input\": \"چند آجر برای دیوار 10 متری با ارتفاع 3 متر؟\",\r\n                    \"output\": \"مساحت دیوار = 10 × 3 = 30 متر مربع\\nآجر استاندارد = 60 عدد در هر متر مربع\\nآجر مورد نیاز = 30 × 60 = 1,800 عدد\\nبا ضریب اتلاف 10% = 1,980 عدد\\n\\nتوصیه: سفارش 2,000 آجر\"\r\n                }\r\n            ]\r\n        )\r\n        self.add_instruction_set(material_instructions)\r\n        \r\n        # Code compliance instructions\r\n        code_instructions = InstructionSet(\r\n            name=\"building_codes\",\r\n            instructions=[\r\n                \"Reference specific code sections (e.g., مبحث 19)\",\r\n                \"State minimum and recommended values\",\r\n                \"Explain reasoning behind requirements\",\r\n                \"Mention variations by region if applicable\",\r\n                \"Always prioritize safety\"\r\n            ],\r\n            examples=[\r\n                {\r\n                    \"input\": \"حداقل ارتفاع سقف آپارتمان مسکونی؟\",\r\n                    \"output\": \"طبق مبحث 19 مقررات ملی ساختمان:\\n- اتاق‌های اصلی: حداقل 2.4 متر\\n- راهرو: حداقل 2.1 متر\\n- سرویس‌های بهداشتی: حداقل 2.1 متر\\n\\nتوصیه: ارتفاع 2.6-2.8 متر برای احساس فضای بهتر\"\r\n                }\r\n            ]\r\n        )\r\n        self.add_instruction_set(code_instructions)\r\n    \r\n    def add_template(self, name: str, template: str, variables: List[str], category: str = \"general\") -> PromptTemplate:\r\n        \"\"\"Add a new prompt template.\"\"\"\r\n        pt = PromptTemplate(name, template, variables, category)\r\n        self.templates[name] = pt\r\n        self._save_template(pt)\r\n        logger.info(f\"Added template: {name}\")\r\n        return pt\r\n    \r\n    def add_instruction_set(self, instruction_set: InstructionSet):\r\n        \"\"\"Add a new instruction set.\"\"\"\r\n        self.instruction_sets[instruction_set.name] = instruction_set\r\n        logger.info(f\"Added instruction set: {instruction_set.name}\")\r\n    \r\n    def get_template(self, name: str) -> Optional[PromptTemplate]:\r\n        \"\"\"Get a template by name.\"\"\"\r\n        return self.templates.get(name)\r\n    \r\n    def list_templates(self, category: Optional[str] = None) -> List[str]:\r\n        \"\"\"List all templates, optionally filtered by category.\"\"\"\r\n        if category:\r\n            return [name for name, tmpl in self.templates.items() if tmpl.category == category]\r\n        return list(self.templates.keys())\r\n    \r\n    def create_few_shot_prompt(\r\n        self,\r\n        task_description: str,\r\n        examples: List[Dict[str, str]],\r\n        current_input: str,\r\n        max_examples: int = 5,\r\n        include_reasoning: bool = False\r\n    ) -> str:\r\n        \"\"\"\r\n        Create a few-shot learning prompt.\r\n        \r\n        Args:\r\n            task_description: What the AI should do\r\n            examples: List of {\"input\": \"...\", \"output\": \"...\"}\r\n            current_input: The new input to process\r\n            max_examples: Maximum number of examples to include\r\n            include_reasoning: Include chain-of-thought reasoning\r\n        \r\n        Returns:\r\n            Formatted few-shot prompt\r\n        \"\"\"\r\n        prompt = f\"# Task\\n{task_description}\\n\\n\"\r\n        \r\n        if include_reasoning:\r\n            prompt += \"Show your reasoning step-by-step.\\n\\n\"\r\n        \r\n        prompt += \"# Examples\\n\\n\"\r\n        \r\n        for i, example in enumerate(examples[:max_examples], 1):\r\n            prompt += f\"Example {i}:\\n\"\r\n            prompt += f\"Input: {example['input']}\\n\"\r\n            \r\n            if include_reasoning and \"reasoning\" in example:\r\n                prompt += f\"Reasoning: {example['reasoning']}\\n\"\r\n            \r\n            prompt += f\"Output: {example['output']}\\n\\n\"\r\n        \r\n        prompt += \"# Your Turn\\n\\n\"\r\n        prompt += f\"Input: {current_input}\\n\"\r\n        \r\n        if include_reasoning:\r\n            prompt += \"Reasoning: \"\r\n        else:\r\n            prompt += \"Output: \"\r\n        \r\n        return prompt\r\n    \r\n    def create_chain_of_thought_prompt(\r\n        self,\r\n        problem: str,\r\n        domain: str = \"general\"\r\n    ) -> str:\r\n        \"\"\"\r\n        Create a chain-of-thought prompt for complex reasoning.\r\n        \r\n        Args:\r\n            problem: The problem to solve\r\n            domain: Problem domain\r\n        \r\n        Returns:\r\n            CoT prompt\r\n        \"\"\"\r\n        prompt = f\"\"\"You are KURDO-AI, an expert in {domain}.\r\n\r\nProblem: {problem}\r\n\r\nSolve this step-by-step:\r\n1. Understand: What is being asked?\r\n2. Identify: What information do we have?\r\n3. Plan: What approach should we use?\r\n4. Calculate: Work through the solution\r\n5. Verify: Does the answer make sense?\r\n6. Conclude: State the final answer clearly\r\n\r\nLet's work through this:\r\n\r\n\"\"\"\r\n        return prompt\r\n    \r\n    def create_role_based_prompt(\r\n        self,\r\n        role: str,\r\n        expertise: List[str],\r\n        task: str,\r\n        constraints: Optional[List[str]] = None\r\n    ) -> str:\r\n        \"\"\"\r\n        Create a role-based prompt.\r\n        \r\n        Args:\r\n            role: AI role (e.g., \"structural engineer\")\r\n            expertise: List of expertise areas\r\n            task: The task to perform\r\n            constraints: Optional constraints\r\n        \r\n        Returns:\r\n            Role-based prompt\r\n        \"\"\"\r\n        prompt = f\"You are KURDO-AI, a professional {role}.\\n\\n\"\r\n        prompt += \"Your expertise includes:\\n\"\r\n        for exp in expertise:\r\n            prompt += f\"- {exp}\\n\"\r\n        prompt += \"\\n\"\r\n        \r\n        if constraints:\r\n            prompt += \"Important constraints:\\n\"\r\n            for constraint in constraints:\r\n                prompt += f\"- {constraint}\\n\"\r\n            prompt += \"\\n\"\r\n        \r\n        prompt += f\"Task: {task}\\n\\n\"\r\n        prompt += \"Provide a professional, detailed response:\\n\\n\"\r\n        \r\n        return prompt\r\n    \r\n    def create_cached_system_prompt(\r\n        self,\r\n        system_role: str,\r\n        training_examples: List[Dict],\r\n        max_examples: int = 20\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Create a cached system prompt (Anthropic style).\r\n        \r\n        This is cost-effective for repeated use with similar tasks.\r\n        \r\n        Args:\r\n            system_role: System role description\r\n            training_examples: Examples to cache\r\n            max_examples: Maximum examples to include\r\n        \r\n        Returns:\r\n            Cached prompt structure\r\n        \"\"\"\r\n        cached_content = f\"System Role: {system_role}\\n\\n\"\r\n        cached_content += \"# Training Examples\\n\\n\"\r\n        cached_content += \"Learn from these examples:\\n\\n\"\r\n        \r\n        for i, example in enumerate(training_examples[:max_examples], 1):\r\n            cached_content += f\"Example {i}:\\n\"\r\n            if \"input\" in example:\r\n                cached_content += f\"Q: {example['input']}\\n\"\r\n            elif \"prompt\" in example:\r\n                cached_content += f\"Q: {example['prompt']}\\n\"\r\n            \r\n            if \"output\" in example:\r\n                cached_content += f\"A: {example['output']}\\n\"\r\n            elif \"completion\" in example:\r\n                cached_content += f\"A: {example['completion']}\\n\"\r\n            cached_content += \"\\n\"\r\n        \r\n        cached_content += \"Now respond to user queries following these patterns.\\n\"\r\n        \r\n        cache_id = f\"cached_prompt_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\r\n        self.cached_prompts[cache_id] = cached_content\r\n        \r\n        return {\r\n            \"cache_id\": cache_id,\r\n            \"cached_content\": cached_content,\r\n            \"num_examples\": min(len(training_examples), max_examples),\r\n            \"estimated_tokens\": len(cached_content.split()),\r\n            \"usage\": \"Use this cached content as system message in API calls\"\r\n        }\r\n    \r\n    def optimize_prompt(\r\n        self,\r\n        original_prompt: str,\r\n        optimization_strategy: str = \"concise\"\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Optimize a prompt for better performance.\r\n        \r\n        Strategies:\r\n        - concise: Remove redundancy\r\n        - detailed: Add more context\r\n        - structured: Improve formatting\r\n        - directive: Make instructions clearer\r\n        \r\n        Args:\r\n            original_prompt: The prompt to optimize\r\n            optimization_strategy: Strategy to use\r\n        \r\n        Returns:\r\n            Optimized prompt and metadata\r\n        \"\"\"\r\n        optimizations = {\r\n            \"concise\": self._optimize_concise,\r\n            \"detailed\": self._optimize_detailed,\r\n            \"structured\": self._optimize_structured,\r\n            \"directive\": self._optimize_directive\r\n        }\r\n        \r\n        if optimization_strategy not in optimizations:\r\n            return {\r\n                \"status\": \"error\",\r\n                \"message\": f\"Unknown strategy: {optimization_strategy}\",\r\n                \"available_strategies\": list(optimizations.keys())\r\n            }\r\n        \r\n        optimized = optimizations[optimization_strategy](original_prompt)\r\n        \r\n        return {\r\n            \"original\": original_prompt,\r\n            \"optimized\": optimized,\r\n            \"strategy\": optimization_strategy,\r\n            \"original_length\": len(original_prompt),\r\n            \"optimized_length\": len(optimized),\r\n            \"reduction\": f\"{(1 - len(optimized) / len(original_prompt)) * 100:.1f}%\"\r\n        }\r\n    \r\n    def _optimize_concise(self, prompt: str) -> str:\r\n        \"\"\"Make prompt more concise.\"\"\"\r\n        # Remove excessive whitespace\r\n        lines = [line.strip() for line in prompt.split('\\n') if line.strip()]\r\n        return '\\n'.join(lines)\r\n    \r\n    def _optimize_detailed(self, prompt: str) -> str:\r\n        \"\"\"Add more detail to prompt.\"\"\"\r\n        detailed = f\"\"\"Task Context:\r\n{prompt}\r\n\r\nRequirements:\r\n- Be accurate and precise\r\n- Show your work/reasoning\r\n- Use appropriate units and formatting\r\n- Provide practical recommendations\r\n\r\nResponse:\"\"\"\r\n        return detailed\r\n    \r\n    def _optimize_structured(self, prompt: str) -> str:\r\n        \"\"\"Improve prompt structure.\"\"\"\r\n        structured = f\"\"\"# Task\r\n{prompt}\r\n\r\n# Instructions\r\n1. Analyze the requirements carefully\r\n2. Provide a structured response\r\n3. Include relevant details and examples\r\n4. Format output clearly\r\n\r\n# Response\r\n\"\"\"\r\n        return structured\r\n    \r\n    def _optimize_directive(self, prompt: str) -> str:\r\n        \"\"\"Make instructions more directive.\"\"\"\r\n        directive = f\"\"\"INSTRUCTION: {prompt}\r\n\r\nYou must:\r\n- Follow the instruction exactly\r\n- Provide complete information\r\n- Use clear, professional language\r\n- Format output appropriately\r\n\r\nBEGIN RESPONSE:\r\n\"\"\"\r\n        return directive\r\n    \r\n    def compare_with_training_methods(self) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Compare prompt engineering with other training methods.\r\n        \r\n        Returns:\r\n            Detailed comparison\r\n        \"\"\"\r\n        return {\r\n            \"prompt_engineering\": {\r\n                \"type\": \"Training-Free\",\r\n                \"setup_time\": \"Minutes\",\r\n                \"cost\": \"$0 (inference only)\",\r\n                \"gpu_required\": False,\r\n                \"quality\": \"Good (depends on prompt quality)\",\r\n                \"flexibility\": \"Very High\",\r\n                \"best_for\": [\r\n                    \"Quick prototypes\",\r\n                    \"No training data\",\r\n                    \"Rapid iteration\",\r\n                    \"Zero-shot tasks\",\r\n                    \"Cost-sensitive applications\"\r\n                ],\r\n                \"limitations\": [\r\n                    \"Token limits (context window)\",\r\n                    \"Repetitive examples increase cost\",\r\n                    \"Less consistent than fine-tuning\",\r\n                    \"Requires prompt engineering skills\"\r\n                ],\r\n                \"techniques\": [\r\n                    \"Zero-shot prompting\",\r\n                    \"Few-shot learning\",\r\n                    \"Chain-of-thought\",\r\n                    \"Role-based prompts\",\r\n                    \"Instruction tuning\",\r\n                    \"Prompt caching\"\r\n                ]\r\n            },\r\n            \"fine_tuning\": {\r\n                \"type\": \"Full Training\",\r\n                \"setup_time\": \"Hours to Days\",\r\n                \"cost\": \"$10-100+\",\r\n                \"gpu_required\": True,\r\n                \"quality\": \"Excellent\",\r\n                \"flexibility\": \"Low (requires retraining)\",\r\n                \"best_for\": [\r\n                    \"Production deployments\",\r\n                    \"Consistent behavior\",\r\n                    \"Large-scale applications\",\r\n                    \"Specialized domains\"\r\n                ]\r\n            },\r\n            \"lora\": {\r\n                \"type\": \"Parameter-Efficient Training\",\r\n                \"setup_time\": \"30min-3hours\",\r\n                \"cost\": \"$0 (local)\",\r\n                \"gpu_required\": True,\r\n                \"quality\": \"Very Good\",\r\n                \"flexibility\": \"Medium (multiple adapters)\",\r\n                \"best_for\": [\r\n                    \"Multiple tasks\",\r\n                    \"Limited GPU\",\r\n                    \"Fast iteration\",\r\n                    \"Cost-effective training\"\r\n                ]\r\n            },\r\n            \"recommendation\": {\r\n                \"use_prompt_engineering_when\": [\r\n                    \"No training data available\",\r\n                    \"Need immediate results\",\r\n                    \"Budget is limited\",\r\n                    \"Task changes frequently\",\r\n                    \"Prototyping phase\"\r\n                ],\r\n                \"use_fine_tuning_when\": [\r\n                    \"Have quality training data (500+ examples)\",\r\n                    \"Need consistent behavior\",\r\n                    \"Production deployment\",\r\n                    \"Budget allows\"\r\n                ],\r\n                \"use_lora_when\": [\r\n                    \"Have training data (50-500 examples)\",\r\n                    \"Need multiple task-specific models\",\r\n                    \"Limited GPU memory\",\r\n                    \"Want fast training\"\r\n                ],\r\n                \"hybrid_approach\": [\r\n                    \"Start with prompt engineering for prototyping\",\r\n                    \"Collect real-world data\",\r\n                    \"Train LoRA adapter for common tasks\",\r\n                    \"Use prompt engineering for edge cases\",\r\n                    \"Fall back to fine-tuning for production\"\r\n                ]\r\n            }\r\n        }\r\n    \r\n    def _save_template(self, template: PromptTemplate):\r\n        \"\"\"Save template to disk.\"\"\"\r\n        filepath = os.path.join(self.storage_dir, f\"{template.name}.json\")\r\n        with open(filepath, 'w', encoding='utf-8') as f:\r\n            json.dump(template.to_dict(), f, indent=2, ensure_ascii=False)\r\n    \r\n    def get_statistics(self) -> Dict[str, Any]:\r\n        \"\"\"Get usage statistics.\"\"\"\r\n        return {\r\n            \"total_templates\": len(self.templates),\r\n            \"templates_by_category\": self._count_by_category(),\r\n            \"total_instruction_sets\": len(self.instruction_sets),\r\n            \"cached_prompts\": len(self.cached_prompts),\r\n            \"most_used_templates\": self._get_most_used_templates(5)\r\n        }\r\n    \r\n    def _count_by_category(self) -> Dict[str, int]:\r\n        \"\"\"Count templates by category.\"\"\"\r\n        counts = {}\r\n        for template in self.templates.values():\r\n            counts[template.category] = counts.get(template.category, 0) + 1\r\n        return counts\r\n    \r\n    def _get_most_used_templates(self, limit: int = 5) -> List[Dict]:\r\n        \"\"\"Get most frequently used templates.\"\"\"\r\n        sorted_templates = sorted(\r\n            self.templates.values(),\r\n            key=lambda t: t.usage_count,\r\n            reverse=True\r\n        )\r\n        return [\r\n            {\"name\": t.name, \"usage_count\": t.usage_count, \"category\": t.category}\r\n            for t in sorted_templates[:limit]\r\n        ]\r\n\r\n    def generate_prompt(\r\n        self,\r\n        query: str,\r\n        task_type: Optional[str] = None,\r\n        template_name: Optional[str] = None,\r\n        **kwargs\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Generate a structured prompt for a query.\r\n\r\n        Args:\r\n            query: The user query\r\n            task_type: Type of task (architectural, structural, etc.)\r\n            template_name: Optional specific template to use\r\n            **kwargs: Additional parameters for template\r\n\r\n        Returns:\r\n            Dictionary with prompt and metadata\r\n        \"\"\"\r\n        # Select template\r\n        if template_name and template_name in self.templates:\r\n            template = self.templates[template_name]\r\n        elif task_type:\r\n            # Try to find template by task type\r\n            category_map = {\r\n                \"architectural\": \"arch_calculation\",\r\n                \"structural\": \"technical_analysis\",\r\n                \"code\": \"code_generation\",\r\n                \"design\": \"design_review\"\r\n            }\r\n            template_name = category_map.get(task_type.lower(), \"technical_analysis\")\r\n            template = self.templates.get(template_name)\r\n        else:\r\n            template = None\r\n\r\n        # Generate prompt\r\n        if template:\r\n            try:\r\n                # Fill template with query and kwargs\r\n                template_vars = {k: kwargs.get(k, query) for k in template.variables}\r\n                if \"task\" in template_vars and template_vars[\"task\"] == query:\r\n                    template_vars[\"task\"] = query\r\n                prompt = template.format(**template_vars)\r\n            except Exception:\r\n                # Fallback if template fails\r\n                prompt = f\"Task: {query}\\n\\nProvide a detailed response:\"\r\n        else:\r\n            # Simple prompt without template\r\n            prompt = f\"Task: {query}\\n\\nProvide a detailed, structured response:\"\r\n\r\n        return {\r\n            \"status\": \"success\",\r\n            \"prompt\": prompt,\r\n            \"template_used\": template.name if template else \"default\",\r\n            \"prompt_length\": len(prompt),\r\n            \"query\": query\r\n        }\r\n\r\n\r\n# Global instance\r\nprompt_engineering_manager = PromptEngineeringManager()\r\n",
    "format": "py"
  },
  {
    "timestamp": "2025-11-21T22:37:43.821Z",
    "fileName": "cad3d\\super_ai\\prompt_engineering.py",
    "content": "\"\"\"\r\nPrompt Engineering & Instruction Tuning Module for KURDO-AI\r\nThird complementary training method alongside Fine-Tuning and LoRA\r\n\r\nThis module provides:\r\n- Prompt templates and optimization\r\n- Few-shot learning without training\r\n- Instruction tuning strategies\r\n- System prompt caching (Anthropic style)\r\n- Prompt chaining and composition\r\n- Zero-shot and few-shot techniques\r\n\"\"\"\r\n\r\nimport logging\r\nfrom typing import Dict, List, Optional, Any, Tuple\r\nfrom datetime import datetime\r\nimport json\r\nimport os\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\nclass PromptTemplate:\r\n    \"\"\"A reusable prompt template with variables.\"\"\"\r\n    \r\n    def __init__(self, name: str, template: str, variables: List[str], category: str = \"general\"):\r\n        self.name = name\r\n        self.template = template\r\n        self.variables = variables\r\n        self.category = category\r\n        self.usage_count = 0\r\n        self.created_at = datetime.now().isoformat()\r\n    \r\n    def format(self, **kwargs) -> str:\r\n        \"\"\"Format the template with given variables.\"\"\"\r\n        self.usage_count += 1\r\n        return self.template.format(**kwargs)\r\n    \r\n    def to_dict(self) -> dict:\r\n        \"\"\"Convert to dictionary.\"\"\"\r\n        return {\r\n            \"name\": self.name,\r\n            \"template\": self.template,\r\n            \"variables\": self.variables,\r\n            \"category\": self.category,\r\n            \"usage_count\": self.usage_count,\r\n            \"created_at\": self.created_at\r\n        }\r\n\r\n\r\nclass InstructionSet:\r\n    \"\"\"A set of instructions for task-specific behavior.\"\"\"\r\n    \r\n    def __init__(self, name: str, instructions: List[str], examples: List[Dict] = None):\r\n        self.name = name\r\n        self.instructions = instructions\r\n        self.examples = examples or []\r\n        self.created_at = datetime.now().isoformat()\r\n    \r\n    def to_prompt(self, include_examples: bool = True, max_examples: int = 5) -> str:\r\n        \"\"\"Convert to a full prompt.\"\"\"\r\n        prompt = \"# Instructions\\n\\n\"\r\n        for i, instruction in enumerate(self.instructions, 1):\r\n            prompt += f\"{i}. {instruction}\\n\"\r\n        \r\n        if include_examples and self.examples:\r\n            prompt += \"\\n# Examples\\n\\n\"\r\n            for i, example in enumerate(self.examples[:max_examples], 1):\r\n                prompt += f\"Example {i}:\\n\"\r\n                if \"input\" in example:\r\n                    prompt += f\"Input: {example['input']}\\n\"\r\n                if \"output\" in example:\r\n                    prompt += f\"Output: {example['output']}\\n\"\r\n                prompt += \"\\n\"\r\n        \r\n        return prompt\r\n\r\n\r\nclass PromptEngineeringManager:\r\n    \"\"\"\r\n    Manages prompt engineering and instruction tuning.\r\n    \r\n    This is a training-free method that relies on:\r\n    - Well-crafted prompts\r\n    - Few-shot learning\r\n    - System instructions\r\n    - Cached examples\r\n    \"\"\"\r\n    \r\n    def __init__(self, storage_dir: str = \"models/prompts\"):\r\n        self.storage_dir = storage_dir\r\n        os.makedirs(storage_dir, exist_ok=True)\r\n        \r\n        self.templates: Dict[str, PromptTemplate] = {}\r\n        self.instruction_sets: Dict[str, InstructionSet] = {}\r\n        self.cached_prompts: Dict[str, str] = {}\r\n        \r\n        # Load built-in templates\r\n        self._initialize_builtin_templates()\r\n        self._initialize_architectural_instructions()\r\n        \r\n        logger.info(\"Prompt Engineering Manager initialized\")\r\n    \r\n    def _initialize_builtin_templates(self):\r\n        \"\"\"Initialize built-in prompt templates.\"\"\"\r\n        \r\n        # Architectural calculation template\r\n        self.add_template(\r\n            name=\"arch_calculation\",\r\n            template=\"\"\"You are KURDO-AI, an expert architectural calculator.\r\n\r\nTask: {task}\r\nGiven: {given_values}\r\nRequired: {required_output}\r\n\r\nShow your calculation steps clearly.\r\nUse appropriate units (metric: meters, square meters, cubic meters).\r\nProvide practical recommendations when relevant.\r\n\r\nAnswer:\"\"\",\r\n            variables=[\"task\", \"given_values\", \"required_output\"],\r\n            category=\"architecture\"\r\n        )\r\n        \r\n        # Code generation template\r\n        self.add_template(\r\n            name=\"code_generation\",\r\n            template=\"\"\"You are KURDO-AI, an expert programmer.\r\n\r\nLanguage: {language}\r\nTask: {task}\r\nRequirements:\r\n{requirements}\r\n\r\nGenerate clean, well-commented code that follows best practices.\r\n\r\nCode:\"\"\",\r\n            variables=[\"language\", \"task\", \"requirements\"],\r\n            category=\"programming\"\r\n        )\r\n        \r\n        # Analysis template\r\n        self.add_template(\r\n            name=\"technical_analysis\",\r\n            template=\"\"\"You are KURDO-AI, a technical analysis expert.\r\n\r\nSubject: {subject}\r\nContext: {context}\r\nAnalysis Type: {analysis_type}\r\n\r\nProvide a detailed, structured analysis with:\r\n1. Key findings\r\n2. Technical details\r\n3. Recommendations\r\n4. Potential issues\r\n\r\nAnalysis:\"\"\",\r\n            variables=[\"subject\", \"context\", \"analysis_type\"],\r\n            category=\"analysis\"\r\n        )\r\n        \r\n        # Design review template\r\n        self.add_template(\r\n            name=\"design_review\",\r\n            template=\"\"\"You are KURDO-AI, an architectural design reviewer.\r\n\r\nProject: {project_name}\r\nDesign Element: {design_element}\r\nStandards: {applicable_standards}\r\n\r\nReview for:\r\n- Code compliance\r\n- Structural integrity\r\n- Practicality\r\n- Cost-effectiveness\r\n- Safety\r\n\r\nReview:\"\"\",\r\n            variables=[\"project_name\", \"design_element\", \"applicable_standards\"],\r\n            category=\"architecture\"\r\n        )\r\n        \r\n        # Translation template\r\n        self.add_template(\r\n            name=\"technical_translation\",\r\n            template=\"\"\"You are KURDO-AI, a technical translator.\r\n\r\nSource Language: {source_lang}\r\nTarget Language: {target_lang}\r\nDomain: {domain}\r\n\r\nTranslate the following technical content accurately, preserving:\r\n- Technical terms\r\n- Measurements and units\r\n- Structural meaning\r\n\r\nText to translate:\r\n{text}\r\n\r\nTranslation:\"\"\",\r\n            variables=[\"source_lang\", \"target_lang\", \"domain\", \"text\"],\r\n            category=\"translation\"\r\n        )\r\n    \r\n    def _initialize_architectural_instructions(self):\r\n        \"\"\"Initialize architectural instruction sets.\"\"\"\r\n        \r\n        # Room calculation instructions\r\n        room_calc_instructions = InstructionSet(\r\n            name=\"room_calculations\",\r\n            instructions=[\r\n                \"Always specify units (meters, square meters, cubic meters)\",\r\n                \"Show calculation steps: formula → substitution → result\",\r\n                \"For area: A = length × width\",\r\n                \"For volume: V = length × width × height\",\r\n                \"Round to 2 decimal places for practical use\",\r\n                \"Provide context (e.g., 'adequate for bedroom', 'requires ventilation')\"\r\n            ],\r\n            examples=[\r\n                {\r\n                    \"input\": \"محاسبه مساحت اتاق 5x4 متر\",\r\n                    \"output\": \"مساحت = طول × عرض\\nمساحت = 5 × 4 = 20 متر مربع\\n\\nاین مساحت برای یک اتاق خواب استاندارد مناسب است.\"\r\n                },\r\n                {\r\n                    \"input\": \"Calculate volume of room 6m × 4m with 2.8m height\",\r\n                    \"output\": \"Volume = length × width × height\\nVolume = 6 × 4 × 2.8 = 67.2 cubic meters\\n\\nThis volume requires adequate ventilation for residential use.\"\r\n                }\r\n            ]\r\n        )\r\n        self.add_instruction_set(room_calc_instructions)\r\n        \r\n        # Material estimation instructions\r\n        material_instructions = InstructionSet(\r\n            name=\"material_estimation\",\r\n            instructions=[\r\n                \"State standard ratios (e.g., 60 bricks per square meter)\",\r\n                \"Calculate base requirement first\",\r\n                \"Add 5-10% waste factor\",\r\n                \"Provide practical ordering advice\",\r\n                \"Consider standard package sizes\"\r\n            ],\r\n            examples=[\r\n                {\r\n                    \"input\": \"چند آجر برای دیوار 10 متری با ارتفاع 3 متر؟\",\r\n                    \"output\": \"مساحت دیوار = 10 × 3 = 30 متر مربع\\nآجر استاندارد = 60 عدد در هر متر مربع\\nآجر مورد نیاز = 30 × 60 = 1,800 عدد\\nبا ضریب اتلاف 10% = 1,980 عدد\\n\\nتوصیه: سفارش 2,000 آجر\"\r\n                }\r\n            ]\r\n        )\r\n        self.add_instruction_set(material_instructions)\r\n        \r\n        # Code compliance instructions\r\n        code_instructions = InstructionSet(\r\n            name=\"building_codes\",\r\n            instructions=[\r\n                \"Reference specific code sections (e.g., مبحث 19)\",\r\n                \"State minimum and recommended values\",\r\n                \"Explain reasoning behind requirements\",\r\n                \"Mention variations by region if applicable\",\r\n                \"Always prioritize safety\"\r\n            ],\r\n            examples=[\r\n                {\r\n                    \"input\": \"حداقل ارتفاع سقف آپارتمان مسکونی؟\",\r\n                    \"output\": \"طبق مبحث 19 مقررات ملی ساختمان:\\n- اتاق‌های اصلی: حداقل 2.4 متر\\n- راهرو: حداقل 2.1 متر\\n- سرویس‌های بهداشتی: حداقل 2.1 متر\\n\\nتوصیه: ارتفاع 2.6-2.8 متر برای احساس فضای بهتر\"\r\n                }\r\n            ]\r\n        )\r\n        self.add_instruction_set(code_instructions)\r\n    \r\n    def add_template(self, name: str, template: str, variables: List[str], category: str = \"general\") -> PromptTemplate:\r\n        \"\"\"Add a new prompt template.\"\"\"\r\n        pt = PromptTemplate(name, template, variables, category)\r\n        self.templates[name] = pt\r\n        self._save_template(pt)\r\n        logger.info(f\"Added template: {name}\")\r\n        return pt\r\n    \r\n    def add_instruction_set(self, instruction_set: InstructionSet):\r\n        \"\"\"Add a new instruction set.\"\"\"\r\n        self.instruction_sets[instruction_set.name] = instruction_set\r\n        logger.info(f\"Added instruction set: {instruction_set.name}\")\r\n    \r\n    def get_template(self, name: str) -> Optional[PromptTemplate]:\r\n        \"\"\"Get a template by name.\"\"\"\r\n        return self.templates.get(name)\r\n    \r\n    def list_templates(self, category: Optional[str] = None) -> List[str]:\r\n        \"\"\"List all templates, optionally filtered by category.\"\"\"\r\n        if category:\r\n            return [name for name, tmpl in self.templates.items() if tmpl.category == category]\r\n        return list(self.templates.keys())\r\n    \r\n    def create_few_shot_prompt(\r\n        self,\r\n        task_description: str,\r\n        examples: List[Dict[str, str]],\r\n        current_input: str,\r\n        max_examples: int = 5,\r\n        include_reasoning: bool = False\r\n    ) -> str:\r\n        \"\"\"\r\n        Create a few-shot learning prompt.\r\n        \r\n        Args:\r\n            task_description: What the AI should do\r\n            examples: List of {\"input\": \"...\", \"output\": \"...\"}\r\n            current_input: The new input to process\r\n            max_examples: Maximum number of examples to include\r\n            include_reasoning: Include chain-of-thought reasoning\r\n        \r\n        Returns:\r\n            Formatted few-shot prompt\r\n        \"\"\"\r\n        prompt = f\"# Task\\n{task_description}\\n\\n\"\r\n        \r\n        if include_reasoning:\r\n            prompt += \"Show your reasoning step-by-step.\\n\\n\"\r\n        \r\n        prompt += \"# Examples\\n\\n\"\r\n        \r\n        for i, example in enumerate(examples[:max_examples], 1):\r\n            prompt += f\"Example {i}:\\n\"\r\n            prompt += f\"Input: {example['input']}\\n\"\r\n            \r\n            if include_reasoning and \"reasoning\" in example:\r\n                prompt += f\"Reasoning: {example['reasoning']}\\n\"\r\n            \r\n            prompt += f\"Output: {example['output']}\\n\\n\"\r\n        \r\n        prompt += \"# Your Turn\\n\\n\"\r\n        prompt += f\"Input: {current_input}\\n\"\r\n        \r\n        if include_reasoning:\r\n            prompt += \"Reasoning: \"\r\n        else:\r\n            prompt += \"Output: \"\r\n        \r\n        return prompt\r\n    \r\n    def create_chain_of_thought_prompt(\r\n        self,\r\n        problem: str,\r\n        domain: str = \"general\"\r\n    ) -> str:\r\n        \"\"\"\r\n        Create a chain-of-thought prompt for complex reasoning.\r\n        \r\n        Args:\r\n            problem: The problem to solve\r\n            domain: Problem domain\r\n        \r\n        Returns:\r\n            CoT prompt\r\n        \"\"\"\r\n        prompt = f\"\"\"You are KURDO-AI, an expert in {domain}.\r\n\r\nProblem: {problem}\r\n\r\nSolve this step-by-step:\r\n1. Understand: What is being asked?\r\n2. Identify: What information do we have?\r\n3. Plan: What approach should we use?\r\n4. Calculate: Work through the solution\r\n5. Verify: Does the answer make sense?\r\n6. Conclude: State the final answer clearly\r\n\r\nLet's work through this:\r\n\r\n\"\"\"\r\n        return prompt\r\n    \r\n    def create_role_based_prompt(\r\n        self,\r\n        role: str,\r\n        expertise: List[str],\r\n        task: str,\r\n        constraints: Optional[List[str]] = None\r\n    ) -> str:\r\n        \"\"\"\r\n        Create a role-based prompt.\r\n        \r\n        Args:\r\n            role: AI role (e.g., \"structural engineer\")\r\n            expertise: List of expertise areas\r\n            task: The task to perform\r\n            constraints: Optional constraints\r\n        \r\n        Returns:\r\n            Role-based prompt\r\n        \"\"\"\r\n        prompt = f\"You are KURDO-AI, a professional {role}.\\n\\n\"\r\n        prompt += \"Your expertise includes:\\n\"\r\n        for exp in expertise:\r\n            prompt += f\"- {exp}\\n\"\r\n        prompt += \"\\n\"\r\n        \r\n        if constraints:\r\n            prompt += \"Important constraints:\\n\"\r\n            for constraint in constraints:\r\n                prompt += f\"- {constraint}\\n\"\r\n            prompt += \"\\n\"\r\n        \r\n        prompt += f\"Task: {task}\\n\\n\"\r\n        prompt += \"Provide a professional, detailed response:\\n\\n\"\r\n        \r\n        return prompt\r\n    \r\n    def create_cached_system_prompt(\r\n        self,\r\n        system_role: str,\r\n        training_examples: List[Dict],\r\n        max_examples: int = 20\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Create a cached system prompt (Anthropic style).\r\n        \r\n        This is cost-effective for repeated use with similar tasks.\r\n        \r\n        Args:\r\n            system_role: System role description\r\n            training_examples: Examples to cache\r\n            max_examples: Maximum examples to include\r\n        \r\n        Returns:\r\n            Cached prompt structure\r\n        \"\"\"\r\n        cached_content = f\"System Role: {system_role}\\n\\n\"\r\n        cached_content += \"# Training Examples\\n\\n\"\r\n        cached_content += \"Learn from these examples:\\n\\n\"\r\n        \r\n        for i, example in enumerate(training_examples[:max_examples], 1):\r\n            cached_content += f\"Example {i}:\\n\"\r\n            if \"input\" in example:\r\n                cached_content += f\"Q: {example['input']}\\n\"\r\n            elif \"prompt\" in example:\r\n                cached_content += f\"Q: {example['prompt']}\\n\"\r\n            \r\n            if \"output\" in example:\r\n                cached_content += f\"A: {example['output']}\\n\"\r\n            elif \"completion\" in example:\r\n                cached_content += f\"A: {example['completion']}\\n\"\r\n            cached_content += \"\\n\"\r\n        \r\n        cached_content += \"Now respond to user queries following these patterns.\\n\"\r\n        \r\n        cache_id = f\"cached_prompt_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\r\n        self.cached_prompts[cache_id] = cached_content\r\n        \r\n        return {\r\n            \"cache_id\": cache_id,\r\n            \"cached_content\": cached_content,\r\n            \"num_examples\": min(len(training_examples), max_examples),\r\n            \"estimated_tokens\": len(cached_content.split()),\r\n            \"usage\": \"Use this cached content as system message in API calls\"\r\n        }\r\n    \r\n    def optimize_prompt(\r\n        self,\r\n        original_prompt: str,\r\n        optimization_strategy: str = \"concise\"\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Optimize a prompt for better performance.\r\n        \r\n        Strategies:\r\n        - concise: Remove redundancy\r\n        - detailed: Add more context\r\n        - structured: Improve formatting\r\n        - directive: Make instructions clearer\r\n        \r\n        Args:\r\n            original_prompt: The prompt to optimize\r\n            optimization_strategy: Strategy to use\r\n        \r\n        Returns:\r\n            Optimized prompt and metadata\r\n        \"\"\"\r\n        optimizations = {\r\n            \"concise\": self._optimize_concise,\r\n            \"detailed\": self._optimize_detailed,\r\n            \"structured\": self._optimize_structured,\r\n            \"directive\": self._optimize_directive\r\n        }\r\n        \r\n        if optimization_strategy not in optimizations:\r\n            return {\r\n                \"status\": \"error\",\r\n                \"message\": f\"Unknown strategy: {optimization_strategy}\",\r\n                \"available_strategies\": list(optimizations.keys())\r\n            }\r\n        \r\n        optimized = optimizations[optimization_strategy](original_prompt)\r\n        \r\n        return {\r\n            \"original\": original_prompt,\r\n            \"optimized\": optimized,\r\n            \"strategy\": optimization_strategy,\r\n            \"original_length\": len(original_prompt),\r\n            \"optimized_length\": len(optimized),\r\n            \"reduction\": f\"{(1 - len(optimized) / len(original_prompt)) * 100:.1f}%\"\r\n        }\r\n    \r\n    def _optimize_concise(self, prompt: str) -> str:\r\n        \"\"\"Make prompt more concise.\"\"\"\r\n        # Remove excessive whitespace\r\n        lines = [line.strip() for line in prompt.split('\\n') if line.strip()]\r\n        return '\\n'.join(lines)\r\n    \r\n    def _optimize_detailed(self, prompt: str) -> str:\r\n        \"\"\"Add more detail to prompt.\"\"\"\r\n        detailed = f\"\"\"Task Context:\r\n{prompt}\r\n\r\nRequirements:\r\n- Be accurate and precise\r\n- Show your work/reasoning\r\n- Use appropriate units and formatting\r\n- Provide practical recommendations\r\n\r\nResponse:\"\"\"\r\n        return detailed\r\n    \r\n    def _optimize_structured(self, prompt: str) -> str:\r\n        \"\"\"Improve prompt structure.\"\"\"\r\n        structured = f\"\"\"# Task\r\n{prompt}\r\n\r\n# Instructions\r\n1. Analyze the requirements carefully\r\n2. Provide a structured response\r\n3. Include relevant details and examples\r\n4. Format output clearly\r\n\r\n# Response\r\n\"\"\"\r\n        return structured\r\n    \r\n    def _optimize_directive(self, prompt: str) -> str:\r\n        \"\"\"Make instructions more directive.\"\"\"\r\n        directive = f\"\"\"INSTRUCTION: {prompt}\r\n\r\nYou must:\r\n- Follow the instruction exactly\r\n- Provide complete information\r\n- Use clear, professional language\r\n- Format output appropriately\r\n\r\nBEGIN RESPONSE:\r\n\"\"\"\r\n        return directive\r\n    \r\n    def compare_with_training_methods(self) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Compare prompt engineering with other training methods.\r\n        \r\n        Returns:\r\n            Detailed comparison\r\n        \"\"\"\r\n        return {\r\n            \"prompt_engineering\": {\r\n                \"type\": \"Training-Free\",\r\n                \"setup_time\": \"Minutes\",\r\n                \"cost\": \"$0 (inference only)\",\r\n                \"gpu_required\": False,\r\n                \"quality\": \"Good (depends on prompt quality)\",\r\n                \"flexibility\": \"Very High\",\r\n                \"best_for\": [\r\n                    \"Quick prototypes\",\r\n                    \"No training data\",\r\n                    \"Rapid iteration\",\r\n                    \"Zero-shot tasks\",\r\n                    \"Cost-sensitive applications\"\r\n                ],\r\n                \"limitations\": [\r\n                    \"Token limits (context window)\",\r\n                    \"Repetitive examples increase cost\",\r\n                    \"Less consistent than fine-tuning\",\r\n                    \"Requires prompt engineering skills\"\r\n                ],\r\n                \"techniques\": [\r\n                    \"Zero-shot prompting\",\r\n                    \"Few-shot learning\",\r\n                    \"Chain-of-thought\",\r\n                    \"Role-based prompts\",\r\n                    \"Instruction tuning\",\r\n                    \"Prompt caching\"\r\n                ]\r\n            },\r\n            \"fine_tuning\": {\r\n                \"type\": \"Full Training\",\r\n                \"setup_time\": \"Hours to Days\",\r\n                \"cost\": \"$10-100+\",\r\n                \"gpu_required\": True,\r\n                \"quality\": \"Excellent\",\r\n                \"flexibility\": \"Low (requires retraining)\",\r\n                \"best_for\": [\r\n                    \"Production deployments\",\r\n                    \"Consistent behavior\",\r\n                    \"Large-scale applications\",\r\n                    \"Specialized domains\"\r\n                ]\r\n            },\r\n            \"lora\": {\r\n                \"type\": \"Parameter-Efficient Training\",\r\n                \"setup_time\": \"30min-3hours\",\r\n                \"cost\": \"$0 (local)\",\r\n                \"gpu_required\": True,\r\n                \"quality\": \"Very Good\",\r\n                \"flexibility\": \"Medium (multiple adapters)\",\r\n                \"best_for\": [\r\n                    \"Multiple tasks\",\r\n                    \"Limited GPU\",\r\n                    \"Fast iteration\",\r\n                    \"Cost-effective training\"\r\n                ]\r\n            },\r\n            \"recommendation\": {\r\n                \"use_prompt_engineering_when\": [\r\n                    \"No training data available\",\r\n                    \"Need immediate results\",\r\n                    \"Budget is limited\",\r\n                    \"Task changes frequently\",\r\n                    \"Prototyping phase\"\r\n                ],\r\n                \"use_fine_tuning_when\": [\r\n                    \"Have quality training data (500+ examples)\",\r\n                    \"Need consistent behavior\",\r\n                    \"Production deployment\",\r\n                    \"Budget allows\"\r\n                ],\r\n                \"use_lora_when\": [\r\n                    \"Have training data (50-500 examples)\",\r\n                    \"Need multiple task-specific models\",\r\n                    \"Limited GPU memory\",\r\n                    \"Want fast training\"\r\n                ],\r\n                \"hybrid_approach\": [\r\n                    \"Start with prompt engineering for prototyping\",\r\n                    \"Collect real-world data\",\r\n                    \"Train LoRA adapter for common tasks\",\r\n                    \"Use prompt engineering for edge cases\",\r\n                    \"Fall back to fine-tuning for production\"\r\n                ]\r\n            }\r\n        }\r\n    \r\n    def _save_template(self, template: PromptTemplate):\r\n        \"\"\"Save template to disk.\"\"\"\r\n        filepath = os.path.join(self.storage_dir, f\"{template.name}.json\")\r\n        with open(filepath, 'w', encoding='utf-8') as f:\r\n            json.dump(template.to_dict(), f, indent=2, ensure_ascii=False)\r\n    \r\n    def get_statistics(self) -> Dict[str, Any]:\r\n        \"\"\"Get usage statistics.\"\"\"\r\n        return {\r\n            \"total_templates\": len(self.templates),\r\n            \"templates_by_category\": self._count_by_category(),\r\n            \"total_instruction_sets\": len(self.instruction_sets),\r\n            \"cached_prompts\": len(self.cached_prompts),\r\n            \"most_used_templates\": self._get_most_used_templates(5)\r\n        }\r\n    \r\n    def _count_by_category(self) -> Dict[str, int]:\r\n        \"\"\"Count templates by category.\"\"\"\r\n        counts = {}\r\n        for template in self.templates.values():\r\n            counts[template.category] = counts.get(template.category, 0) + 1\r\n        return counts\r\n    \r\n    def _get_most_used_templates(self, limit: int = 5) -> List[Dict]:\r\n        \"\"\"Get most frequently used templates.\"\"\"\r\n        sorted_templates = sorted(\r\n            self.templates.values(),\r\n            key=lambda t: t.usage_count,\r\n            reverse=True\r\n        )\r\n        return [\r\n            {\"name\": t.name, \"usage_count\": t.usage_count, \"category\": t.category}\r\n            for t in sorted_templates[:limit]\r\n        ]\r\n\r\n    def generate_prompt(\r\n        self,\r\n        query: str,\r\n        task_type: Optional[str] = None,\r\n        template_name: Optional[str] = None,\r\n        **kwargs\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Generate a structured prompt for a query.\r\n\r\n        Args:\r\n            query: The user query\r\n            task_type: Type of task (architectural, structural, etc.)\r\n            template_name: Optional specific template to use\r\n            **kwargs: Additional parameters for template\r\n\r\n        Returns:\r\n            Dictionary with prompt and metadata\r\n        \"\"\"\r\n        # Select template\r\n        if template_name and template_name in self.templates:\r\n            template = self.templates[template_name]\r\n        elif task_type:\r\n            # Try to find template by task type\r\n            category_map = {\r\n                \"architectural\": \"arch_calculation\",\r\n                \"structural\": \"technical_analysis\",\r\n                \"code\": \"code_generation\",\r\n                \"design\": \"design_review\"\r\n            }\r\n            template_name = category_map.get(task_type.lower(), \"technical_analysis\")\r\n            template = self.templates.get(template_name)\r\n        else:\r\n            template = None\r\n\r\n        # Generate prompt\r\n        if template:\r\n            try:\r\n                # Fill template with query and kwargs\r\n                template_vars = {k: kwargs.get(k, query) for k in template.variables}\r\n                if \"task\" in template_vars and template_vars[\"task\"] == query:\r\n                    template_vars[\"task\"] = query\r\n                prompt = template.format(**template_vars)\r\n            except Exception:\r\n                # Fallback if template fails\r\n                prompt = f\"Task: {query}\\n\\nProvide a detailed response:\"\r\n        else:\r\n            # Simple prompt without template\r\n            prompt = f\"Task: {query}\\n\\nProvide a detailed, structured response:\"\r\n\r\n        return {\r\n            \"status\": \"success\",\r\n            \"prompt\": prompt,\r\n            \"template_used\": template.name if template else \"default\",\r\n            \"prompt_length\": len(prompt),\r\n            \"query\": query\r\n        }\r\n\r\n\r\n# Global instance\r\nprompt_engineering_manager = PromptEngineeringManager()\r\n",
    "format": "py"
  }
]