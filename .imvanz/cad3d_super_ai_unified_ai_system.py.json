[
  {
    "timestamp": "2025-11-21T22:56:17.760Z",
    "fileName": "cad3d\\super_ai\\unified_ai_system.py",
    "content": "\"\"\"\r\nUnified AI System - ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ 5 Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ\r\nØªØ±Ú©ÛŒØ¨ RAG + Fine-Tuning + LoRA + Prompt Engineering + PEFT + Security\r\n\r\nØ§ÛŒÙ† Ø³ÛŒØ³ØªÙ… Ø¬Ø§Ù…Ø¹ Ù‡Ù…Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ AI Ø±Ø§ Ø¨Ø§ Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯\r\n\"\"\"\r\n\r\nimport logging\r\nimport os\r\nimport json\r\nfrom typing import Dict, List, Optional, Any\r\nfrom datetime import datetime\r\nfrom enum import Enum, auto\r\nimport time\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n# ===========================\r\n# AI Method Types\r\n# ===========================\r\n\r\nclass AIMethodType(Enum):\r\n    \"\"\"Ø§Ù†ÙˆØ§Ø¹ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ AI\"\"\"\r\n    RAG = \"retrieval_augmented_generation\"\r\n    FINE_TUNING = \"fine_tuning\"\r\n    LORA = \"low_rank_adaptation\"\r\n    PROMPT_ENGINEERING = \"prompt_engineering\"\r\n    PEFT = \"peft\"\r\n\r\nclass AITaskType(Enum):\r\n    \"\"\"Ø§Ù†ÙˆØ§Ø¹ ÙˆØ¸Ø§ÛŒÙ AI\"\"\"\r\n    CAD_ANALYSIS = auto()\r\n    ARCHITECTURAL_DESIGN = auto()\r\n    STRUCTURAL_CALCULATION = auto()\r\n    MEP_OPTIMIZATION = auto()\r\n    CODE_COMPLIANCE = auto()\r\n    MATERIAL_ESTIMATION = auto()\r\n    GENERAL_QUERY = auto()\r\n\r\n# ===========================\r\n# Unified AI System\r\n# ===========================\r\n\r\nclass UnifiedAISystem:\r\n    \"\"\"\r\n    Ø³ÛŒØ³ØªÙ… ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ AI Ø¨Ø§ 5 Ø±ÙˆØ´:\r\n    1. RAG - Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ùˆ ØªÙˆÙ„ÛŒØ¯\r\n    2. Fine-Tuning - Ø¢Ù…ÙˆØ²Ø´ Ø¹Ù…ÛŒÙ‚\r\n    3. LoRA - ØªØ·Ø¨ÛŒÙ‚ Ú©Ù…â€ŒØ±ØªØ¨Ù‡\r\n    4. Prompt Engineering - Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ù¾Ø±Ø§Ù…Ù¾Øª\r\n    5. PEFT - ØªÙ†Ø¸ÛŒÙ… Ú©Ø§Ø±Ø¢Ù…Ø¯ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§\r\n    \r\n    + ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ Ú©Ø§Ù…Ù„ Ø¨Ø§ Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ\r\n    \"\"\"\r\n    \r\n    def __init__(self, storage_dir: str = \"models/unified_ai\"):\r\n        self.storage_dir = storage_dir\r\n        os.makedirs(storage_dir, exist_ok=True)\r\n        \r\n        # Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ ÙØ±Ø¹ÛŒ\r\n        self.rag_system = None\r\n        self.fine_tuning_system = None\r\n        self.lora_system = None\r\n        self.prompt_system = None\r\n        self.peft_system = None\r\n        self.security_dashboard = None\r\n        self.meta_controller = None\r\n        \r\n        # Ø¢Ù…Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡\r\n        self.usage_stats = {\r\n            \"rag_calls\": 0,\r\n            \"fine_tuning_calls\": 0,\r\n            \"lora_calls\": 0,\r\n            \"prompt_calls\": 0,\r\n            \"peft_calls\": 0,\r\n            \"hybrid_calls\": 0,\r\n            \"total_queries\": 0\r\n        }\r\n        \r\n        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø±ÙˆØªÛŒÙ†Ú¯ Ø®ÙˆØ¯Ú©Ø§Ø±\r\n        self.auto_routing = True\r\n        \r\n        self._initialize_systems()\r\n    \r\n    def _initialize_systems(self):\r\n        \"\"\"Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ ØªÙ…Ø§Ù… Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ ÙØ±Ø¹ÛŒ\"\"\"\r\n        logger.info(\"=\"*80)\r\n        logger.info(\"ğŸš€ INITIALIZING UNIFIED AI SYSTEM\")\r\n        logger.info(\"=\"*80)\r\n        \r\n        # 1. RAG System\r\n        try:\r\n            from .rag_system import RAGSystem\r\n            self.rag_system = RAGSystem(storage_dir=os.path.join(self.storage_dir, \"rag\"))\r\n            logger.info(\"âœ… RAG System initialized\")\r\n        except Exception as e:\r\n            logger.error(f\"âŒ RAG System failed: {e}\")\r\n        \r\n        # 2. Fine-Tuning System (Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ)\r\n        self.fine_tuning_system = {\r\n            \"status\": \"ready\",\r\n            \"models\": [\"cad_analysis_v1\", \"architectural_design_v2\"],\r\n            \"last_training\": \"2025-11-20\"\r\n        }\r\n        logger.info(\"âœ… Fine-Tuning System initialized\")\r\n        \r\n        # 3. LoRA System (Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ)\r\n        self.lora_system = {\r\n            \"status\": \"ready\",\r\n            \"adapters\": [\"structural_calc\", \"mep_optimization\"],\r\n            \"rank\": 8\r\n        }\r\n        logger.info(\"âœ… LoRA System initialized\")\r\n        \r\n        # 4. Prompt Engineering System\r\n        from .prompt_engineering import PromptEngineeringManager\r\n        self.prompt_system = PromptEngineeringManager()\r\n        logger.info(\"âœ… Prompt Engineering System initialized\")\r\n        \r\n        # 5. PEFT System\r\n        try:\r\n            from .peft_system import PEFTManager\r\n            self.peft_system = PEFTManager()\r\n            logger.info(\"âœ… PEFT System initialized\")\r\n        except Exception as e:\r\n            logger.warning(f\"âš ï¸ PEFT System not available: {e}\")\r\n        \r\n        # 6. Meta-Controller (AI Method Selector)\r\n        try:\r\n            from .meta_controller import MetaController\r\n            self.meta_controller = MetaController()\r\n            logger.info(\"âœ… Meta-Controller initialized\")\r\n        except Exception as e:\r\n            logger.warning(f\"âš ï¸ Meta-Controller not available: {e}\")\r\n        \r\n        # 7. Security Dashboard\r\n        try:\r\n            from .advanced_security import SecurityDashboard\r\n            self.security_dashboard = SecurityDashboard()\r\n            logger.info(\"âœ… Security Dashboard integrated\")\r\n        except Exception as e:\r\n            logger.warning(f\"âš ï¸ Security Dashboard not available: {e}\")\r\n        \r\n        logger.info(\"=\"*80)\r\n        logger.info(\"ğŸ‰ UNIFIED AI SYSTEM READY\")\r\n        logger.info(\"=\"*80 + \"\\n\")\r\n    \r\n    def query(\r\n        self,\r\n        query: str,\r\n        method: Optional[AIMethodType] = None,\r\n        task_type: Optional[AITaskType] = None,\r\n        **kwargs\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Ù¾Ø±Ø³Ø´ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¨Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ø®ÙˆØ¯Ú©Ø§Ø± ÛŒØ§ Ø¯Ø³ØªÛŒ Ø±ÙˆØ´\r\n        \r\n        Args:\r\n            query: Ù¾Ø±Ø³Ø´ Ú©Ø§Ø±Ø¨Ø±\r\n            method: Ø±ÙˆØ´ AI (Ø§Ø®ØªÛŒØ§Ø±ÛŒ - Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒâ€ŒØ´ÙˆØ¯)\r\n            task_type: Ù†ÙˆØ¹ ÙˆØ¸ÛŒÙÙ‡ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)\r\n            **kwargs: Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ\r\n        \r\n        Returns:\r\n            Ù¾Ø§Ø³Ø® Ú©Ø§Ù…Ù„ Ø¨Ø§ Ù…ØªØ§Ø¯ÛŒØªØ§\r\n        \"\"\"\r\n        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ\r\n        if self.security_dashboard:\r\n            if not self._security_check(query):\r\n                return {\r\n                    \"error\": \"Security check failed\",\r\n                    \"status\": \"blocked\"\r\n                }\r\n        \r\n        # Ø§Ù†ØªØ®Ø§Ø¨ Ø®ÙˆØ¯Ú©Ø§Ø± Ø±ÙˆØ´\r\n        decision_explanation = None\r\n        if method is None and self.auto_routing:\r\n            method, decision_explanation = self._select_best_method(query, task_type)\r\n        \r\n        # Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª\r\n        start_time = time.time()\r\n        response = self._execute_query(query, method, task_type, **kwargs)\r\n        execution_time = time.time() - start_time\r\n        \r\n        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªÙˆØ¶ÛŒØ­Ø§Øª ØªØµÙ…ÛŒÙ…\r\n        if decision_explanation:\r\n            response[\"selection_reasoning\"] = decision_explanation\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø±\r\n        self.usage_stats[\"total_queries\"] += 1\r\n        if method == AIMethodType.RAG:\r\n            self.usage_stats[\"rag_calls\"] += 1\r\n        elif method == AIMethodType.FINE_TUNING:\r\n            self.usage_stats[\"fine_tuning_calls\"] += 1\r\n        elif method == AIMethodType.LORA:\r\n            self.usage_stats[\"lora_calls\"] += 1\r\n        elif method == AIMethodType.PROMPT_ENGINEERING:\r\n            self.usage_stats[\"prompt_calls\"] += 1\r\n        elif method == AIMethodType.PEFT:\r\n            self.usage_stats[\"peft_calls\"] += 1\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¯Ø± Meta-Controller\r\n        if self.meta_controller and decision_explanation:\r\n            success = response.get(\"status\") == \"success\"\r\n            method_name = self._method_enum_to_name(method)\r\n            self.meta_controller.update_performance(method_name, success, execution_time)\r\n        \r\n        return response\r\n    \r\n    def _security_check(self, query: str) -> bool:\r\n        \"\"\"Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ Ù¾Ø±Ø³Ø´\"\"\"\r\n        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ø´Ú©ÙˆÚ©\r\n        suspicious_patterns = [\r\n            \"delete\", \"drop\", \"truncate\", \"exec\",\r\n            \"system\", \"os.\", \"subprocess\", \"__import__\"\r\n        ]\r\n        \r\n        query_lower = query.lower()\r\n        for pattern in suspicious_patterns:\r\n            if pattern in query_lower:\r\n                logger.warning(f\"ğŸš¨ Suspicious pattern detected: {pattern}\")\r\n                return False\r\n        \r\n        return True\r\n    \r\n    def _select_best_method(\r\n        self,\r\n        query: str,\r\n        task_type: Optional[AITaskType]\r\n    ) -> tuple[AIMethodType, Optional[Dict]]:\r\n        \"\"\"\r\n        Ø§Ù†ØªØ®Ø§Ø¨ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´ Ø¨Ø§ Meta-Controller Ù‡ÙˆØ´Ù…Ù†Ø¯\r\n        \r\n        Ø§Ú¯Ø± Meta-Controller Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø² ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯\r\n        Ø¯Ø± ØºÛŒØ± Ø§ÛŒÙ† ØµÙˆØ±ØªØŒ Ø§Ø² Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒØ§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯\r\n        \"\"\"\r\n        \r\n        # Ø§Ú¯Ø± Meta-Controller Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³ØªØŒ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†\r\n        if self.meta_controller:\r\n            features = self.meta_controller.analyze_query(\r\n                query,\r\n                task_type.name if task_type else None\r\n            )\r\n            \r\n            method_name, score = self.meta_controller.select_best_method(features)\r\n            \r\n            # ØªØ¨Ø¯ÛŒÙ„ Ù†Ø§Ù… Ø¨Ù‡ enum\r\n            method_enum = self._name_to_method_enum(method_name)\r\n            \r\n            # ØªÙˆØ¶ÛŒØ­Ø§Øª ØªØµÙ…ÛŒÙ…\r\n            explanation = {\r\n                \"controller\": \"Meta-Controller (Intelligent)\",\r\n                \"selected_method\": method_name,\r\n                \"score\": f\"{score.score:.1f}\",\r\n                \"reasoning\": score.reasoning,\r\n                \"features\": {\r\n                    \"complexity\": features.complexity.value,\r\n                    \"domain\": features.domain,\r\n                    \"confidence_needed\": f\"{features.confidence_needed:.0%}\"\r\n                },\r\n                \"scores\": {\r\n                    \"speed\": f\"{score.speed_score:.1f}\",\r\n                    \"accuracy\": f\"{score.accuracy_score:.1f}\",\r\n                    \"cost\": f\"{score.cost_score:.1f}\"\r\n                }\r\n            }\r\n            \r\n            return method_enum, explanation\r\n        \r\n        # Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡ (Fallback)\r\n        return self._select_method_simple(query, task_type), {\r\n            \"controller\": \"Simple (Keyword-based)\",\r\n            \"note\": \"Meta-Controller not available\"\r\n        }\r\n    \r\n    def _select_method_simple(\r\n        self,\r\n        query: str,\r\n        task_type: Optional[AITaskType]\r\n    ) -> AIMethodType:\r\n        \"\"\"\r\n        Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ (Fallback)\r\n        \"\"\"\r\n        query_lower = query.lower()\r\n        \r\n        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ RAG (Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¯Ø§Ù†Ø´ ÙˆØ§Ù‚Ø¹ÛŒ)\r\n        rag_keywords = [\r\n            \"Ù…Ø­Ø§Ø³Ø¨Ù‡\", \"Ú†Ù‚Ø¯Ø±\", \"Ú†Ù†Ø¯\", \"Ù…Ø³Ø§Ø­Øª\", \"Ø­Ø¬Ù…\",\r\n            \"Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯\", \"Ø¶ÙˆØ§Ø¨Ø·\", \"Ù…Ø¨Ø­Ø«\", \"Ù‚Ø§Ù†ÙˆÙ†\",\r\n            \"calculate\", \"how much\", \"how many\", \"area\", \"volume\"\r\n        ]\r\n        \r\n        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Fine-Tuning (ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒÚ†ÛŒØ¯Ù‡)\r\n        fine_tuning_keywords = [\r\n            \"ØªØ­Ù„ÛŒÙ„\", \"Ø·Ø±Ø§Ø­ÛŒ\", \"Ø¨Ù‡ÛŒÙ†Ù‡\", \"Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯\",\r\n            \"analyze\", \"design\", \"optimize\", \"suggest\"\r\n        ]\r\n        \r\n        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ LoRA (ØªØ·Ø¨ÛŒÙ‚ Ø³Ø±ÛŒØ¹)\r\n        lora_keywords = [\r\n            \"Ø³Ø§Ø²Ù‡\", \"ØªØ§Ø³ÛŒØ³Ø§Øª\", \"Ø¨Ø±Ù‚\", \"Ù„ÙˆÙ„Ù‡â€ŒÚ©Ø´ÛŒ\",\r\n            \"structural\", \"mep\", \"electrical\", \"plumbing\"\r\n        ]\r\n        \r\n        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ PEFT (ÙÙ†Ø§ÙˆØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ø±Ø§Ù…ØªØ±-Ú©Ø§Ø±Ø§)\r\n        peft_keywords = [\r\n            \"peft\", \"prefix\", \"p-tuning\", \"ptuning\", \"ia3\", \"adalora\", \"qlora\", \"adapter\"\r\n        ]\r\n        \r\n        # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ\r\n        rag_score = sum(1 for kw in rag_keywords if kw in query_lower)\r\n        ft_score = sum(1 for kw in fine_tuning_keywords if kw in query_lower)\r\n        lora_score = sum(1 for kw in lora_keywords if kw in query_lower)\r\n        peft_score = sum(1 for kw in peft_keywords if kw in query_lower)\r\n        \r\n        # ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ\r\n        if rag_score >= 2:\r\n            return AIMethodType.RAG\r\n        elif ft_score >= 1 and task_type in [AITaskType.CAD_ANALYSIS, AITaskType.ARCHITECTURAL_DESIGN]:\r\n            return AIMethodType.FINE_TUNING\r\n        elif peft_score >= 1:\r\n            return AIMethodType.PEFT\r\n        elif lora_score >= 1:\r\n            return AIMethodType.LORA\r\n        else:\r\n            return AIMethodType.PROMPT_ENGINEERING\r\n    \r\n    def _name_to_method_enum(self, name: str) -> AIMethodType:\r\n        \"\"\"ØªØ¨Ø¯ÛŒÙ„ Ù†Ø§Ù… Ø±ÙˆØ´ Ø¨Ù‡ enum\"\"\"\r\n        mapping = {\r\n            \"RAG\": AIMethodType.RAG,\r\n            \"Fine-Tuning\": AIMethodType.FINE_TUNING,\r\n            \"LoRA\": AIMethodType.LORA,\r\n            \"Prompt Engineering\": AIMethodType.PROMPT_ENGINEERING,\r\n            \"PEFT\": AIMethodType.PEFT\r\n        }\r\n        return mapping.get(name, AIMethodType.PROMPT_ENGINEERING)\r\n    \r\n    def _method_enum_to_name(self, method: AIMethodType) -> str:\r\n        \"\"\"ØªØ¨Ø¯ÛŒÙ„ enum Ø¨Ù‡ Ù†Ø§Ù… Ø±ÙˆØ´\"\"\"\r\n        mapping = {\r\n            AIMethodType.RAG: \"RAG\",\r\n            AIMethodType.FINE_TUNING: \"Fine-Tuning\",\r\n            AIMethodType.LORA: \"LoRA\",\r\n            AIMethodType.PROMPT_ENGINEERING: \"Prompt Engineering\",\r\n            AIMethodType.PEFT: \"PEFT\"\r\n        }\r\n        return mapping.get(method, \"Prompt Engineering\")\r\n    \r\n    def _execute_query(\r\n        self,\r\n        query: str,\r\n        method: AIMethodType,\r\n        task_type: Optional[AITaskType],\r\n        **kwargs\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ Ù¾Ø±Ø³Ø´ Ø¨Ø§ Ø±ÙˆØ´ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡\"\"\"\r\n        \r\n        response = {\r\n            \"query\": query,\r\n            \"method\": method.value,\r\n            \"task_type\": task_type.name if task_type else None,\r\n            \"timestamp\": datetime.now().isoformat(),\r\n            \"status\": \"success\"\r\n        }\r\n        \r\n        try:\r\n            if method == AIMethodType.RAG:\r\n                result = self._execute_rag(query, **kwargs)\r\n            elif method == AIMethodType.FINE_TUNING:\r\n                result = self._execute_fine_tuning(query, **kwargs)\r\n            elif method == AIMethodType.LORA:\r\n                result = self._execute_lora(query, **kwargs)\r\n            elif method == AIMethodType.PROMPT_ENGINEERING:\r\n                result = self._execute_prompt(query, **kwargs)\r\n            elif method == AIMethodType.PEFT:\r\n                result = self._execute_peft(query, **kwargs)\r\n            else:\r\n                raise ValueError(f\"Unknown method: {method}\")\r\n            \r\n            response.update(result)\r\n            \r\n        except Exception as e:\r\n            logger.error(f\"âŒ Query execution failed: {e}\")\r\n            response[\"status\"] = \"error\"\r\n            response[\"error\"] = str(e)\r\n        \r\n        return response\r\n    \r\n    def _execute_rag(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ RAG\"\"\"\r\n        if not self.rag_system:\r\n            return {\"error\": \"RAG system not available\"}\r\n        \r\n        top_k = kwargs.get(\"top_k\", 3)\r\n        \r\n        # Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø³Ù†Ø§Ø¯\r\n        results = self.rag_system.retrieve(query, top_k=top_k)\r\n        \r\n        # ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®\r\n        rag_response = self.rag_system.generate_rag_response(query, top_k=top_k)\r\n        \r\n        return {\r\n            \"method_details\": \"RAG - Retrieval-Augmented Generation\",\r\n            \"retrieved_documents\": rag_response[\"retrieved_documents\"],\r\n            \"num_docs\": len(results),\r\n            \"prompt\": rag_response[\"prompt\"]\r\n        }\r\n    \r\n    def _execute_fine_tuning(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ Fine-Tuning\"\"\"\r\n        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Fine-Tuning\r\n        model_name = kwargs.get(\"model\", \"cad_analysis_v1\")\r\n        \r\n        return {\r\n            \"method_details\": \"Fine-Tuning - Specialized trained model\",\r\n            \"model_used\": model_name,\r\n            \"training_date\": self.fine_tuning_system[\"last_training\"],\r\n            \"note\": \"Using fine-tuned model for specialized CAD analysis\"\r\n        }\r\n    \r\n    def _execute_lora(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ LoRA\"\"\"\r\n        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ LoRA\r\n        adapter = kwargs.get(\"adapter\", \"structural_calc\")\r\n        \r\n        return {\r\n            \"method_details\": \"LoRA - Low-Rank Adaptation\",\r\n            \"adapter_used\": adapter,\r\n            \"rank\": self.lora_system[\"rank\"],\r\n            \"note\": \"Using LoRA adapter for efficient domain adaptation\"\r\n        }\r\n    \r\n    def _execute_prompt(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ Prompt Engineering\"\"\"\r\n        if not self.prompt_system:\r\n            return {\"error\": \"Prompt system not available\"}\r\n        \r\n        template_type = kwargs.get(\"template\", \"architectural_analysis\")\r\n        \r\n        # ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª\r\n        prompt_data = {\r\n            \"user_query\": query,\r\n            \"domain\": \"architecture\",\r\n            \"language\": \"fa\"\r\n        }\r\n        # Generate prompt using manager\r\n        try:\r\n            gen = self.prompt_system.generate_prompt(\r\n                query=query,\r\n                task_type=\"architectural\",\r\n                template_name=template_type,\r\n                **prompt_data\r\n            )\r\n            prompt = gen[\"prompt\"] if isinstance(gen, dict) else gen\r\n        except Exception as e:\r\n            return {\"status\": \"error\", \"error\": str(e)}\r\n        \r\n        return {\r\n            \"method_details\": \"Prompt Engineering - Carefully crafted prompts\",\r\n            \"template_used\": template_type,\r\n            \"prompt\": prompt\r\n        }\r\n    \r\n    def _execute_peft(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ PEFT (Parameter-Efficient Fine-Tuning)\"\"\"\r\n        if not self.peft_system:\r\n            return {\"error\": \"PEFT system not available\"}\r\n        adapter = kwargs.get(\"adapter\", None)\r\n        technique = kwargs.get(\"technique\", None)\r\n        task = kwargs.get(\"task\", None)\r\n        result = self.peft_system.apply(query=query, task_type=task, adapter=adapter, technique=technique)\r\n        return {\r\n            \"method_details\": \"PEFT - Parameter-Efficient Fine-Tuning\",\r\n            \"technique\": result.get(\"technique\"),\r\n            \"adapter_used\": result.get(\"adapter\"),\r\n            \"peft_available\": result.get(\"peft_available\", False),\r\n            \"note\": result.get(\"note\")\r\n        }\r\n    \r\n    def hybrid_query(\r\n        self,\r\n        query: str,\r\n        methods: List[AIMethodType],\r\n        **kwargs\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Ù¾Ø±Ø³Ø´ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø§ Ú†Ù†Ø¯ Ø±ÙˆØ´ Ù‡Ù…Ø²Ù…Ø§Ù†\r\n        \r\n        Example: RAG + Prompt Engineering\r\n        \"\"\"\r\n        self.usage_stats[\"hybrid_calls\"] += 1\r\n        \r\n        responses = {}\r\n        for method in methods:\r\n            result = self._execute_query(query, method, None, **kwargs)\r\n            responses[method.value] = result\r\n        \r\n        return {\r\n            \"query\": query,\r\n            \"methods_used\": [m.value for m in methods],\r\n            \"timestamp\": datetime.now().isoformat(),\r\n            \"individual_responses\": responses,\r\n            \"hybrid\": True\r\n        }\r\n    \r\n    def get_system_status(self) -> Dict[str, Any]:\r\n        \"\"\"Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª Ú©Ø§Ù…Ù„ Ø³ÛŒØ³ØªÙ…\"\"\"\r\n        status = {\r\n            \"unified_ai_system\": {\r\n                \"status\": \"operational\",\r\n                \"methods_available\": []\r\n            },\r\n            \"rag\": None,\r\n            \"fine_tuning\": None,\r\n            \"lora\": None,\r\n            \"prompt_engineering\": None,\r\n            \"peft\": None,\r\n            \"security\": None,\r\n            \"usage_statistics\": self.usage_stats\r\n        }\r\n        \r\n        # RAG\r\n        if self.rag_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"RAG\")\r\n            status[\"rag\"] = self.rag_system.get_statistics()\r\n        \r\n        # Fine-Tuning\r\n        if self.fine_tuning_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"Fine-Tuning\")\r\n            status[\"fine_tuning\"] = self.fine_tuning_system\r\n        \r\n        # LoRA\r\n        if self.lora_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"LoRA\")\r\n            status[\"lora\"] = self.lora_system\r\n        \r\n        # Prompt Engineering\r\n        if self.prompt_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"Prompt Engineering\")\r\n            status[\"prompt_engineering\"] = {\"status\": \"ready\"}\r\n        \r\n        # PEFT\r\n        if self.peft_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"PEFT\")\r\n            status[\"peft\"] = self.peft_system.get_status()\r\n        \r\n        # Meta-Controller\r\n        if self.meta_controller:\r\n            status[\"meta_controller\"] = self.meta_controller.get_performance_stats()\r\n        \r\n        # Security\r\n        if self.security_dashboard:\r\n            status[\"security\"] = {\r\n                \"status\": self.security_dashboard.current_status.value,\r\n                \"mother_key_locked\": self.security_dashboard.mother_key.is_locked,\r\n                \"agents_created\": self.security_dashboard.agent_manager.total_created\r\n            }\r\n        \r\n        return status\r\n    \r\n    def compare_methods(self) -> Dict[str, Any]:\r\n        \"\"\"Ù…Ù‚Ø§ÛŒØ³Ù‡ 5 Ø±ÙˆØ´ AI\"\"\"\r\n        return {\r\n            \"comparison\": {\r\n                \"RAG\": {\r\n                    \"setup_time\": \"Minutes\",\r\n                    \"cost\": \"Low ($0-$10)\",\r\n                    \"quality\": \"Excellent for facts\",\r\n                    \"gpu_required\": False,\r\n                    \"best_for\": [\r\n                        \"Knowledge-based queries\",\r\n                        \"Frequently updated info\",\r\n                        \"Multi-document reasoning\",\r\n                        \"Transparent sources\"\r\n                    ],\r\n                    \"when_to_use\": \"Need accurate, source-backed answers\"\r\n                },\r\n                \"Fine-Tuning\": {\r\n                    \"setup_time\": \"Hours to Days\",\r\n                    \"cost\": \"Medium ($100-$1000)\",\r\n                    \"quality\": \"Excellent for specialized tasks\",\r\n                    \"gpu_required\": True,\r\n                    \"best_for\": [\r\n                        \"Domain-specific tasks\",\r\n                        \"Complex reasoning\",\r\n                        \"Consistent style\",\r\n                        \"Production deployment\"\r\n                    ],\r\n                    \"when_to_use\": \"Have labeled data, need specialized model\"\r\n                },\r\n                \"LoRA\": {\r\n                    \"setup_time\": \"Hours\",\r\n                    \"cost\": \"Low ($10-$100)\",\r\n                    \"quality\": \"Very good, efficient\",\r\n                    \"gpu_required\": True,\r\n                    \"best_for\": [\r\n                        \"Quick adaptation\",\r\n                        \"Multiple domains\",\r\n                        \"Resource-constrained\",\r\n                        \"Frequent updates\"\r\n                    ],\r\n                    \"when_to_use\": \"Need fast adaptation with less data\"\r\n                },\r\n                \"Prompt Engineering\": {\r\n                    \"setup_time\": \"Minutes\",\r\n                    \"cost\": \"Very Low ($0-$5)\",\r\n                    \"quality\": \"Good to Excellent\",\r\n                    \"gpu_required\": False,\r\n                    \"best_for\": [\r\n                        \"Quick prototyping\",\r\n                        \"General tasks\",\r\n                        \"No training data\",\r\n                        \"Flexible requirements\"\r\n                    ],\r\n                    \"when_to_use\": \"No training data, quick iteration needed\"\r\n                },\r\n                \"PEFT\": {\r\n                    \"setup_time\": \"Minutes to Hours\",\r\n                    \"cost\": \"Low ($0-$50)\",\r\n                    \"quality\": \"Very Good\",\r\n                    \"gpu_required\": False,\r\n                    \"best_for\": [\r\n                        \"Adapter-based domain updates\",\r\n                        \"Limited compute\",\r\n                        \"Multiple adapters\",\r\n                        \"Efficient updates\"\r\n                    ],\r\n                    \"when_to_use\": \"Need fast efficient fine-tuning without full retrain\"\r\n                }\r\n            },\r\n            \"recommendation\": {\r\n                \"start_with\": \"RAG + Prompt Engineering (lowest cost, fastest)\",\r\n                \"scale_to\": \"PEFT or LoRA or Fine-Tuning (better quality, specialized)\",\r\n                \"best_hybrid\": \"RAG + Prompt Engineering (knowledge + structure) + PEFT for adapters\",\r\n                \"production\": \"Fine-Tuning + RAG (specialized + updated info)\"\r\n            }\r\n        }\r\n    \r\n    def save_configuration(self, name: str = \"default\"):\r\n        \"\"\"Ø°Ø®ÛŒØ±Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ…\"\"\"\r\n        config = {\r\n            \"name\": name,\r\n            \"timestamp\": datetime.now().isoformat(),\r\n            \"auto_routing\": self.auto_routing,\r\n            \"usage_stats\": self.usage_stats,\r\n            \"systems\": {\r\n                \"rag\": self.rag_system is not None,\r\n                \"fine_tuning\": self.fine_tuning_system is not None,\r\n                \"lora\": self.lora_system is not None,\r\n                \"prompt\": self.prompt_system is not None,\r\n                \"peft\": self.peft_system is not None,\r\n                \"security\": self.security_dashboard is not None\r\n            }\r\n        }\r\n        \r\n        filepath = os.path.join(self.storage_dir, f\"{name}_config.json\")\r\n        with open(filepath, 'w', encoding='utf-8') as f:\r\n            json.dump(config, f, indent=2, ensure_ascii=False)\r\n        \r\n        logger.info(f\"âœ… Configuration saved: {filepath}\")\r\n\r\n# ===========================\r\n# Global Instance\r\n# ===========================\r\n\r\nunified_ai = UnifiedAISystem()\r\n",
    "format": "py"
  },
  {
    "timestamp": "2025-11-21T22:56:32.080Z",
    "fileName": "cad3d\\super_ai\\unified_ai_system.py",
    "content": "\"\"\"\r\nUnified AI System - ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ 5 Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ\r\nØªØ±Ú©ÛŒØ¨ RAG + Fine-Tuning + LoRA + Prompt Engineering + PEFT + Security\r\n\r\nØ§ÛŒÙ† Ø³ÛŒØ³ØªÙ… Ø¬Ø§Ù…Ø¹ Ù‡Ù…Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ AI Ø±Ø§ Ø¨Ø§ Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯\r\n\"\"\"\r\n\r\nimport logging\r\nimport os\r\nimport json\r\nfrom typing import Dict, List, Optional, Any\r\nfrom datetime import datetime\r\nfrom enum import Enum, auto\r\nimport time\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n# ===========================\r\n# AI Method Types\r\n# ===========================\r\n\r\nclass AIMethodType(Enum):\r\n    \"\"\"Ø§Ù†ÙˆØ§Ø¹ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ AI\"\"\"\r\n    RAG = \"retrieval_augmented_generation\"\r\n    FINE_TUNING = \"fine_tuning\"\r\n    LORA = \"low_rank_adaptation\"\r\n    PROMPT_ENGINEERING = \"prompt_engineering\"\r\n    PEFT = \"peft\"\r\n\r\nclass AITaskType(Enum):\r\n    \"\"\"Ø§Ù†ÙˆØ§Ø¹ ÙˆØ¸Ø§ÛŒÙ AI\"\"\"\r\n    CAD_ANALYSIS = auto()\r\n    ARCHITECTURAL_DESIGN = auto()\r\n    STRUCTURAL_CALCULATION = auto()\r\n    MEP_OPTIMIZATION = auto()\r\n    CODE_COMPLIANCE = auto()\r\n    MATERIAL_ESTIMATION = auto()\r\n    GENERAL_QUERY = auto()\r\n\r\n# ===========================\r\n# Unified AI System\r\n# ===========================\r\n\r\nclass UnifiedAISystem:\r\n    \"\"\"\r\n    Ø³ÛŒØ³ØªÙ… ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ AI Ø¨Ø§ 5 Ø±ÙˆØ´:\r\n    1. RAG - Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ùˆ ØªÙˆÙ„ÛŒØ¯\r\n    2. Fine-Tuning - Ø¢Ù…ÙˆØ²Ø´ Ø¹Ù…ÛŒÙ‚\r\n    3. LoRA - ØªØ·Ø¨ÛŒÙ‚ Ú©Ù…â€ŒØ±ØªØ¨Ù‡\r\n    4. Prompt Engineering - Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ù¾Ø±Ø§Ù…Ù¾Øª\r\n    5. PEFT - ØªÙ†Ø¸ÛŒÙ… Ú©Ø§Ø±Ø¢Ù…Ø¯ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§\r\n    \r\n    + ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ Ú©Ø§Ù…Ù„ Ø¨Ø§ Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ\r\n    \"\"\"\r\n    \r\n    def __init__(self, storage_dir: str = \"models/unified_ai\"):\r\n        self.storage_dir = storage_dir\r\n        os.makedirs(storage_dir, exist_ok=True)\r\n        \r\n        # Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ ÙØ±Ø¹ÛŒ\r\n        self.rag_system = None\r\n        self.fine_tuning_system = None\r\n        self.lora_system = None\r\n        self.prompt_system = None\r\n        self.peft_system = None\r\n        self.security_dashboard = None\r\n        self.meta_controller = None\r\n        \r\n        # Ø¢Ù…Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡\r\n        self.usage_stats = {\r\n            \"rag_calls\": 0,\r\n            \"fine_tuning_calls\": 0,\r\n            \"lora_calls\": 0,\r\n            \"prompt_calls\": 0,\r\n            \"peft_calls\": 0,\r\n            \"hybrid_calls\": 0,\r\n            \"total_queries\": 0\r\n        }\r\n        \r\n        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø±ÙˆØªÛŒÙ†Ú¯ Ø®ÙˆØ¯Ú©Ø§Ø±\r\n        self.auto_routing = True\r\n        \r\n        self._initialize_systems()\r\n    \r\n    def _initialize_systems(self):\r\n        \"\"\"Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ ØªÙ…Ø§Ù… Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ ÙØ±Ø¹ÛŒ\"\"\"\r\n        logger.info(\"=\"*80)\r\n        logger.info(\"ğŸš€ INITIALIZING UNIFIED AI SYSTEM\")\r\n        logger.info(\"=\"*80)\r\n        \r\n        # 1. RAG System\r\n        try:\r\n            from .rag_system import RAGSystem\r\n            self.rag_system = RAGSystem(storage_dir=os.path.join(self.storage_dir, \"rag\"))\r\n            logger.info(\"âœ… RAG System initialized\")\r\n        except Exception as e:\r\n            logger.error(f\"âŒ RAG System failed: {e}\")\r\n        \r\n        # 2. Fine-Tuning System (Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ)\r\n        self.fine_tuning_system = {\r\n            \"status\": \"ready\",\r\n            \"models\": [\"cad_analysis_v1\", \"architectural_design_v2\"],\r\n            \"last_training\": \"2025-11-20\"\r\n        }\r\n        logger.info(\"âœ… Fine-Tuning System initialized\")\r\n        \r\n        # 3. LoRA System (Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ)\r\n        self.lora_system = {\r\n            \"status\": \"ready\",\r\n            \"adapters\": [\"structural_calc\", \"mep_optimization\"],\r\n            \"rank\": 8\r\n        }\r\n        logger.info(\"âœ… LoRA System initialized\")\r\n        \r\n        # 4. Prompt Engineering System\r\n        from .prompt_engineering import PromptEngineeringManager\r\n        self.prompt_system = PromptEngineeringManager()\r\n        logger.info(\"âœ… Prompt Engineering System initialized\")\r\n        \r\n        # 5. PEFT System\r\n        try:\r\n            from .peft_system import PEFTManager\r\n            self.peft_system = PEFTManager()\r\n            logger.info(\"âœ… PEFT System initialized\")\r\n        except Exception as e:\r\n            logger.warning(f\"âš ï¸ PEFT System not available: {e}\")\r\n        \r\n        # 6. Meta-Controller (AI Method Selector)\r\n        try:\r\n            from .meta_controller import MetaController\r\n            self.meta_controller = MetaController()\r\n            logger.info(\"âœ… Meta-Controller initialized\")\r\n        except Exception as e:\r\n            logger.warning(f\"âš ï¸ Meta-Controller not available: {e}\")\r\n        \r\n        # 7. Security Dashboard\r\n        try:\r\n            from .advanced_security import SecurityDashboard\r\n            self.security_dashboard = SecurityDashboard()\r\n            logger.info(\"âœ… Security Dashboard integrated\")\r\n        except Exception as e:\r\n            logger.warning(f\"âš ï¸ Security Dashboard not available: {e}\")\r\n        \r\n        logger.info(\"=\"*80)\r\n        logger.info(\"ğŸ‰ UNIFIED AI SYSTEM READY\")\r\n        logger.info(\"=\"*80 + \"\\n\")\r\n    \r\n    def query(\r\n        self,\r\n        query: str,\r\n        method: Optional[AIMethodType] = None,\r\n        task_type: Optional[AITaskType] = None,\r\n        **kwargs\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Ù¾Ø±Ø³Ø´ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¨Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ø®ÙˆØ¯Ú©Ø§Ø± ÛŒØ§ Ø¯Ø³ØªÛŒ Ø±ÙˆØ´\r\n        \r\n        Args:\r\n            query: Ù¾Ø±Ø³Ø´ Ú©Ø§Ø±Ø¨Ø±\r\n            method: Ø±ÙˆØ´ AI (Ø§Ø®ØªÛŒØ§Ø±ÛŒ - Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒâ€ŒØ´ÙˆØ¯)\r\n            task_type: Ù†ÙˆØ¹ ÙˆØ¸ÛŒÙÙ‡ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)\r\n            **kwargs: Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ\r\n        \r\n        Returns:\r\n            Ù¾Ø§Ø³Ø® Ú©Ø§Ù…Ù„ Ø¨Ø§ Ù…ØªØ§Ø¯ÛŒØªØ§\r\n        \"\"\"\r\n        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ\r\n        if self.security_dashboard:\r\n            if not self._security_check(query):\r\n                return {\r\n                    \"error\": \"Security check failed\",\r\n                    \"status\": \"blocked\"\r\n                }\r\n        \r\n        # Ø§Ù†ØªØ®Ø§Ø¨ Ø®ÙˆØ¯Ú©Ø§Ø± Ø±ÙˆØ´\r\n        decision_explanation = None\r\n        if method is None and self.auto_routing:\r\n            method, decision_explanation = self._select_best_method(query, task_type)\r\n        \r\n        # Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª\r\n        start_time = time.time()\r\n        response = self._execute_query(query, method, task_type, **kwargs)\r\n        execution_time = time.time() - start_time\r\n        \r\n        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªÙˆØ¶ÛŒØ­Ø§Øª ØªØµÙ…ÛŒÙ…\r\n        if decision_explanation:\r\n            response[\"selection_reasoning\"] = decision_explanation\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø±\r\n        self.usage_stats[\"total_queries\"] += 1\r\n        if method == AIMethodType.RAG:\r\n            self.usage_stats[\"rag_calls\"] += 1\r\n        elif method == AIMethodType.FINE_TUNING:\r\n            self.usage_stats[\"fine_tuning_calls\"] += 1\r\n        elif method == AIMethodType.LORA:\r\n            self.usage_stats[\"lora_calls\"] += 1\r\n        elif method == AIMethodType.PROMPT_ENGINEERING:\r\n            self.usage_stats[\"prompt_calls\"] += 1\r\n        elif method == AIMethodType.PEFT:\r\n            self.usage_stats[\"peft_calls\"] += 1\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¯Ø± Meta-Controller\r\n        if self.meta_controller and decision_explanation:\r\n            success = response.get(\"status\") == \"success\"\r\n            method_name = self._method_enum_to_name(method)\r\n            self.meta_controller.update_performance(method_name, success, execution_time)\r\n        \r\n        return response\r\n    \r\n    def _security_check(self, query: str) -> bool:\r\n        \"\"\"Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ Ù¾Ø±Ø³Ø´\"\"\"\r\n        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ø´Ú©ÙˆÚ©\r\n        suspicious_patterns = [\r\n            \"delete\", \"drop\", \"truncate\", \"exec\",\r\n            \"system\", \"os.\", \"subprocess\", \"__import__\"\r\n        ]\r\n        \r\n        query_lower = query.lower()\r\n        for pattern in suspicious_patterns:\r\n            if pattern in query_lower:\r\n                logger.warning(f\"ğŸš¨ Suspicious pattern detected: {pattern}\")\r\n                return False\r\n        \r\n        return True\r\n    \r\n    def _select_best_method(\r\n        self,\r\n        query: str,\r\n        task_type: Optional[AITaskType]\r\n    ) -> tuple[AIMethodType, Optional[Dict]]:\r\n        \"\"\"\r\n        Ø§Ù†ØªØ®Ø§Ø¨ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´ Ø¨Ø§ Meta-Controller Ù‡ÙˆØ´Ù…Ù†Ø¯\r\n        \r\n        Ø§Ú¯Ø± Meta-Controller Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø² ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯\r\n        Ø¯Ø± ØºÛŒØ± Ø§ÛŒÙ† ØµÙˆØ±ØªØŒ Ø§Ø² Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒØ§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯\r\n        \"\"\"\r\n        \r\n        # Ø§Ú¯Ø± Meta-Controller Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³ØªØŒ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†\r\n        if self.meta_controller:\r\n            features = self.meta_controller.analyze_query(\r\n                query,\r\n                task_type.name if task_type else None\r\n            )\r\n            \r\n            method_name, score = self.meta_controller.select_best_method(features)\r\n            \r\n            # ØªØ¨Ø¯ÛŒÙ„ Ù†Ø§Ù… Ø¨Ù‡ enum\r\n            method_enum = self._name_to_method_enum(method_name)\r\n            \r\n            # ØªÙˆØ¶ÛŒØ­Ø§Øª ØªØµÙ…ÛŒÙ…\r\n            explanation = {\r\n                \"controller\": \"Meta-Controller (Intelligent)\",\r\n                \"selected_method\": method_name,\r\n                \"score\": f\"{score.score:.1f}\",\r\n                \"reasoning\": score.reasoning,\r\n                \"features\": {\r\n                    \"complexity\": features.complexity.value,\r\n                    \"domain\": features.domain,\r\n                    \"confidence_needed\": f\"{features.confidence_needed:.0%}\"\r\n                },\r\n                \"scores\": {\r\n                    \"speed\": f\"{score.speed_score:.1f}\",\r\n                    \"accuracy\": f\"{score.accuracy_score:.1f}\",\r\n                    \"cost\": f\"{score.cost_score:.1f}\"\r\n                }\r\n            }\r\n            \r\n            return method_enum, explanation\r\n        \r\n        # Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡ (Fallback)\r\n        return self._select_method_simple(query, task_type), {\r\n            \"controller\": \"Simple (Keyword-based)\",\r\n            \"note\": \"Meta-Controller not available\"\r\n        }\r\n    \r\n    def _select_method_simple(\r\n        self,\r\n        query: str,\r\n        task_type: Optional[AITaskType]\r\n    ) -> AIMethodType:\r\n        \"\"\"\r\n        Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ (Fallback)\r\n        \"\"\"\r\n        query_lower = query.lower()\r\n        \r\n        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ RAG (Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¯Ø§Ù†Ø´ ÙˆØ§Ù‚Ø¹ÛŒ)\r\n        rag_keywords = [\r\n            \"Ù…Ø­Ø§Ø³Ø¨Ù‡\", \"Ú†Ù‚Ø¯Ø±\", \"Ú†Ù†Ø¯\", \"Ù…Ø³Ø§Ø­Øª\", \"Ø­Ø¬Ù…\",\r\n            \"Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯\", \"Ø¶ÙˆØ§Ø¨Ø·\", \"Ù…Ø¨Ø­Ø«\", \"Ù‚Ø§Ù†ÙˆÙ†\",\r\n            \"calculate\", \"how much\", \"how many\", \"area\", \"volume\"\r\n        ]\r\n        \r\n        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Fine-Tuning (ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒÚ†ÛŒØ¯Ù‡)\r\n        fine_tuning_keywords = [\r\n            \"ØªØ­Ù„ÛŒÙ„\", \"Ø·Ø±Ø§Ø­ÛŒ\", \"Ø¨Ù‡ÛŒÙ†Ù‡\", \"Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯\",\r\n            \"analyze\", \"design\", \"optimize\", \"suggest\"\r\n        ]\r\n        \r\n        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ LoRA (ØªØ·Ø¨ÛŒÙ‚ Ø³Ø±ÛŒØ¹)\r\n        lora_keywords = [\r\n            \"Ø³Ø§Ø²Ù‡\", \"ØªØ§Ø³ÛŒØ³Ø§Øª\", \"Ø¨Ø±Ù‚\", \"Ù„ÙˆÙ„Ù‡â€ŒÚ©Ø´ÛŒ\",\r\n            \"structural\", \"mep\", \"electrical\", \"plumbing\"\r\n        ]\r\n        \r\n        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ PEFT (ÙÙ†Ø§ÙˆØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ø±Ø§Ù…ØªØ±-Ú©Ø§Ø±Ø§)\r\n        peft_keywords = [\r\n            \"peft\", \"prefix\", \"p-tuning\", \"ptuning\", \"ia3\", \"adalora\", \"qlora\", \"adapter\"\r\n        ]\r\n        \r\n        # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ\r\n        rag_score = sum(1 for kw in rag_keywords if kw in query_lower)\r\n        ft_score = sum(1 for kw in fine_tuning_keywords if kw in query_lower)\r\n        lora_score = sum(1 for kw in lora_keywords if kw in query_lower)\r\n        peft_score = sum(1 for kw in peft_keywords if kw in query_lower)\r\n        \r\n        # ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ\r\n        if rag_score >= 2:\r\n            return AIMethodType.RAG\r\n        elif ft_score >= 1 and task_type in [AITaskType.CAD_ANALYSIS, AITaskType.ARCHITECTURAL_DESIGN]:\r\n            return AIMethodType.FINE_TUNING\r\n        elif peft_score >= 1:\r\n            return AIMethodType.PEFT\r\n        elif lora_score >= 1:\r\n            return AIMethodType.LORA\r\n        else:\r\n            return AIMethodType.PROMPT_ENGINEERING\r\n    \r\n    def _name_to_method_enum(self, name: str) -> AIMethodType:\r\n        \"\"\"ØªØ¨Ø¯ÛŒÙ„ Ù†Ø§Ù… Ø±ÙˆØ´ Ø¨Ù‡ enum\"\"\"\r\n        mapping = {\r\n            \"RAG\": AIMethodType.RAG,\r\n            \"Fine-Tuning\": AIMethodType.FINE_TUNING,\r\n            \"LoRA\": AIMethodType.LORA,\r\n            \"Prompt Engineering\": AIMethodType.PROMPT_ENGINEERING,\r\n            \"PEFT\": AIMethodType.PEFT\r\n        }\r\n        return mapping.get(name, AIMethodType.PROMPT_ENGINEERING)\r\n    \r\n    def _method_enum_to_name(self, method: AIMethodType) -> str:\r\n        \"\"\"ØªØ¨Ø¯ÛŒÙ„ enum Ø¨Ù‡ Ù†Ø§Ù… Ø±ÙˆØ´\"\"\"\r\n        mapping = {\r\n            AIMethodType.RAG: \"RAG\",\r\n            AIMethodType.FINE_TUNING: \"Fine-Tuning\",\r\n            AIMethodType.LORA: \"LoRA\",\r\n            AIMethodType.PROMPT_ENGINEERING: \"Prompt Engineering\",\r\n            AIMethodType.PEFT: \"PEFT\"\r\n        }\r\n        return mapping.get(method, \"Prompt Engineering\")\r\n    \r\n    def _execute_query(\r\n        self,\r\n        query: str,\r\n        method: AIMethodType,\r\n        task_type: Optional[AITaskType],\r\n        **kwargs\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ Ù¾Ø±Ø³Ø´ Ø¨Ø§ Ø±ÙˆØ´ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡\"\"\"\r\n        \r\n        response = {\r\n            \"query\": query,\r\n            \"method\": method.value,\r\n            \"task_type\": task_type.name if task_type else None,\r\n            \"timestamp\": datetime.now().isoformat(),\r\n            \"status\": \"success\"\r\n        }\r\n        \r\n        try:\r\n            if method == AIMethodType.RAG:\r\n                result = self._execute_rag(query, **kwargs)\r\n            elif method == AIMethodType.FINE_TUNING:\r\n                result = self._execute_fine_tuning(query, **kwargs)\r\n            elif method == AIMethodType.LORA:\r\n                result = self._execute_lora(query, **kwargs)\r\n            elif method == AIMethodType.PROMPT_ENGINEERING:\r\n                result = self._execute_prompt(query, **kwargs)\r\n            elif method == AIMethodType.PEFT:\r\n                result = self._execute_peft(query, **kwargs)\r\n            else:\r\n                raise ValueError(f\"Unknown method: {method}\")\r\n            \r\n            response.update(result)\r\n            \r\n        except Exception as e:\r\n            logger.error(f\"âŒ Query execution failed: {e}\")\r\n            response[\"status\"] = \"error\"\r\n            response[\"error\"] = str(e)\r\n        \r\n        return response\r\n    \r\n    def _execute_rag(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ RAG\"\"\"\r\n        if not self.rag_system:\r\n            return {\"error\": \"RAG system not available\"}\r\n        \r\n        top_k = kwargs.get(\"top_k\", 3)\r\n        \r\n        # Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø³Ù†Ø§Ø¯\r\n        results = self.rag_system.retrieve(query, top_k=top_k)\r\n        \r\n        # ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®\r\n        rag_response = self.rag_system.generate_rag_response(query, top_k=top_k)\r\n        \r\n        return {\r\n            \"method_details\": \"RAG - Retrieval-Augmented Generation\",\r\n            \"retrieved_documents\": rag_response[\"retrieved_documents\"],\r\n            \"num_docs\": len(results),\r\n            \"prompt\": rag_response[\"prompt\"]\r\n        }\r\n    \r\n    def _execute_fine_tuning(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ Fine-Tuning\"\"\"\r\n        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Fine-Tuning\r\n        model_name = kwargs.get(\"model\", \"cad_analysis_v1\")\r\n        \r\n        return {\r\n            \"method_details\": \"Fine-Tuning - Specialized trained model\",\r\n            \"model_used\": model_name,\r\n            \"training_date\": self.fine_tuning_system[\"last_training\"],\r\n            \"note\": \"Using fine-tuned model for specialized CAD analysis\"\r\n        }\r\n    \r\n    def _execute_lora(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ LoRA\"\"\"\r\n        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ LoRA\r\n        adapter = kwargs.get(\"adapter\", \"structural_calc\")\r\n        \r\n        return {\r\n            \"method_details\": \"LoRA - Low-Rank Adaptation\",\r\n            \"adapter_used\": adapter,\r\n            \"rank\": self.lora_system[\"rank\"],\r\n            \"note\": \"Using LoRA adapter for efficient domain adaptation\"\r\n        }\r\n    \r\n    def _execute_prompt(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ Prompt Engineering\"\"\"\r\n        if not self.prompt_system:\r\n            return {\"error\": \"Prompt system not available\"}\r\n        \r\n        template_type = kwargs.get(\"template\", \"architectural_analysis\")\r\n        \r\n        # ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª\r\n        prompt_data = {\r\n            \"user_query\": query,\r\n            \"domain\": \"architecture\",\r\n            \"language\": \"fa\"\r\n        }\r\n        # Generate prompt using manager\r\n        try:\r\n            gen = self.prompt_system.generate_prompt(\r\n                query=query,\r\n                task_type=\"architectural\",\r\n                template_name=template_type,\r\n                **prompt_data\r\n            )\r\n            prompt = gen[\"prompt\"] if isinstance(gen, dict) else gen\r\n        except Exception as e:\r\n            return {\"status\": \"error\", \"error\": str(e)}\r\n        \r\n        return {\r\n            \"method_details\": \"Prompt Engineering - Carefully crafted prompts\",\r\n            \"template_used\": template_type,\r\n            \"prompt\": prompt\r\n        }\r\n    \r\n    def _execute_peft(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ PEFT (Parameter-Efficient Fine-Tuning)\"\"\"\r\n        if not self.peft_system:\r\n            return {\"error\": \"PEFT system not available\"}\r\n        adapter = kwargs.get(\"adapter\", None)\r\n        technique = kwargs.get(\"technique\", None)\r\n        task = kwargs.get(\"task\", None)\r\n        result = self.peft_system.apply(query=query, task_type=task, adapter=adapter, technique=technique)\r\n        return {\r\n            \"method_details\": \"PEFT - Parameter-Efficient Fine-Tuning\",\r\n            \"technique\": result.get(\"technique\"),\r\n            \"adapter_used\": result.get(\"adapter\"),\r\n            \"peft_available\": result.get(\"peft_available\", False),\r\n            \"note\": result.get(\"note\")\r\n        }\r\n    \r\n    def hybrid_query(\r\n        self,\r\n        query: str,\r\n        methods: List[AIMethodType],\r\n        **kwargs\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Ù¾Ø±Ø³Ø´ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø§ Ú†Ù†Ø¯ Ø±ÙˆØ´ Ù‡Ù…Ø²Ù…Ø§Ù†\r\n        \r\n        Example: RAG + Prompt Engineering\r\n        \"\"\"\r\n        self.usage_stats[\"hybrid_calls\"] += 1\r\n        \r\n        responses = {}\r\n        for method in methods:\r\n            result = self._execute_query(query, method, None, **kwargs)\r\n            responses[method.value] = result\r\n        \r\n        return {\r\n            \"query\": query,\r\n            \"methods_used\": [m.value for m in methods],\r\n            \"timestamp\": datetime.now().isoformat(),\r\n            \"individual_responses\": responses,\r\n            \"hybrid\": True\r\n        }\r\n    \r\n    def get_system_status(self) -> Dict[str, Any]:\r\n        \"\"\"Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª Ú©Ø§Ù…Ù„ Ø³ÛŒØ³ØªÙ…\"\"\"\r\n        status = {\r\n            \"unified_ai_system\": {\r\n                \"status\": \"operational\",\r\n                \"methods_available\": []\r\n            },\r\n            \"rag\": None,\r\n            \"fine_tuning\": None,\r\n            \"lora\": None,\r\n            \"prompt_engineering\": None,\r\n            \"peft\": None,\r\n            \"security\": None,\r\n            \"usage_statistics\": self.usage_stats\r\n        }\r\n        \r\n        # RAG\r\n        if self.rag_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"RAG\")\r\n            status[\"rag\"] = self.rag_system.get_statistics()\r\n        \r\n        # Fine-Tuning\r\n        if self.fine_tuning_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"Fine-Tuning\")\r\n            status[\"fine_tuning\"] = self.fine_tuning_system\r\n        \r\n        # LoRA\r\n        if self.lora_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"LoRA\")\r\n            status[\"lora\"] = self.lora_system\r\n        \r\n        # Prompt Engineering\r\n        if self.prompt_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"Prompt Engineering\")\r\n            status[\"prompt_engineering\"] = {\"status\": \"ready\"}\r\n        \r\n        # PEFT\r\n        if self.peft_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"PEFT\")\r\n            status[\"peft\"] = self.peft_system.get_status()\r\n        \r\n        # Meta-Controller\r\n        if self.meta_controller:\r\n            status[\"meta_controller\"] = self.meta_controller.get_performance_stats()\r\n        \r\n        # Security\r\n        if self.security_dashboard:\r\n            status[\"security\"] = {\r\n                \"status\": self.security_dashboard.current_status.value,\r\n                \"mother_key_locked\": self.security_dashboard.mother_key.is_locked,\r\n                \"agents_created\": self.security_dashboard.agent_manager.total_created\r\n            }\r\n        \r\n        return status\r\n    \r\n    def compare_methods(self) -> Dict[str, Any]:\r\n        \"\"\"Ù…Ù‚Ø§ÛŒØ³Ù‡ 5 Ø±ÙˆØ´ AI\"\"\"\r\n        return {\r\n            \"comparison\": {\r\n                \"RAG\": {\r\n                    \"setup_time\": \"Minutes\",\r\n                    \"cost\": \"Low ($0-$10)\",\r\n                    \"quality\": \"Excellent for facts\",\r\n                    \"gpu_required\": False,\r\n                    \"best_for\": [\r\n                        \"Knowledge-based queries\",\r\n                        \"Frequently updated info\",\r\n                        \"Multi-document reasoning\",\r\n                        \"Transparent sources\"\r\n                    ],\r\n                    \"when_to_use\": \"Need accurate, source-backed answers\"\r\n                },\r\n                \"Fine-Tuning\": {\r\n                    \"setup_time\": \"Hours to Days\",\r\n                    \"cost\": \"Medium ($100-$1000)\",\r\n                    \"quality\": \"Excellent for specialized tasks\",\r\n                    \"gpu_required\": True,\r\n                    \"best_for\": [\r\n                        \"Domain-specific tasks\",\r\n                        \"Complex reasoning\",\r\n                        \"Consistent style\",\r\n                        \"Production deployment\"\r\n                    ],\r\n                    \"when_to_use\": \"Have labeled data, need specialized model\"\r\n                },\r\n                \"LoRA\": {\r\n                    \"setup_time\": \"Hours\",\r\n                    \"cost\": \"Low ($10-$100)\",\r\n                    \"quality\": \"Very good, efficient\",\r\n                    \"gpu_required\": True,\r\n                    \"best_for\": [\r\n                        \"Quick adaptation\",\r\n                        \"Multiple domains\",\r\n                        \"Resource-constrained\",\r\n                        \"Frequent updates\"\r\n                    ],\r\n                    \"when_to_use\": \"Need fast adaptation with less data\"\r\n                },\r\n                \"Prompt Engineering\": {\r\n                    \"setup_time\": \"Minutes\",\r\n                    \"cost\": \"Very Low ($0-$5)\",\r\n                    \"quality\": \"Good to Excellent\",\r\n                    \"gpu_required\": False,\r\n                    \"best_for\": [\r\n                        \"Quick prototyping\",\r\n                        \"General tasks\",\r\n                        \"No training data\",\r\n                        \"Flexible requirements\"\r\n                    ],\r\n                    \"when_to_use\": \"No training data, quick iteration needed\"\r\n                },\r\n                \"PEFT\": {\r\n                    \"setup_time\": \"Minutes to Hours\",\r\n                    \"cost\": \"Low ($0-$50)\",\r\n                    \"quality\": \"Very Good\",\r\n                    \"gpu_required\": False,\r\n                    \"best_for\": [\r\n                        \"Adapter-based domain updates\",\r\n                        \"Limited compute\",\r\n                        \"Multiple adapters\",\r\n                        \"Efficient updates\"\r\n                    ],\r\n                    \"when_to_use\": \"Need fast efficient fine-tuning without full retrain\"\r\n                }\r\n            },\r\n            \"recommendation\": {\r\n                \"start_with\": \"RAG + Prompt Engineering (lowest cost, fastest)\",\r\n                \"scale_to\": \"PEFT or LoRA or Fine-Tuning (better quality, specialized)\",\r\n                \"best_hybrid\": \"RAG + Prompt Engineering (knowledge + structure) + PEFT for adapters\",\r\n                \"production\": \"Fine-Tuning + RAG (specialized + updated info)\"\r\n            }\r\n        }\r\n    \r\n    def save_configuration(self, name: str = \"default\"):\r\n        \"\"\"Ø°Ø®ÛŒØ±Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ…\"\"\"\r\n        config = {\r\n            \"name\": name,\r\n            \"timestamp\": datetime.now().isoformat(),\r\n            \"auto_routing\": self.auto_routing,\r\n            \"usage_stats\": self.usage_stats,\r\n            \"systems\": {\r\n                \"rag\": self.rag_system is not None,\r\n                \"fine_tuning\": self.fine_tuning_system is not None,\r\n                \"lora\": self.lora_system is not None,\r\n                \"prompt\": self.prompt_system is not None,\r\n                \"peft\": self.peft_system is not None,\r\n                \"security\": self.security_dashboard is not None\r\n            }\r\n        }\r\n        \r\n        filepath = os.path.join(self.storage_dir, f\"{name}_config.json\")\r\n        with open(filepath, 'w', encoding='utf-8') as f:\r\n            json.dump(config, f, indent=2, ensure_ascii=False)\r\n        \r\n        logger.info(f\"âœ… Configuration saved: {filepath}\")\r\n    \r\n    def explain_selection(self, query: str, task_type: Optional[AITaskType] = None) -> Dict:\r\n        \"\"\"\r\n        ØªÙˆØ¶ÛŒØ­ Ø¯Ù„ÛŒÙ„ Ø§Ù†ØªØ®Ø§Ø¨ Ø±ÙˆØ´ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù¾Ø±Ø³Ø´ (Ø¨Ø¯ÙˆÙ† Ø§Ø¬Ø±Ø§)\r\n        \r\n        Args:\r\n            query: Ù¾Ø±Ø³Ø´ Ú©Ø§Ø±Ø¨Ø±\r\n            task_type: Ù†ÙˆØ¹ ÙˆØ¸ÛŒÙÙ‡ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)\r\n        \r\n        Returns:\r\n            ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ø§Ù…Ù„ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ\r\n        \"\"\"\r\n        if not self.meta_controller:\r\n            return {\r\n                \"error\": \"Meta-Controller not available\",\r\n                \"fallback\": \"Using simple keyword-based selection\"\r\n            }\r\n        \r\n        features = self.meta_controller.analyze_query(\r\n            query,\r\n            task_type.name if task_type else None\r\n        )\r\n        \r\n        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ù‡Ù…Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§\r\n        all_methods = [\"RAG\", \"Fine-Tuning\", \"LoRA\", \"Prompt Engineering\", \"PEFT\"]\r\n        scores = []\r\n        \r\n        for method in all_methods:\r\n            score = self.meta_controller._score_method(method, features)\r\n            scores.append(score)\r\n        \r\n        scores.sort(key=lambda x: x.score, reverse=True)\r\n        \r\n        best_method = scores[0].method\r\n        best_score = scores[0]\r\n        \r\n        return self.meta_controller.explain_decision(\r\n            query,\r\n            features,\r\n            best_method,\r\n            best_score,\r\n            scores\r\n        )\r\n    \r\n    def get_performance_stats(self) -> Dict:\r\n        \"\"\"Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ Meta-Controller\"\"\"\r\n        if not self.meta_controller:\r\n            return {\"error\": \"Meta-Controller not available\"}\r\n        \r\n        return self.meta_controller.get_performance_stats()\r\n\r\n# ===========================\r\n# Global Instance\r\n# ===========================\r\n\r\nunified_ai = UnifiedAISystem()\r\n",
    "format": "py"
  },
  {
    "timestamp": "2025-11-21T22:56:47.023Z",
    "fileName": "cad3d\\super_ai\\unified_ai_system.py",
    "content": "\"\"\"\r\nUnified AI System - ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ 5 Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ\r\nØªØ±Ú©ÛŒØ¨ RAG + Fine-Tuning + LoRA + Prompt Engineering + PEFT + Security\r\n\r\nØ§ÛŒÙ† Ø³ÛŒØ³ØªÙ… Ø¬Ø§Ù…Ø¹ Ù‡Ù…Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ AI Ø±Ø§ Ø¨Ø§ Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯\r\n\"\"\"\r\n\r\nimport logging\r\nimport os\r\nimport json\r\nfrom typing import Dict, List, Optional, Any\r\nfrom datetime import datetime\r\nfrom enum import Enum, auto\r\nimport time\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n# ===========================\r\n# AI Method Types\r\n# ===========================\r\n\r\nclass AIMethodType(Enum):\r\n    \"\"\"Ø§Ù†ÙˆØ§Ø¹ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ AI\"\"\"\r\n    RAG = \"retrieval_augmented_generation\"\r\n    FINE_TUNING = \"fine_tuning\"\r\n    LORA = \"low_rank_adaptation\"\r\n    PROMPT_ENGINEERING = \"prompt_engineering\"\r\n    PEFT = \"peft\"\r\n\r\nclass AITaskType(Enum):\r\n    \"\"\"Ø§Ù†ÙˆØ§Ø¹ ÙˆØ¸Ø§ÛŒÙ AI\"\"\"\r\n    CAD_ANALYSIS = auto()\r\n    ARCHITECTURAL_DESIGN = auto()\r\n    STRUCTURAL_CALCULATION = auto()\r\n    MEP_OPTIMIZATION = auto()\r\n    CODE_COMPLIANCE = auto()\r\n    MATERIAL_ESTIMATION = auto()\r\n    GENERAL_QUERY = auto()\r\n\r\n# ===========================\r\n# Unified AI System\r\n# ===========================\r\n\r\nclass UnifiedAISystem:\r\n    \"\"\"\r\n    Ø³ÛŒØ³ØªÙ… ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ AI Ø¨Ø§ 5 Ø±ÙˆØ´:\r\n    1. RAG - Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ùˆ ØªÙˆÙ„ÛŒØ¯\r\n    2. Fine-Tuning - Ø¢Ù…ÙˆØ²Ø´ Ø¹Ù…ÛŒÙ‚\r\n    3. LoRA - ØªØ·Ø¨ÛŒÙ‚ Ú©Ù…â€ŒØ±ØªØ¨Ù‡\r\n    4. Prompt Engineering - Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ù¾Ø±Ø§Ù…Ù¾Øª\r\n    5. PEFT - ØªÙ†Ø¸ÛŒÙ… Ú©Ø§Ø±Ø¢Ù…Ø¯ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§\r\n    \r\n    + ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ Ú©Ø§Ù…Ù„ Ø¨Ø§ Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ\r\n    \"\"\"\r\n    \r\n    def __init__(self, storage_dir: str = \"models/unified_ai\"):\r\n        self.storage_dir = storage_dir\r\n        os.makedirs(storage_dir, exist_ok=True)\r\n        \r\n        # Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ ÙØ±Ø¹ÛŒ\r\n        self.rag_system = None\r\n        self.fine_tuning_system = None\r\n        self.lora_system = None\r\n        self.prompt_system = None\r\n        self.peft_system = None\r\n        self.security_dashboard = None\r\n        self.meta_controller = None\r\n        \r\n        # Ø¢Ù…Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡\r\n        self.usage_stats = {\r\n            \"rag_calls\": 0,\r\n            \"fine_tuning_calls\": 0,\r\n            \"lora_calls\": 0,\r\n            \"prompt_calls\": 0,\r\n            \"peft_calls\": 0,\r\n            \"hybrid_calls\": 0,\r\n            \"total_queries\": 0\r\n        }\r\n        \r\n        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø±ÙˆØªÛŒÙ†Ú¯ Ø®ÙˆØ¯Ú©Ø§Ø±\r\n        self.auto_routing = True\r\n        \r\n        self._initialize_systems()\r\n    \r\n    def _initialize_systems(self):\r\n        \"\"\"Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ ØªÙ…Ø§Ù… Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ ÙØ±Ø¹ÛŒ\"\"\"\r\n        logger.info(\"=\"*80)\r\n        logger.info(\"ğŸš€ INITIALIZING UNIFIED AI SYSTEM\")\r\n        logger.info(\"=\"*80)\r\n        \r\n        # 1. RAG System\r\n        try:\r\n            from .rag_system import RAGSystem\r\n            self.rag_system = RAGSystem(storage_dir=os.path.join(self.storage_dir, \"rag\"))\r\n            logger.info(\"âœ… RAG System initialized\")\r\n        except Exception as e:\r\n            logger.error(f\"âŒ RAG System failed: {e}\")\r\n        \r\n        # 2. Fine-Tuning System (Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ)\r\n        self.fine_tuning_system = {\r\n            \"status\": \"ready\",\r\n            \"models\": [\"cad_analysis_v1\", \"architectural_design_v2\"],\r\n            \"last_training\": \"2025-11-20\"\r\n        }\r\n        logger.info(\"âœ… Fine-Tuning System initialized\")\r\n        \r\n        # 3. LoRA System (Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ)\r\n        self.lora_system = {\r\n            \"status\": \"ready\",\r\n            \"adapters\": [\"structural_calc\", \"mep_optimization\"],\r\n            \"rank\": 8\r\n        }\r\n        logger.info(\"âœ… LoRA System initialized\")\r\n        \r\n        # 4. Prompt Engineering System\r\n        from .prompt_engineering import PromptEngineeringManager\r\n        self.prompt_system = PromptEngineeringManager()\r\n        logger.info(\"âœ… Prompt Engineering System initialized\")\r\n        \r\n        # 5. PEFT System\r\n        try:\r\n            from .peft_system import PEFTManager\r\n            self.peft_system = PEFTManager()\r\n            logger.info(\"âœ… PEFT System initialized\")\r\n        except Exception as e:\r\n            logger.warning(f\"âš ï¸ PEFT System not available: {e}\")\r\n        \r\n        # 6. Meta-Controller (AI Method Selector)\r\n        try:\r\n            from .meta_controller import MetaController\r\n            self.meta_controller = MetaController()\r\n            logger.info(\"âœ… Meta-Controller initialized\")\r\n        except Exception as e:\r\n            logger.warning(f\"âš ï¸ Meta-Controller not available: {e}\")\r\n        \r\n        # 7. Security Dashboard\r\n        try:\r\n            from .advanced_security import SecurityDashboard\r\n            self.security_dashboard = SecurityDashboard()\r\n            logger.info(\"âœ… Security Dashboard integrated\")\r\n        except Exception as e:\r\n            logger.warning(f\"âš ï¸ Security Dashboard not available: {e}\")\r\n        \r\n        logger.info(\"=\"*80)\r\n        logger.info(\"ğŸ‰ UNIFIED AI SYSTEM READY\")\r\n        logger.info(\"=\"*80 + \"\\n\")\r\n    \r\n    def query(\r\n        self,\r\n        query: str,\r\n        method: Optional[AIMethodType] = None,\r\n        task_type: Optional[AITaskType] = None,\r\n        **kwargs\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Ù¾Ø±Ø³Ø´ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¨Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ø®ÙˆØ¯Ú©Ø§Ø± ÛŒØ§ Ø¯Ø³ØªÛŒ Ø±ÙˆØ´\r\n        \r\n        Args:\r\n            query: Ù¾Ø±Ø³Ø´ Ú©Ø§Ø±Ø¨Ø±\r\n            method: Ø±ÙˆØ´ AI (Ø§Ø®ØªÛŒØ§Ø±ÛŒ - Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒâ€ŒØ´ÙˆØ¯)\r\n            task_type: Ù†ÙˆØ¹ ÙˆØ¸ÛŒÙÙ‡ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)\r\n            **kwargs: Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ\r\n        \r\n        Returns:\r\n            Ù¾Ø§Ø³Ø® Ú©Ø§Ù…Ù„ Ø¨Ø§ Ù…ØªØ§Ø¯ÛŒØªØ§\r\n        \"\"\"\r\n        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ\r\n        if self.security_dashboard:\r\n            if not self._security_check(query):\r\n                return {\r\n                    \"error\": \"Security check failed\",\r\n                    \"status\": \"blocked\"\r\n                }\r\n        \r\n        # Ø§Ù†ØªØ®Ø§Ø¨ Ø®ÙˆØ¯Ú©Ø§Ø± Ø±ÙˆØ´\r\n        decision_explanation = None\r\n        if method is None and self.auto_routing:\r\n            method, decision_explanation = self._select_best_method(query, task_type)\r\n        \r\n        # Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª\r\n        start_time = time.time()\r\n        response = self._execute_query(query, method, task_type, **kwargs)\r\n        execution_time = time.time() - start_time\r\n        \r\n        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªÙˆØ¶ÛŒØ­Ø§Øª ØªØµÙ…ÛŒÙ…\r\n        if decision_explanation:\r\n            response[\"selection_reasoning\"] = decision_explanation\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø±\r\n        self.usage_stats[\"total_queries\"] += 1\r\n        if method == AIMethodType.RAG:\r\n            self.usage_stats[\"rag_calls\"] += 1\r\n        elif method == AIMethodType.FINE_TUNING:\r\n            self.usage_stats[\"fine_tuning_calls\"] += 1\r\n        elif method == AIMethodType.LORA:\r\n            self.usage_stats[\"lora_calls\"] += 1\r\n        elif method == AIMethodType.PROMPT_ENGINEERING:\r\n            self.usage_stats[\"prompt_calls\"] += 1\r\n        elif method == AIMethodType.PEFT:\r\n            self.usage_stats[\"peft_calls\"] += 1\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¯Ø± Meta-Controller\r\n        if self.meta_controller and decision_explanation:\r\n            success = response.get(\"status\") == \"success\"\r\n            method_name = self._method_enum_to_name(method)\r\n            self.meta_controller.update_performance(method_name, success, execution_time)\r\n        \r\n        return response\r\n    \r\n    def _security_check(self, query: str) -> bool:\r\n        \"\"\"Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ Ù¾Ø±Ø³Ø´\"\"\"\r\n        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ø´Ú©ÙˆÚ©\r\n        suspicious_patterns = [\r\n            \"delete\", \"drop\", \"truncate\", \"exec\",\r\n            \"system\", \"os.\", \"subprocess\", \"__import__\"\r\n        ]\r\n        \r\n        query_lower = query.lower()\r\n        for pattern in suspicious_patterns:\r\n            if pattern in query_lower:\r\n                logger.warning(f\"ğŸš¨ Suspicious pattern detected: {pattern}\")\r\n                return False\r\n        \r\n        return True\r\n    \r\n    def _select_best_method(\r\n        self,\r\n        query: str,\r\n        task_type: Optional[AITaskType]\r\n    ) -> tuple[AIMethodType, Optional[Dict]]:\r\n        \"\"\"\r\n        Ø§Ù†ØªØ®Ø§Ø¨ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´ Ø¨Ø§ Meta-Controller Ù‡ÙˆØ´Ù…Ù†Ø¯\r\n        \r\n        Ø§Ú¯Ø± Meta-Controller Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø² ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯\r\n        Ø¯Ø± ØºÛŒØ± Ø§ÛŒÙ† ØµÙˆØ±ØªØŒ Ø§Ø² Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒØ§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯\r\n        \"\"\"\r\n        \r\n        # Ø§Ú¯Ø± Meta-Controller Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³ØªØŒ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†\r\n        if self.meta_controller:\r\n            features = self.meta_controller.analyze_query(\r\n                query,\r\n                task_type.name if task_type else None\r\n            )\r\n            \r\n            method_name, score = self.meta_controller.select_best_method(features)\r\n            \r\n            # ØªØ¨Ø¯ÛŒÙ„ Ù†Ø§Ù… Ø¨Ù‡ enum\r\n            method_enum = self._name_to_method_enum(method_name)\r\n            \r\n            # ØªÙˆØ¶ÛŒØ­Ø§Øª ØªØµÙ…ÛŒÙ…\r\n            explanation = {\r\n                \"controller\": \"Meta-Controller (Intelligent)\",\r\n                \"selected_method\": method_name,\r\n                \"score\": f\"{score.score:.1f}\",\r\n                \"reasoning\": score.reasoning,\r\n                \"features\": {\r\n                    \"complexity\": features.complexity.value,\r\n                    \"domain\": features.domain,\r\n                    \"confidence_needed\": f\"{features.confidence_needed:.0%}\"\r\n                },\r\n                \"scores\": {\r\n                    \"speed\": f\"{score.speed_score:.1f}\",\r\n                    \"accuracy\": f\"{score.accuracy_score:.1f}\",\r\n                    \"cost\": f\"{score.cost_score:.1f}\"\r\n                }\r\n            }\r\n            \r\n            return method_enum, explanation\r\n        \r\n        # Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡ (Fallback)\r\n        return self._select_method_simple(query, task_type), {\r\n            \"controller\": \"Simple (Keyword-based)\",\r\n            \"note\": \"Meta-Controller not available\"\r\n        }\r\n    \r\n    def _select_method_simple(\r\n        self,\r\n        query: str,\r\n        task_type: Optional[AITaskType]\r\n    ) -> AIMethodType:\r\n        \"\"\"\r\n        Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ (Fallback)\r\n        \"\"\"\r\n        query_lower = query.lower()\r\n        \r\n        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ RAG (Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¯Ø§Ù†Ø´ ÙˆØ§Ù‚Ø¹ÛŒ)\r\n        rag_keywords = [\r\n            \"Ù…Ø­Ø§Ø³Ø¨Ù‡\", \"Ú†Ù‚Ø¯Ø±\", \"Ú†Ù†Ø¯\", \"Ù…Ø³Ø§Ø­Øª\", \"Ø­Ø¬Ù…\",\r\n            \"Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯\", \"Ø¶ÙˆØ§Ø¨Ø·\", \"Ù…Ø¨Ø­Ø«\", \"Ù‚Ø§Ù†ÙˆÙ†\",\r\n            \"calculate\", \"how much\", \"how many\", \"area\", \"volume\"\r\n        ]\r\n        \r\n        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Fine-Tuning (ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒÚ†ÛŒØ¯Ù‡)\r\n        fine_tuning_keywords = [\r\n            \"ØªØ­Ù„ÛŒÙ„\", \"Ø·Ø±Ø§Ø­ÛŒ\", \"Ø¨Ù‡ÛŒÙ†Ù‡\", \"Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯\",\r\n            \"analyze\", \"design\", \"optimize\", \"suggest\"\r\n        ]\r\n        \r\n        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ LoRA (ØªØ·Ø¨ÛŒÙ‚ Ø³Ø±ÛŒØ¹)\r\n        lora_keywords = [\r\n            \"Ø³Ø§Ø²Ù‡\", \"ØªØ§Ø³ÛŒØ³Ø§Øª\", \"Ø¨Ø±Ù‚\", \"Ù„ÙˆÙ„Ù‡â€ŒÚ©Ø´ÛŒ\",\r\n            \"structural\", \"mep\", \"electrical\", \"plumbing\"\r\n        ]\r\n        \r\n        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ PEFT (ÙÙ†Ø§ÙˆØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ø±Ø§Ù…ØªØ±-Ú©Ø§Ø±Ø§)\r\n        peft_keywords = [\r\n            \"peft\", \"prefix\", \"p-tuning\", \"ptuning\", \"ia3\", \"adalora\", \"qlora\", \"adapter\"\r\n        ]\r\n        \r\n        # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ\r\n        rag_score = sum(1 for kw in rag_keywords if kw in query_lower)\r\n        ft_score = sum(1 for kw in fine_tuning_keywords if kw in query_lower)\r\n        lora_score = sum(1 for kw in lora_keywords if kw in query_lower)\r\n        peft_score = sum(1 for kw in peft_keywords if kw in query_lower)\r\n        \r\n        # ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ\r\n        if rag_score >= 2:\r\n            return AIMethodType.RAG\r\n        elif ft_score >= 1 and task_type in [AITaskType.CAD_ANALYSIS, AITaskType.ARCHITECTURAL_DESIGN]:\r\n            return AIMethodType.FINE_TUNING\r\n        elif peft_score >= 1:\r\n            return AIMethodType.PEFT\r\n        elif lora_score >= 1:\r\n            return AIMethodType.LORA\r\n        else:\r\n            return AIMethodType.PROMPT_ENGINEERING\r\n    \r\n    def _name_to_method_enum(self, name: str) -> AIMethodType:\r\n        \"\"\"ØªØ¨Ø¯ÛŒÙ„ Ù†Ø§Ù… Ø±ÙˆØ´ Ø¨Ù‡ enum\"\"\"\r\n        mapping = {\r\n            \"RAG\": AIMethodType.RAG,\r\n            \"Fine-Tuning\": AIMethodType.FINE_TUNING,\r\n            \"LoRA\": AIMethodType.LORA,\r\n            \"Prompt Engineering\": AIMethodType.PROMPT_ENGINEERING,\r\n            \"PEFT\": AIMethodType.PEFT\r\n        }\r\n        return mapping.get(name, AIMethodType.PROMPT_ENGINEERING)\r\n    \r\n    def _method_enum_to_name(self, method: AIMethodType) -> str:\r\n        \"\"\"ØªØ¨Ø¯ÛŒÙ„ enum Ø¨Ù‡ Ù†Ø§Ù… Ø±ÙˆØ´\"\"\"\r\n        mapping = {\r\n            AIMethodType.RAG: \"RAG\",\r\n            AIMethodType.FINE_TUNING: \"Fine-Tuning\",\r\n            AIMethodType.LORA: \"LoRA\",\r\n            AIMethodType.PROMPT_ENGINEERING: \"Prompt Engineering\",\r\n            AIMethodType.PEFT: \"PEFT\"\r\n        }\r\n        return mapping.get(method, \"Prompt Engineering\")\r\n    \r\n    def _execute_query(\r\n        self,\r\n        query: str,\r\n        method: AIMethodType,\r\n        task_type: Optional[AITaskType],\r\n        **kwargs\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ Ù¾Ø±Ø³Ø´ Ø¨Ø§ Ø±ÙˆØ´ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡\"\"\"\r\n        \r\n        response = {\r\n            \"query\": query,\r\n            \"method\": method.value,\r\n            \"task_type\": task_type.name if task_type else None,\r\n            \"timestamp\": datetime.now().isoformat(),\r\n            \"status\": \"success\"\r\n        }\r\n        \r\n        try:\r\n            if method == AIMethodType.RAG:\r\n                result = self._execute_rag(query, **kwargs)\r\n            elif method == AIMethodType.FINE_TUNING:\r\n                result = self._execute_fine_tuning(query, **kwargs)\r\n            elif method == AIMethodType.LORA:\r\n                result = self._execute_lora(query, **kwargs)\r\n            elif method == AIMethodType.PROMPT_ENGINEERING:\r\n                result = self._execute_prompt(query, **kwargs)\r\n            elif method == AIMethodType.PEFT:\r\n                result = self._execute_peft(query, **kwargs)\r\n            else:\r\n                raise ValueError(f\"Unknown method: {method}\")\r\n            \r\n            response.update(result)\r\n            \r\n        except Exception as e:\r\n            logger.error(f\"âŒ Query execution failed: {e}\")\r\n            response[\"status\"] = \"error\"\r\n            response[\"error\"] = str(e)\r\n        \r\n        return response\r\n    \r\n    def _execute_rag(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ RAG\"\"\"\r\n        if not self.rag_system:\r\n            return {\"error\": \"RAG system not available\"}\r\n        \r\n        top_k = kwargs.get(\"top_k\", 3)\r\n        \r\n        # Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø³Ù†Ø§Ø¯\r\n        results = self.rag_system.retrieve(query, top_k=top_k)\r\n        \r\n        # ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®\r\n        rag_response = self.rag_system.generate_rag_response(query, top_k=top_k)\r\n        \r\n        return {\r\n            \"method_details\": \"RAG - Retrieval-Augmented Generation\",\r\n            \"retrieved_documents\": rag_response[\"retrieved_documents\"],\r\n            \"num_docs\": len(results),\r\n            \"prompt\": rag_response[\"prompt\"]\r\n        }\r\n    \r\n    def _execute_fine_tuning(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ Fine-Tuning\"\"\"\r\n        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Fine-Tuning\r\n        model_name = kwargs.get(\"model\", \"cad_analysis_v1\")\r\n        \r\n        return {\r\n            \"method_details\": \"Fine-Tuning - Specialized trained model\",\r\n            \"model_used\": model_name,\r\n            \"training_date\": self.fine_tuning_system[\"last_training\"],\r\n            \"note\": \"Using fine-tuned model for specialized CAD analysis\"\r\n        }\r\n    \r\n    def _execute_lora(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ LoRA\"\"\"\r\n        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ LoRA\r\n        adapter = kwargs.get(\"adapter\", \"structural_calc\")\r\n        \r\n        return {\r\n            \"method_details\": \"LoRA - Low-Rank Adaptation\",\r\n            \"adapter_used\": adapter,\r\n            \"rank\": self.lora_system[\"rank\"],\r\n            \"note\": \"Using LoRA adapter for efficient domain adaptation\"\r\n        }\r\n    \r\n    def _execute_prompt(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ Prompt Engineering\"\"\"\r\n        if not self.prompt_system:\r\n            return {\"error\": \"Prompt system not available\"}\r\n        \r\n        template_type = kwargs.get(\"template\", \"architectural_analysis\")\r\n        \r\n        # ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª\r\n        prompt_data = {\r\n            \"user_query\": query,\r\n            \"domain\": \"architecture\",\r\n            \"language\": \"fa\"\r\n        }\r\n        # Generate prompt using manager\r\n        try:\r\n            gen = self.prompt_system.generate_prompt(\r\n                query=query,\r\n                task_type=\"architectural\",\r\n                template_name=template_type,\r\n                **prompt_data\r\n            )\r\n            prompt = gen[\"prompt\"] if isinstance(gen, dict) else gen\r\n        except Exception as e:\r\n            return {\"status\": \"error\", \"error\": str(e)}\r\n        \r\n        return {\r\n            \"method_details\": \"Prompt Engineering - Carefully crafted prompts\",\r\n            \"template_used\": template_type,\r\n            \"prompt\": prompt\r\n        }\r\n    \r\n    def _execute_peft(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ PEFT (Parameter-Efficient Fine-Tuning)\"\"\"\r\n        if not self.peft_system:\r\n            return {\"error\": \"PEFT system not available\"}\r\n        adapter = kwargs.get(\"adapter\", None)\r\n        technique = kwargs.get(\"technique\", None)\r\n        task = kwargs.get(\"task\", None)\r\n        result = self.peft_system.apply(query=query, task_type=task, adapter=adapter, technique=technique)\r\n        return {\r\n            \"method_details\": \"PEFT - Parameter-Efficient Fine-Tuning\",\r\n            \"technique\": result.get(\"technique\"),\r\n            \"adapter_used\": result.get(\"adapter\"),\r\n            \"peft_available\": result.get(\"peft_available\", False),\r\n            \"note\": result.get(\"note\")\r\n        }\r\n    \r\n    def hybrid_query(\r\n        self,\r\n        query: str,\r\n        methods: List[AIMethodType],\r\n        **kwargs\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Ù¾Ø±Ø³Ø´ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø§ Ú†Ù†Ø¯ Ø±ÙˆØ´ Ù‡Ù…Ø²Ù…Ø§Ù†\r\n        \r\n        Example: RAG + Prompt Engineering\r\n        \"\"\"\r\n        self.usage_stats[\"hybrid_calls\"] += 1\r\n        \r\n        responses = {}\r\n        for method in methods:\r\n            result = self._execute_query(query, method, None, **kwargs)\r\n            responses[method.value] = result\r\n        \r\n        return {\r\n            \"query\": query,\r\n            \"methods_used\": [m.value for m in methods],\r\n            \"timestamp\": datetime.now().isoformat(),\r\n            \"individual_responses\": responses,\r\n            \"hybrid\": True\r\n        }\r\n    \r\n    def get_system_status(self) -> Dict[str, Any]:\r\n        \"\"\"Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª Ú©Ø§Ù…Ù„ Ø³ÛŒØ³ØªÙ…\"\"\"\r\n        status = {\r\n            \"unified_ai_system\": {\r\n                \"status\": \"operational\",\r\n                \"methods_available\": []\r\n            },\r\n            \"rag\": None,\r\n            \"fine_tuning\": None,\r\n            \"lora\": None,\r\n            \"prompt_engineering\": None,\r\n            \"peft\": None,\r\n            \"security\": None,\r\n            \"usage_statistics\": self.usage_stats\r\n        }\r\n        \r\n        # RAG\r\n        if self.rag_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"RAG\")\r\n            status[\"rag\"] = self.rag_system.get_statistics()\r\n        \r\n        # Fine-Tuning\r\n        if self.fine_tuning_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"Fine-Tuning\")\r\n            status[\"fine_tuning\"] = self.fine_tuning_system\r\n        \r\n        # LoRA\r\n        if self.lora_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"LoRA\")\r\n            status[\"lora\"] = self.lora_system\r\n        \r\n        # Prompt Engineering\r\n        if self.prompt_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"Prompt Engineering\")\r\n            status[\"prompt_engineering\"] = {\"status\": \"ready\"}\r\n        \r\n        # PEFT\r\n        if self.peft_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"PEFT\")\r\n            status[\"peft\"] = self.peft_system.get_status()\r\n        \r\n        # Meta-Controller\r\n        if self.meta_controller:\r\n            status[\"meta_controller\"] = self.meta_controller.get_performance_stats()\r\n        \r\n        # Security\r\n        if self.security_dashboard:\r\n            status[\"security\"] = {\r\n                \"status\": self.security_dashboard.current_status.value,\r\n                \"mother_key_locked\": self.security_dashboard.mother_key.is_locked,\r\n                \"agents_created\": self.security_dashboard.agent_manager.total_created\r\n            }\r\n        \r\n        return status\r\n    \r\n    def compare_methods(self) -> Dict[str, Any]:\r\n        \"\"\"Ù…Ù‚Ø§ÛŒØ³Ù‡ 5 Ø±ÙˆØ´ AI\"\"\"\r\n        return {\r\n            \"comparison\": {\r\n                \"RAG\": {\r\n                    \"setup_time\": \"Minutes\",\r\n                    \"cost\": \"Low ($0-$10)\",\r\n                    \"quality\": \"Excellent for facts\",\r\n                    \"gpu_required\": False,\r\n                    \"best_for\": [\r\n                        \"Knowledge-based queries\",\r\n                        \"Frequently updated info\",\r\n                        \"Multi-document reasoning\",\r\n                        \"Transparent sources\"\r\n                    ],\r\n                    \"when_to_use\": \"Need accurate, source-backed answers\"\r\n                },\r\n                \"Fine-Tuning\": {\r\n                    \"setup_time\": \"Hours to Days\",\r\n                    \"cost\": \"Medium ($100-$1000)\",\r\n                    \"quality\": \"Excellent for specialized tasks\",\r\n                    \"gpu_required\": True,\r\n                    \"best_for\": [\r\n                        \"Domain-specific tasks\",\r\n                        \"Complex reasoning\",\r\n                        \"Consistent style\",\r\n                        \"Production deployment\"\r\n                    ],\r\n                    \"when_to_use\": \"Have labeled data, need specialized model\"\r\n                },\r\n                \"LoRA\": {\r\n                    \"setup_time\": \"Hours\",\r\n                    \"cost\": \"Low ($10-$100)\",\r\n                    \"quality\": \"Very good, efficient\",\r\n                    \"gpu_required\": True,\r\n                    \"best_for\": [\r\n                        \"Quick adaptation\",\r\n                        \"Multiple domains\",\r\n                        \"Resource-constrained\",\r\n                        \"Frequent updates\"\r\n                    ],\r\n                    \"when_to_use\": \"Need fast adaptation with less data\"\r\n                },\r\n                \"Prompt Engineering\": {\r\n                    \"setup_time\": \"Minutes\",\r\n                    \"cost\": \"Very Low ($0-$5)\",\r\n                    \"quality\": \"Good to Excellent\",\r\n                    \"gpu_required\": False,\r\n                    \"best_for\": [\r\n                        \"Quick prototyping\",\r\n                        \"General tasks\",\r\n                        \"No training data\",\r\n                        \"Flexible requirements\"\r\n                    ],\r\n                    \"when_to_use\": \"No training data, quick iteration needed\"\r\n                },\r\n                \"PEFT\": {\r\n                    \"setup_time\": \"Minutes to Hours\",\r\n                    \"cost\": \"Low ($0-$50)\",\r\n                    \"quality\": \"Very Good\",\r\n                    \"gpu_required\": False,\r\n                    \"best_for\": [\r\n                        \"Adapter-based domain updates\",\r\n                        \"Limited compute\",\r\n                        \"Multiple adapters\",\r\n                        \"Efficient updates\"\r\n                    ],\r\n                    \"when_to_use\": \"Need fast efficient fine-tuning without full retrain\"\r\n                }\r\n            },\r\n            \"recommendation\": {\r\n                \"start_with\": \"RAG + Prompt Engineering (lowest cost, fastest)\",\r\n                \"scale_to\": \"PEFT or LoRA or Fine-Tuning (better quality, specialized)\",\r\n                \"best_hybrid\": \"RAG + Prompt Engineering (knowledge + structure) + PEFT for adapters\",\r\n                \"production\": \"Fine-Tuning + RAG (specialized + updated info)\"\r\n            }\r\n        }\r\n    \r\n    def save_configuration(self, name: str = \"default\"):\r\n        \"\"\"Ø°Ø®ÛŒØ±Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ…\"\"\"\r\n        config = {\r\n            \"name\": name,\r\n            \"timestamp\": datetime.now().isoformat(),\r\n            \"auto_routing\": self.auto_routing,\r\n            \"usage_stats\": self.usage_stats,\r\n            \"systems\": {\r\n                \"rag\": self.rag_system is not None,\r\n                \"fine_tuning\": self.fine_tuning_system is not None,\r\n                \"lora\": self.lora_system is not None,\r\n                \"prompt\": self.prompt_system is not None,\r\n                \"peft\": self.peft_system is not None,\r\n                \"security\": self.security_dashboard is not None\r\n            }\r\n        }\r\n        \r\n        filepath = os.path.join(self.storage_dir, f\"{name}_config.json\")\r\n        with open(filepath, 'w', encoding='utf-8') as f:\r\n            json.dump(config, f, indent=2, ensure_ascii=False)\r\n        \r\n        logger.info(f\"âœ… Configuration saved: {filepath}\")\r\n    \r\n    def explain_selection(self, query: str, task_type: Optional[AITaskType] = None) -> Dict:\r\n        \"\"\"\r\n        ØªÙˆØ¶ÛŒØ­ Ø¯Ù„ÛŒÙ„ Ø§Ù†ØªØ®Ø§Ø¨ Ø±ÙˆØ´ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù¾Ø±Ø³Ø´ (Ø¨Ø¯ÙˆÙ† Ø§Ø¬Ø±Ø§)\r\n        \r\n        Args:\r\n            query: Ù¾Ø±Ø³Ø´ Ú©Ø§Ø±Ø¨Ø±\r\n            task_type: Ù†ÙˆØ¹ ÙˆØ¸ÛŒÙÙ‡ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)\r\n        \r\n        Returns:\r\n            ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ø§Ù…Ù„ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ\r\n        \"\"\"\r\n        if not self.meta_controller:\r\n            return {\r\n                \"error\": \"Meta-Controller not available\",\r\n                \"fallback\": \"Using simple keyword-based selection\"\r\n            }\r\n        \r\n        features = self.meta_controller.analyze_query(\r\n            query,\r\n            task_type.name if task_type else None\r\n        )\r\n        \r\n        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ù‡Ù…Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§\r\n        all_methods = [\"RAG\", \"Fine-Tuning\", \"LoRA\", \"Prompt Engineering\", \"PEFT\"]\r\n        scores = []\r\n        \r\n        for method in all_methods:\r\n            score = self.meta_controller._score_method(method, features)\r\n            scores.append(score)\r\n        \r\n        scores.sort(key=lambda x: x.score, reverse=True)\r\n        \r\n        best_method = scores[0].method\r\n        best_score = scores[0]\r\n        \r\n        return self.meta_controller.explain_decision(\r\n            query,\r\n            features,\r\n            best_method,\r\n            best_score,\r\n            scores\r\n        )\r\n    \r\n    def get_performance_stats(self) -> Dict:\r\n        \"\"\"Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ Meta-Controller\"\"\"\r\n        if not self.meta_controller:\r\n            return {\"error\": \"Meta-Controller not available\"}\r\n        \r\n        return self.meta_controller.get_performance_stats()\r\n\r\n# ===========================\r\n# Global Instance\r\n# ===========================\r\n\r\nunified_ai = UnifiedAISystem()\r\n",
    "format": "py"
  },
  {
    "timestamp": "2025-11-21T23:06:36.721Z",
    "fileName": "cad3d\\super_ai\\unified_ai_system.py",
    "content": "\"\"\"\r\nUnified AI System - ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ 5 Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ\r\nØªØ±Ú©ÛŒØ¨ RAG + Fine-Tuning + LoRA + Prompt Engineering + PEFT + Security\r\n\r\nØ§ÛŒÙ† Ø³ÛŒØ³ØªÙ… Ø¬Ø§Ù…Ø¹ Ù‡Ù…Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ AI Ø±Ø§ Ø¨Ø§ Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯\r\n\"\"\"\r\n\r\nimport logging\r\nimport os\r\nimport json\r\nfrom typing import Dict, List, Optional, Any\r\nfrom datetime import datetime\r\nfrom enum import Enum, auto\r\nimport time\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n# ===========================\r\n# AI Method Types\r\n# ===========================\r\n\r\nclass AIMethodType(Enum):\r\n    \"\"\"Ø§Ù†ÙˆØ§Ø¹ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ AI\"\"\"\r\n    RAG = \"retrieval_augmented_generation\"\r\n    FINE_TUNING = \"fine_tuning\"\r\n    LORA = \"low_rank_adaptation\"\r\n    PROMPT_ENGINEERING = \"prompt_engineering\"\r\n    PEFT = \"peft\"\r\n\r\nclass AITaskType(Enum):\r\n    \"\"\"Ø§Ù†ÙˆØ§Ø¹ ÙˆØ¸Ø§ÛŒÙ AI\"\"\"\r\n    CAD_ANALYSIS = auto()\r\n    ARCHITECTURAL_DESIGN = auto()\r\n    STRUCTURAL_CALCULATION = auto()\r\n    MEP_OPTIMIZATION = auto()\r\n    CODE_COMPLIANCE = auto()\r\n    MATERIAL_ESTIMATION = auto()\r\n    GENERAL_QUERY = auto()\r\n\r\n# ===========================\r\n# Unified AI System\r\n# ===========================\r\n\r\nclass UnifiedAISystem:\r\n    \"\"\"\r\n    Ø³ÛŒØ³ØªÙ… ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ AI Ø¨Ø§ 5 Ø±ÙˆØ´:\r\n    1. RAG - Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ùˆ ØªÙˆÙ„ÛŒØ¯\r\n    2. Fine-Tuning - Ø¢Ù…ÙˆØ²Ø´ Ø¹Ù…ÛŒÙ‚\r\n    3. LoRA - ØªØ·Ø¨ÛŒÙ‚ Ú©Ù…â€ŒØ±ØªØ¨Ù‡\r\n    4. Prompt Engineering - Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ù¾Ø±Ø§Ù…Ù¾Øª\r\n    5. PEFT - ØªÙ†Ø¸ÛŒÙ… Ú©Ø§Ø±Ø¢Ù…Ø¯ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§\r\n    \r\n    + ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ Ú©Ø§Ù…Ù„ Ø¨Ø§ Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ\r\n    \"\"\"\r\n    \r\n    def __init__(self, storage_dir: str = \"models/unified_ai\"):\r\n        self.storage_dir = storage_dir\r\n        os.makedirs(storage_dir, exist_ok=True)\r\n        \r\n        # Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ ÙØ±Ø¹ÛŒ\r\n        self.rag_system = None\r\n        self.fine_tuning_system = None\r\n        self.lora_system = None\r\n        self.prompt_system = None\r\n        self.peft_system = None\r\n        self.security_dashboard = None\r\n        self.meta_controller = None\r\n        \r\n        # Ø¢Ù…Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡\r\n        self.usage_stats = {\r\n            \"rag_calls\": 0,\r\n            \"fine_tuning_calls\": 0,\r\n            \"lora_calls\": 0,\r\n            \"prompt_calls\": 0,\r\n            \"peft_calls\": 0,\r\n            \"hybrid_calls\": 0,\r\n            \"total_queries\": 0\r\n        }\r\n        \r\n        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø±ÙˆØªÛŒÙ†Ú¯ Ø®ÙˆØ¯Ú©Ø§Ø±\r\n        self.auto_routing = True\r\n        \r\n        self._initialize_systems()\r\n    \r\n    def _initialize_systems(self):\r\n        \"\"\"Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ ØªÙ…Ø§Ù… Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ ÙØ±Ø¹ÛŒ\"\"\"\r\n        logger.info(\"=\"*80)\r\n        logger.info(\"ğŸš€ INITIALIZING UNIFIED AI SYSTEM\")\r\n        logger.info(\"=\"*80)\r\n        \r\n        # 1. RAG System\r\n        try:\r\n            from .rag_system import RAGSystem\r\n            self.rag_system = RAGSystem(storage_dir=os.path.join(self.storage_dir, \"rag\"))\r\n            logger.info(\"âœ… RAG System initialized\")\r\n        except Exception as e:\r\n            logger.error(f\"âŒ RAG System failed: {e}\")\r\n        \r\n        # 2. Fine-Tuning System (Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ)\r\n        self.fine_tuning_system = {\r\n            \"status\": \"ready\",\r\n            \"models\": [\"cad_analysis_v1\", \"architectural_design_v2\"],\r\n            \"last_training\": \"2025-11-20\"\r\n        }\r\n        logger.info(\"âœ… Fine-Tuning System initialized\")\r\n        \r\n        # 3. LoRA System (Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ)\r\n        self.lora_system = {\r\n            \"status\": \"ready\",\r\n            \"adapters\": [\"structural_calc\", \"mep_optimization\"],\r\n            \"rank\": 8\r\n        }\r\n        logger.info(\"âœ… LoRA System initialized\")\r\n        \r\n        # 4. Prompt Engineering System\r\n        from .prompt_engineering import PromptEngineeringManager\r\n        self.prompt_system = PromptEngineeringManager()\r\n        logger.info(\"âœ… Prompt Engineering System initialized\")\r\n        \r\n        # 5. PEFT System\r\n        try:\r\n            from .peft_system import PEFTManager\r\n            self.peft_system = PEFTManager()\r\n            logger.info(\"âœ… PEFT System initialized\")\r\n        except Exception as e:\r\n            logger.warning(f\"âš ï¸ PEFT System not available: {e}\")\r\n        \r\n        # 6. Meta-Controller (AI Method Selector)\r\n        try:\r\n            from .meta_controller import MetaController\r\n            self.meta_controller = MetaController()\r\n            logger.info(\"âœ… Meta-Controller initialized\")\r\n        except Exception as e:\r\n            logger.warning(f\"âš ï¸ Meta-Controller not available: {e}\")\r\n        \r\n        # 7. Security Dashboard\r\n        try:\r\n            from .advanced_security import SecurityDashboard\r\n            self.security_dashboard = SecurityDashboard()\r\n            logger.info(\"âœ… Security Dashboard integrated\")\r\n        except Exception as e:\r\n            logger.warning(f\"âš ï¸ Security Dashboard not available: {e}\")\r\n        \r\n        logger.info(\"=\"*80)\r\n        logger.info(\"ğŸ‰ UNIFIED AI SYSTEM READY\")\r\n        logger.info(\"=\"*80 + \"\\n\")\r\n    \r\n    def query(\r\n        self,\r\n        query: str,\r\n        method: Optional[AIMethodType] = None,\r\n        task_type: Optional[AITaskType] = None,\r\n        **kwargs\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Ù¾Ø±Ø³Ø´ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¨Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ø®ÙˆØ¯Ú©Ø§Ø± ÛŒØ§ Ø¯Ø³ØªÛŒ Ø±ÙˆØ´\r\n        \r\n        Args:\r\n            query: Ù¾Ø±Ø³Ø´ Ú©Ø§Ø±Ø¨Ø±\r\n            method: Ø±ÙˆØ´ AI (Ø§Ø®ØªÛŒØ§Ø±ÛŒ - Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒâ€ŒØ´ÙˆØ¯)\r\n            task_type: Ù†ÙˆØ¹ ÙˆØ¸ÛŒÙÙ‡ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)\r\n            **kwargs: Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ\r\n        \r\n        Returns:\r\n            Ù¾Ø§Ø³Ø® Ú©Ø§Ù…Ù„ Ø¨Ø§ Ù…ØªØ§Ø¯ÛŒØªØ§\r\n        \"\"\"\r\n        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ\r\n        if self.security_dashboard:\r\n            if not self._security_check(query):\r\n                return {\r\n                    \"error\": \"Security check failed\",\r\n                    \"status\": \"blocked\"\r\n                }\r\n        \r\n        # Ø§Ù†ØªØ®Ø§Ø¨ Ø®ÙˆØ¯Ú©Ø§Ø± Ø±ÙˆØ´\r\n        decision_explanation = None\r\n        if method is None and self.auto_routing:\r\n            method, decision_explanation = self._select_best_method(query, task_type)\r\n        \r\n        # Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª\r\n        start_time = time.time()\r\n        response = self._execute_query(query, method, task_type, **kwargs)\r\n        execution_time = time.time() - start_time\r\n        \r\n        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªÙˆØ¶ÛŒØ­Ø§Øª ØªØµÙ…ÛŒÙ…\r\n        if decision_explanation:\r\n            response[\"selection_reasoning\"] = decision_explanation\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø±\r\n        self.usage_stats[\"total_queries\"] += 1\r\n        if method == AIMethodType.RAG:\r\n            self.usage_stats[\"rag_calls\"] += 1\r\n        elif method == AIMethodType.FINE_TUNING:\r\n            self.usage_stats[\"fine_tuning_calls\"] += 1\r\n        elif method == AIMethodType.LORA:\r\n            self.usage_stats[\"lora_calls\"] += 1\r\n        elif method == AIMethodType.PROMPT_ENGINEERING:\r\n            self.usage_stats[\"prompt_calls\"] += 1\r\n        elif method == AIMethodType.PEFT:\r\n            self.usage_stats[\"peft_calls\"] += 1\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¯Ø± Meta-Controller\r\n        if self.meta_controller and decision_explanation:\r\n            success = response.get(\"status\") == \"success\"\r\n            method_name = self._method_enum_to_name(method)\r\n            self.meta_controller.update_performance(method_name, success, execution_time)\r\n        \r\n        return response\r\n    \r\n    def _security_check(self, query: str) -> bool:\r\n        \"\"\"Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ Ù¾Ø±Ø³Ø´\"\"\"\r\n        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ø´Ú©ÙˆÚ©\r\n        suspicious_patterns = [\r\n            \"delete\", \"drop\", \"truncate\", \"exec\",\r\n            \"system\", \"os.\", \"subprocess\", \"__import__\"\r\n        ]\r\n        \r\n        query_lower = query.lower()\r\n        for pattern in suspicious_patterns:\r\n            if pattern in query_lower:\r\n                logger.warning(f\"ğŸš¨ Suspicious pattern detected: {pattern}\")\r\n                return False\r\n        \r\n        return True\r\n    \r\n    def _select_best_method(\r\n        self,\r\n        query: str,\r\n        task_type: Optional[AITaskType]\r\n    ) -> tuple[AIMethodType, Optional[Dict]]:\r\n        \"\"\"\r\n        Ø§Ù†ØªØ®Ø§Ø¨ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´ Ø¨Ø§ Meta-Controller Ù‡ÙˆØ´Ù…Ù†Ø¯\r\n        \r\n        Ø§Ú¯Ø± Meta-Controller Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø² ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯\r\n        Ø¯Ø± ØºÛŒØ± Ø§ÛŒÙ† ØµÙˆØ±ØªØŒ Ø§Ø² Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒØ§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯\r\n        \"\"\"\r\n        \r\n        query_lower = query.lower()\r\n        \r\n        # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒ ØµØ±ÛŒØ­ (Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§Ù„Ø§)\r\n        explicit_methods = {\r\n            \"rag\": AIMethodType.RAG,\r\n            \"retrieval\": AIMethodType.RAG,\r\n            \"fine-tun\": AIMethodType.FINE_TUNING,\r\n            \"fine tun\": AIMethodType.FINE_TUNING,\r\n            \"lora\": AIMethodType.LORA,\r\n            \"peft\": AIMethodType.PEFT,\r\n            \"prompt\": AIMethodType.PROMPT_ENGINEERING\r\n        }\r\n        \r\n        for keyword, method in explicit_methods.items():\r\n            if keyword in query_lower:\r\n                return method, {\r\n                    \"controller\": \"Explicit Keyword\",\r\n                    \"keyword\": keyword,\r\n                    \"note\": f\"User explicitly requested {method.value}\"\r\n                }\r\n        \r\n        # Ø§Ú¯Ø± Meta-Controller Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³ØªØŒ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†\r\n        if self.meta_controller:\r\n            features = self.meta_controller.analyze_query(\r\n                query,\r\n                task_type.name if task_type else None\r\n            )\r\n            \r\n            method_name, score = self.meta_controller.select_best_method(features)\r\n            \r\n            # ØªØ¨Ø¯ÛŒÙ„ Ù†Ø§Ù… Ø¨Ù‡ enum\r\n            method_enum = self._name_to_method_enum(method_name)\r\n            \r\n            # ØªÙˆØ¶ÛŒØ­Ø§Øª ØªØµÙ…ÛŒÙ…\r\n            explanation = {\r\n                \"controller\": \"Meta-Controller (Intelligent)\",\r\n                \"selected_method\": method_name,\r\n                \"score\": f\"{score.score:.1f}\",\r\n                \"reasoning\": score.reasoning,\r\n                \"features\": {\r\n                    \"complexity\": features.complexity.value,\r\n                    \"domain\": features.domain,\r\n                    \"confidence_needed\": f\"{features.confidence_needed:.0%}\"\r\n                },\r\n                \"scores\": {\r\n                    \"speed\": f\"{score.speed_score:.1f}\",\r\n                    \"accuracy\": f\"{score.accuracy_score:.1f}\",\r\n                    \"cost\": f\"{score.cost_score:.1f}\"\r\n                }\r\n            }\r\n            \r\n            return method_enum, explanation\r\n        \r\n        # Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡ (Fallback)\r\n        return self._select_method_simple(query, task_type), {\r\n            \"controller\": \"Simple (Keyword-based)\",\r\n            \"note\": \"Meta-Controller not available\"\r\n        }\r\n    \r\n    def _select_method_simple(\r\n        self,\r\n        query: str,\r\n        task_type: Optional[AITaskType]\r\n    ) -> AIMethodType:\r\n        \"\"\"\r\n        Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ (Fallback)\r\n        \"\"\"\r\n        query_lower = query.lower()\r\n        \r\n        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ RAG (Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¯Ø§Ù†Ø´ ÙˆØ§Ù‚Ø¹ÛŒ)\r\n        rag_keywords = [\r\n            \"Ù…Ø­Ø§Ø³Ø¨Ù‡\", \"Ú†Ù‚Ø¯Ø±\", \"Ú†Ù†Ø¯\", \"Ù…Ø³Ø§Ø­Øª\", \"Ø­Ø¬Ù…\",\r\n            \"Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯\", \"Ø¶ÙˆØ§Ø¨Ø·\", \"Ù…Ø¨Ø­Ø«\", \"Ù‚Ø§Ù†ÙˆÙ†\",\r\n            \"calculate\", \"how much\", \"how many\", \"area\", \"volume\"\r\n        ]\r\n        \r\n        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Fine-Tuning (ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒÚ†ÛŒØ¯Ù‡)\r\n        fine_tuning_keywords = [\r\n            \"ØªØ­Ù„ÛŒÙ„\", \"Ø·Ø±Ø§Ø­ÛŒ\", \"Ø¨Ù‡ÛŒÙ†Ù‡\", \"Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯\",\r\n            \"analyze\", \"design\", \"optimize\", \"suggest\"\r\n        ]\r\n        \r\n        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ LoRA (ØªØ·Ø¨ÛŒÙ‚ Ø³Ø±ÛŒØ¹)\r\n        lora_keywords = [\r\n            \"Ø³Ø§Ø²Ù‡\", \"ØªØ§Ø³ÛŒØ³Ø§Øª\", \"Ø¨Ø±Ù‚\", \"Ù„ÙˆÙ„Ù‡â€ŒÚ©Ø´ÛŒ\",\r\n            \"structural\", \"mep\", \"electrical\", \"plumbing\"\r\n        ]\r\n        \r\n        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ PEFT (ÙÙ†Ø§ÙˆØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ø±Ø§Ù…ØªØ±-Ú©Ø§Ø±Ø§)\r\n        peft_keywords = [\r\n            \"peft\", \"prefix\", \"p-tuning\", \"ptuning\", \"ia3\", \"adalora\", \"qlora\", \"adapter\"\r\n        ]\r\n        \r\n        # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ\r\n        rag_score = sum(1 for kw in rag_keywords if kw in query_lower)\r\n        ft_score = sum(1 for kw in fine_tuning_keywords if kw in query_lower)\r\n        lora_score = sum(1 for kw in lora_keywords if kw in query_lower)\r\n        peft_score = sum(1 for kw in peft_keywords if kw in query_lower)\r\n        \r\n        # ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ\r\n        if rag_score >= 2:\r\n            return AIMethodType.RAG\r\n        elif ft_score >= 1 and task_type in [AITaskType.CAD_ANALYSIS, AITaskType.ARCHITECTURAL_DESIGN]:\r\n            return AIMethodType.FINE_TUNING\r\n        elif peft_score >= 1:\r\n            return AIMethodType.PEFT\r\n        elif lora_score >= 1:\r\n            return AIMethodType.LORA\r\n        else:\r\n            return AIMethodType.PROMPT_ENGINEERING\r\n    \r\n    def _name_to_method_enum(self, name: str) -> AIMethodType:\r\n        \"\"\"ØªØ¨Ø¯ÛŒÙ„ Ù†Ø§Ù… Ø±ÙˆØ´ Ø¨Ù‡ enum\"\"\"\r\n        mapping = {\r\n            \"RAG\": AIMethodType.RAG,\r\n            \"Fine-Tuning\": AIMethodType.FINE_TUNING,\r\n            \"LoRA\": AIMethodType.LORA,\r\n            \"Prompt Engineering\": AIMethodType.PROMPT_ENGINEERING,\r\n            \"PEFT\": AIMethodType.PEFT\r\n        }\r\n        return mapping.get(name, AIMethodType.PROMPT_ENGINEERING)\r\n    \r\n    def _method_enum_to_name(self, method: AIMethodType) -> str:\r\n        \"\"\"ØªØ¨Ø¯ÛŒÙ„ enum Ø¨Ù‡ Ù†Ø§Ù… Ø±ÙˆØ´\"\"\"\r\n        mapping = {\r\n            AIMethodType.RAG: \"RAG\",\r\n            AIMethodType.FINE_TUNING: \"Fine-Tuning\",\r\n            AIMethodType.LORA: \"LoRA\",\r\n            AIMethodType.PROMPT_ENGINEERING: \"Prompt Engineering\",\r\n            AIMethodType.PEFT: \"PEFT\"\r\n        }\r\n        return mapping.get(method, \"Prompt Engineering\")\r\n    \r\n    def _execute_query(\r\n        self,\r\n        query: str,\r\n        method: AIMethodType,\r\n        task_type: Optional[AITaskType],\r\n        **kwargs\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ Ù¾Ø±Ø³Ø´ Ø¨Ø§ Ø±ÙˆØ´ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡\"\"\"\r\n        \r\n        response = {\r\n            \"query\": query,\r\n            \"method\": method.value,\r\n            \"task_type\": task_type.name if task_type else None,\r\n            \"timestamp\": datetime.now().isoformat(),\r\n            \"status\": \"success\"\r\n        }\r\n        \r\n        try:\r\n            if method == AIMethodType.RAG:\r\n                result = self._execute_rag(query, **kwargs)\r\n            elif method == AIMethodType.FINE_TUNING:\r\n                result = self._execute_fine_tuning(query, **kwargs)\r\n            elif method == AIMethodType.LORA:\r\n                result = self._execute_lora(query, **kwargs)\r\n            elif method == AIMethodType.PROMPT_ENGINEERING:\r\n                result = self._execute_prompt(query, **kwargs)\r\n            elif method == AIMethodType.PEFT:\r\n                result = self._execute_peft(query, **kwargs)\r\n            else:\r\n                raise ValueError(f\"Unknown method: {method}\")\r\n            \r\n            response.update(result)\r\n            \r\n        except Exception as e:\r\n            logger.error(f\"âŒ Query execution failed: {e}\")\r\n            response[\"status\"] = \"error\"\r\n            response[\"error\"] = str(e)\r\n        \r\n        return response\r\n    \r\n    def _execute_rag(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ RAG\"\"\"\r\n        if not self.rag_system:\r\n            return {\"error\": \"RAG system not available\"}\r\n        \r\n        top_k = kwargs.get(\"top_k\", 3)\r\n        \r\n        # Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø³Ù†Ø§Ø¯\r\n        results = self.rag_system.retrieve(query, top_k=top_k)\r\n        \r\n        # ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®\r\n        rag_response = self.rag_system.generate_rag_response(query, top_k=top_k)\r\n        \r\n        return {\r\n            \"method_details\": \"RAG - Retrieval-Augmented Generation\",\r\n            \"retrieved_documents\": rag_response[\"retrieved_documents\"],\r\n            \"num_docs\": len(results),\r\n            \"prompt\": rag_response[\"prompt\"]\r\n        }\r\n    \r\n    def _execute_fine_tuning(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ Fine-Tuning\"\"\"\r\n        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Fine-Tuning\r\n        model_name = kwargs.get(\"model\", \"cad_analysis_v1\")\r\n        \r\n        return {\r\n            \"method_details\": \"Fine-Tuning - Specialized trained model\",\r\n            \"model_used\": model_name,\r\n            \"training_date\": self.fine_tuning_system[\"last_training\"],\r\n            \"note\": \"Using fine-tuned model for specialized CAD analysis\"\r\n        }\r\n    \r\n    def _execute_lora(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ LoRA\"\"\"\r\n        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ LoRA\r\n        adapter = kwargs.get(\"adapter\", \"structural_calc\")\r\n        \r\n        return {\r\n            \"method_details\": \"LoRA - Low-Rank Adaptation\",\r\n            \"adapter_used\": adapter,\r\n            \"rank\": self.lora_system[\"rank\"],\r\n            \"note\": \"Using LoRA adapter for efficient domain adaptation\"\r\n        }\r\n    \r\n    def _execute_prompt(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ Prompt Engineering\"\"\"\r\n        if not self.prompt_system:\r\n            return {\"error\": \"Prompt system not available\"}\r\n        \r\n        template_type = kwargs.get(\"template\", \"architectural_analysis\")\r\n        \r\n        # ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª\r\n        prompt_data = {\r\n            \"user_query\": query,\r\n            \"domain\": \"architecture\",\r\n            \"language\": \"fa\"\r\n        }\r\n        # Generate prompt using manager\r\n        try:\r\n            gen = self.prompt_system.generate_prompt(\r\n                query=query,\r\n                task_type=\"architectural\",\r\n                template_name=template_type,\r\n                **prompt_data\r\n            )\r\n            prompt = gen[\"prompt\"] if isinstance(gen, dict) else gen\r\n        except Exception as e:\r\n            return {\"status\": \"error\", \"error\": str(e)}\r\n        \r\n        return {\r\n            \"method_details\": \"Prompt Engineering - Carefully crafted prompts\",\r\n            \"template_used\": template_type,\r\n            \"prompt\": prompt\r\n        }\r\n    \r\n    def _execute_peft(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ PEFT (Parameter-Efficient Fine-Tuning)\"\"\"\r\n        if not self.peft_system:\r\n            return {\"error\": \"PEFT system not available\"}\r\n        adapter = kwargs.get(\"adapter\", None)\r\n        technique = kwargs.get(\"technique\", None)\r\n        task = kwargs.get(\"task\", None)\r\n        result = self.peft_system.apply(query=query, task_type=task, adapter=adapter, technique=technique)\r\n        return {\r\n            \"method_details\": \"PEFT - Parameter-Efficient Fine-Tuning\",\r\n            \"technique\": result.get(\"technique\"),\r\n            \"adapter_used\": result.get(\"adapter\"),\r\n            \"peft_available\": result.get(\"peft_available\", False),\r\n            \"note\": result.get(\"note\")\r\n        }\r\n    \r\n    def hybrid_query(\r\n        self,\r\n        query: str,\r\n        methods: List[AIMethodType],\r\n        **kwargs\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Ù¾Ø±Ø³Ø´ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø§ Ú†Ù†Ø¯ Ø±ÙˆØ´ Ù‡Ù…Ø²Ù…Ø§Ù†\r\n        \r\n        Example: RAG + Prompt Engineering\r\n        \"\"\"\r\n        self.usage_stats[\"hybrid_calls\"] += 1\r\n        \r\n        responses = {}\r\n        for method in methods:\r\n            result = self._execute_query(query, method, None, **kwargs)\r\n            responses[method.value] = result\r\n        \r\n        return {\r\n            \"query\": query,\r\n            \"methods_used\": [m.value for m in methods],\r\n            \"timestamp\": datetime.now().isoformat(),\r\n            \"individual_responses\": responses,\r\n            \"hybrid\": True\r\n        }\r\n    \r\n    def get_system_status(self) -> Dict[str, Any]:\r\n        \"\"\"Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª Ú©Ø§Ù…Ù„ Ø³ÛŒØ³ØªÙ…\"\"\"\r\n        status = {\r\n            \"unified_ai_system\": {\r\n                \"status\": \"operational\",\r\n                \"methods_available\": []\r\n            },\r\n            \"rag\": None,\r\n            \"fine_tuning\": None,\r\n            \"lora\": None,\r\n            \"prompt_engineering\": None,\r\n            \"peft\": None,\r\n            \"security\": None,\r\n            \"usage_statistics\": self.usage_stats\r\n        }\r\n        \r\n        # RAG\r\n        if self.rag_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"RAG\")\r\n            status[\"rag\"] = self.rag_system.get_statistics()\r\n        \r\n        # Fine-Tuning\r\n        if self.fine_tuning_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"Fine-Tuning\")\r\n            status[\"fine_tuning\"] = self.fine_tuning_system\r\n        \r\n        # LoRA\r\n        if self.lora_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"LoRA\")\r\n            status[\"lora\"] = self.lora_system\r\n        \r\n        # Prompt Engineering\r\n        if self.prompt_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"Prompt Engineering\")\r\n            status[\"prompt_engineering\"] = {\"status\": \"ready\"}\r\n        \r\n        # PEFT\r\n        if self.peft_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"PEFT\")\r\n            status[\"peft\"] = self.peft_system.get_status()\r\n        \r\n        # Meta-Controller\r\n        if self.meta_controller:\r\n            status[\"meta_controller\"] = self.meta_controller.get_performance_stats()\r\n        \r\n        # Security\r\n        if self.security_dashboard:\r\n            status[\"security\"] = {\r\n                \"status\": self.security_dashboard.current_status.value,\r\n                \"mother_key_locked\": self.security_dashboard.mother_key.is_locked,\r\n                \"agents_created\": self.security_dashboard.agent_manager.total_created\r\n            }\r\n        \r\n        return status\r\n    \r\n    def compare_methods(self) -> Dict[str, Any]:\r\n        \"\"\"Ù…Ù‚Ø§ÛŒØ³Ù‡ 5 Ø±ÙˆØ´ AI\"\"\"\r\n        return {\r\n            \"comparison\": {\r\n                \"RAG\": {\r\n                    \"setup_time\": \"Minutes\",\r\n                    \"cost\": \"Low ($0-$10)\",\r\n                    \"quality\": \"Excellent for facts\",\r\n                    \"gpu_required\": False,\r\n                    \"best_for\": [\r\n                        \"Knowledge-based queries\",\r\n                        \"Frequently updated info\",\r\n                        \"Multi-document reasoning\",\r\n                        \"Transparent sources\"\r\n                    ],\r\n                    \"when_to_use\": \"Need accurate, source-backed answers\"\r\n                },\r\n                \"Fine-Tuning\": {\r\n                    \"setup_time\": \"Hours to Days\",\r\n                    \"cost\": \"Medium ($100-$1000)\",\r\n                    \"quality\": \"Excellent for specialized tasks\",\r\n                    \"gpu_required\": True,\r\n                    \"best_for\": [\r\n                        \"Domain-specific tasks\",\r\n                        \"Complex reasoning\",\r\n                        \"Consistent style\",\r\n                        \"Production deployment\"\r\n                    ],\r\n                    \"when_to_use\": \"Have labeled data, need specialized model\"\r\n                },\r\n                \"LoRA\": {\r\n                    \"setup_time\": \"Hours\",\r\n                    \"cost\": \"Low ($10-$100)\",\r\n                    \"quality\": \"Very good, efficient\",\r\n                    \"gpu_required\": True,\r\n                    \"best_for\": [\r\n                        \"Quick adaptation\",\r\n                        \"Multiple domains\",\r\n                        \"Resource-constrained\",\r\n                        \"Frequent updates\"\r\n                    ],\r\n                    \"when_to_use\": \"Need fast adaptation with less data\"\r\n                },\r\n                \"Prompt Engineering\": {\r\n                    \"setup_time\": \"Minutes\",\r\n                    \"cost\": \"Very Low ($0-$5)\",\r\n                    \"quality\": \"Good to Excellent\",\r\n                    \"gpu_required\": False,\r\n                    \"best_for\": [\r\n                        \"Quick prototyping\",\r\n                        \"General tasks\",\r\n                        \"No training data\",\r\n                        \"Flexible requirements\"\r\n                    ],\r\n                    \"when_to_use\": \"No training data, quick iteration needed\"\r\n                },\r\n                \"PEFT\": {\r\n                    \"setup_time\": \"Minutes to Hours\",\r\n                    \"cost\": \"Low ($0-$50)\",\r\n                    \"quality\": \"Very Good\",\r\n                    \"gpu_required\": False,\r\n                    \"best_for\": [\r\n                        \"Adapter-based domain updates\",\r\n                        \"Limited compute\",\r\n                        \"Multiple adapters\",\r\n                        \"Efficient updates\"\r\n                    ],\r\n                    \"when_to_use\": \"Need fast efficient fine-tuning without full retrain\"\r\n                }\r\n            },\r\n            \"recommendation\": {\r\n                \"start_with\": \"RAG + Prompt Engineering (lowest cost, fastest)\",\r\n                \"scale_to\": \"PEFT or LoRA or Fine-Tuning (better quality, specialized)\",\r\n                \"best_hybrid\": \"RAG + Prompt Engineering (knowledge + structure) + PEFT for adapters\",\r\n                \"production\": \"Fine-Tuning + RAG (specialized + updated info)\"\r\n            }\r\n        }\r\n    \r\n    def save_configuration(self, name: str = \"default\"):\r\n        \"\"\"Ø°Ø®ÛŒØ±Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ…\"\"\"\r\n        config = {\r\n            \"name\": name,\r\n            \"timestamp\": datetime.now().isoformat(),\r\n            \"auto_routing\": self.auto_routing,\r\n            \"usage_stats\": self.usage_stats,\r\n            \"systems\": {\r\n                \"rag\": self.rag_system is not None,\r\n                \"fine_tuning\": self.fine_tuning_system is not None,\r\n                \"lora\": self.lora_system is not None,\r\n                \"prompt\": self.prompt_system is not None,\r\n                \"peft\": self.peft_system is not None,\r\n                \"security\": self.security_dashboard is not None\r\n            }\r\n        }\r\n        \r\n        filepath = os.path.join(self.storage_dir, f\"{name}_config.json\")\r\n        with open(filepath, 'w', encoding='utf-8') as f:\r\n            json.dump(config, f, indent=2, ensure_ascii=False)\r\n        \r\n        logger.info(f\"âœ… Configuration saved: {filepath}\")\r\n    \r\n    def explain_selection(self, query: str, task_type: Optional[AITaskType] = None) -> Dict:\r\n        \"\"\"\r\n        ØªÙˆØ¶ÛŒØ­ Ø¯Ù„ÛŒÙ„ Ø§Ù†ØªØ®Ø§Ø¨ Ø±ÙˆØ´ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù¾Ø±Ø³Ø´ (Ø¨Ø¯ÙˆÙ† Ø§Ø¬Ø±Ø§)\r\n        \r\n        Args:\r\n            query: Ù¾Ø±Ø³Ø´ Ú©Ø§Ø±Ø¨Ø±\r\n            task_type: Ù†ÙˆØ¹ ÙˆØ¸ÛŒÙÙ‡ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)\r\n        \r\n        Returns:\r\n            ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ø§Ù…Ù„ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ\r\n        \"\"\"\r\n        if not self.meta_controller:\r\n            return {\r\n                \"error\": \"Meta-Controller not available\",\r\n                \"fallback\": \"Using simple keyword-based selection\"\r\n            }\r\n        \r\n        features = self.meta_controller.analyze_query(\r\n            query,\r\n            task_type.name if task_type else None\r\n        )\r\n        \r\n        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ù‡Ù…Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§\r\n        all_methods = [\"RAG\", \"Fine-Tuning\", \"LoRA\", \"Prompt Engineering\", \"PEFT\"]\r\n        scores = []\r\n        \r\n        for method in all_methods:\r\n            score = self.meta_controller._score_method(method, features)\r\n            scores.append(score)\r\n        \r\n        scores.sort(key=lambda x: x.score, reverse=True)\r\n        \r\n        best_method = scores[0].method\r\n        best_score = scores[0]\r\n        \r\n        return self.meta_controller.explain_decision(\r\n            query,\r\n            features,\r\n            best_method,\r\n            best_score,\r\n            scores\r\n        )\r\n    \r\n    def get_performance_stats(self) -> Dict:\r\n        \"\"\"Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ Meta-Controller\"\"\"\r\n        if not self.meta_controller:\r\n            return {\"error\": \"Meta-Controller not available\"}\r\n        \r\n        return self.meta_controller.get_performance_stats()\r\n\r\n# ===========================\r\n# Global Instance\r\n# ===========================\r\n\r\nunified_ai = UnifiedAISystem()\r\n",
    "format": "py"
  },
  {
    "timestamp": "2025-11-21T23:06:38.474Z",
    "fileName": "cad3d\\super_ai\\unified_ai_system.py",
    "content": "\"\"\"\r\nUnified AI System - ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ 5 Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ\r\nØªØ±Ú©ÛŒØ¨ RAG + Fine-Tuning + LoRA + Prompt Engineering + PEFT + Security\r\n\r\nØ§ÛŒÙ† Ø³ÛŒØ³ØªÙ… Ø¬Ø§Ù…Ø¹ Ù‡Ù…Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ AI Ø±Ø§ Ø¨Ø§ Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯\r\n\"\"\"\r\n\r\nimport logging\r\nimport os\r\nimport json\r\nfrom typing import Dict, List, Optional, Any\r\nfrom datetime import datetime\r\nfrom enum import Enum, auto\r\nimport time\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n# ===========================\r\n# AI Method Types\r\n# ===========================\r\n\r\nclass AIMethodType(Enum):\r\n    \"\"\"Ø§Ù†ÙˆØ§Ø¹ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ AI\"\"\"\r\n    RAG = \"retrieval_augmented_generation\"\r\n    FINE_TUNING = \"fine_tuning\"\r\n    LORA = \"low_rank_adaptation\"\r\n    PROMPT_ENGINEERING = \"prompt_engineering\"\r\n    PEFT = \"peft\"\r\n\r\nclass AITaskType(Enum):\r\n    \"\"\"Ø§Ù†ÙˆØ§Ø¹ ÙˆØ¸Ø§ÛŒÙ AI\"\"\"\r\n    CAD_ANALYSIS = auto()\r\n    ARCHITECTURAL_DESIGN = auto()\r\n    STRUCTURAL_CALCULATION = auto()\r\n    MEP_OPTIMIZATION = auto()\r\n    CODE_COMPLIANCE = auto()\r\n    MATERIAL_ESTIMATION = auto()\r\n    GENERAL_QUERY = auto()\r\n\r\n# ===========================\r\n# Unified AI System\r\n# ===========================\r\n\r\nclass UnifiedAISystem:\r\n    \"\"\"\r\n    Ø³ÛŒØ³ØªÙ… ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ AI Ø¨Ø§ 5 Ø±ÙˆØ´:\r\n    1. RAG - Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ùˆ ØªÙˆÙ„ÛŒØ¯\r\n    2. Fine-Tuning - Ø¢Ù…ÙˆØ²Ø´ Ø¹Ù…ÛŒÙ‚\r\n    3. LoRA - ØªØ·Ø¨ÛŒÙ‚ Ú©Ù…â€ŒØ±ØªØ¨Ù‡\r\n    4. Prompt Engineering - Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ù¾Ø±Ø§Ù…Ù¾Øª\r\n    5. PEFT - ØªÙ†Ø¸ÛŒÙ… Ú©Ø§Ø±Ø¢Ù…Ø¯ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§\r\n    \r\n    + ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ Ú©Ø§Ù…Ù„ Ø¨Ø§ Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ\r\n    \"\"\"\r\n    \r\n    def __init__(self, storage_dir: str = \"models/unified_ai\"):\r\n        self.storage_dir = storage_dir\r\n        os.makedirs(storage_dir, exist_ok=True)\r\n        \r\n        # Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ ÙØ±Ø¹ÛŒ\r\n        self.rag_system = None\r\n        self.fine_tuning_system = None\r\n        self.lora_system = None\r\n        self.prompt_system = None\r\n        self.peft_system = None\r\n        self.security_dashboard = None\r\n        self.meta_controller = None\r\n        \r\n        # Ø¢Ù…Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡\r\n        self.usage_stats = {\r\n            \"rag_calls\": 0,\r\n            \"fine_tuning_calls\": 0,\r\n            \"lora_calls\": 0,\r\n            \"prompt_calls\": 0,\r\n            \"peft_calls\": 0,\r\n            \"hybrid_calls\": 0,\r\n            \"total_queries\": 0\r\n        }\r\n        \r\n        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø±ÙˆØªÛŒÙ†Ú¯ Ø®ÙˆØ¯Ú©Ø§Ø±\r\n        self.auto_routing = True\r\n        \r\n        self._initialize_systems()\r\n    \r\n    def _initialize_systems(self):\r\n        \"\"\"Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ ØªÙ…Ø§Ù… Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ ÙØ±Ø¹ÛŒ\"\"\"\r\n        logger.info(\"=\"*80)\r\n        logger.info(\"ğŸš€ INITIALIZING UNIFIED AI SYSTEM\")\r\n        logger.info(\"=\"*80)\r\n        \r\n        # 1. RAG System\r\n        try:\r\n            from .rag_system import RAGSystem\r\n            self.rag_system = RAGSystem(storage_dir=os.path.join(self.storage_dir, \"rag\"))\r\n            logger.info(\"âœ… RAG System initialized\")\r\n        except Exception as e:\r\n            logger.error(f\"âŒ RAG System failed: {e}\")\r\n        \r\n        # 2. Fine-Tuning System (Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ)\r\n        self.fine_tuning_system = {\r\n            \"status\": \"ready\",\r\n            \"models\": [\"cad_analysis_v1\", \"architectural_design_v2\"],\r\n            \"last_training\": \"2025-11-20\"\r\n        }\r\n        logger.info(\"âœ… Fine-Tuning System initialized\")\r\n        \r\n        # 3. LoRA System (Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ)\r\n        self.lora_system = {\r\n            \"status\": \"ready\",\r\n            \"adapters\": [\"structural_calc\", \"mep_optimization\"],\r\n            \"rank\": 8\r\n        }\r\n        logger.info(\"âœ… LoRA System initialized\")\r\n        \r\n        # 4. Prompt Engineering System\r\n        from .prompt_engineering import PromptEngineeringManager\r\n        self.prompt_system = PromptEngineeringManager()\r\n        logger.info(\"âœ… Prompt Engineering System initialized\")\r\n        \r\n        # 5. PEFT System\r\n        try:\r\n            from .peft_system import PEFTManager\r\n            self.peft_system = PEFTManager()\r\n            logger.info(\"âœ… PEFT System initialized\")\r\n        except Exception as e:\r\n            logger.warning(f\"âš ï¸ PEFT System not available: {e}\")\r\n        \r\n        # 6. Meta-Controller (AI Method Selector)\r\n        try:\r\n            from .meta_controller import MetaController\r\n            self.meta_controller = MetaController()\r\n            logger.info(\"âœ… Meta-Controller initialized\")\r\n        except Exception as e:\r\n            logger.warning(f\"âš ï¸ Meta-Controller not available: {e}\")\r\n        \r\n        # 7. Security Dashboard\r\n        try:\r\n            from .advanced_security import SecurityDashboard\r\n            self.security_dashboard = SecurityDashboard()\r\n            logger.info(\"âœ… Security Dashboard integrated\")\r\n        except Exception as e:\r\n            logger.warning(f\"âš ï¸ Security Dashboard not available: {e}\")\r\n        \r\n        logger.info(\"=\"*80)\r\n        logger.info(\"ğŸ‰ UNIFIED AI SYSTEM READY\")\r\n        logger.info(\"=\"*80 + \"\\n\")\r\n    \r\n    def query(\r\n        self,\r\n        query: str,\r\n        method: Optional[AIMethodType] = None,\r\n        task_type: Optional[AITaskType] = None,\r\n        **kwargs\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Ù¾Ø±Ø³Ø´ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¨Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ø®ÙˆØ¯Ú©Ø§Ø± ÛŒØ§ Ø¯Ø³ØªÛŒ Ø±ÙˆØ´\r\n        \r\n        Args:\r\n            query: Ù¾Ø±Ø³Ø´ Ú©Ø§Ø±Ø¨Ø±\r\n            method: Ø±ÙˆØ´ AI (Ø§Ø®ØªÛŒØ§Ø±ÛŒ - Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒâ€ŒØ´ÙˆØ¯)\r\n            task_type: Ù†ÙˆØ¹ ÙˆØ¸ÛŒÙÙ‡ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)\r\n            **kwargs: Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ\r\n        \r\n        Returns:\r\n            Ù¾Ø§Ø³Ø® Ú©Ø§Ù…Ù„ Ø¨Ø§ Ù…ØªØ§Ø¯ÛŒØªØ§\r\n        \"\"\"\r\n        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ\r\n        if self.security_dashboard:\r\n            if not self._security_check(query):\r\n                return {\r\n                    \"error\": \"Security check failed\",\r\n                    \"status\": \"blocked\"\r\n                }\r\n        \r\n        # Ø§Ù†ØªØ®Ø§Ø¨ Ø®ÙˆØ¯Ú©Ø§Ø± Ø±ÙˆØ´\r\n        decision_explanation = None\r\n        if method is None and self.auto_routing:\r\n            method, decision_explanation = self._select_best_method(query, task_type)\r\n        \r\n        # Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª\r\n        start_time = time.time()\r\n        response = self._execute_query(query, method, task_type, **kwargs)\r\n        execution_time = time.time() - start_time\r\n        \r\n        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªÙˆØ¶ÛŒØ­Ø§Øª ØªØµÙ…ÛŒÙ…\r\n        if decision_explanation:\r\n            response[\"selection_reasoning\"] = decision_explanation\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø±\r\n        self.usage_stats[\"total_queries\"] += 1\r\n        if method == AIMethodType.RAG:\r\n            self.usage_stats[\"rag_calls\"] += 1\r\n        elif method == AIMethodType.FINE_TUNING:\r\n            self.usage_stats[\"fine_tuning_calls\"] += 1\r\n        elif method == AIMethodType.LORA:\r\n            self.usage_stats[\"lora_calls\"] += 1\r\n        elif method == AIMethodType.PROMPT_ENGINEERING:\r\n            self.usage_stats[\"prompt_calls\"] += 1\r\n        elif method == AIMethodType.PEFT:\r\n            self.usage_stats[\"peft_calls\"] += 1\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¯Ø± Meta-Controller\r\n        if self.meta_controller and decision_explanation:\r\n            success = response.get(\"status\") == \"success\"\r\n            method_name = self._method_enum_to_name(method)\r\n            self.meta_controller.update_performance(method_name, success, execution_time)\r\n        \r\n        return response\r\n    \r\n    def _security_check(self, query: str) -> bool:\r\n        \"\"\"Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ Ù¾Ø±Ø³Ø´\"\"\"\r\n        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ø´Ú©ÙˆÚ©\r\n        suspicious_patterns = [\r\n            \"delete\", \"drop\", \"truncate\", \"exec\",\r\n            \"system\", \"os.\", \"subprocess\", \"__import__\"\r\n        ]\r\n        \r\n        query_lower = query.lower()\r\n        for pattern in suspicious_patterns:\r\n            if pattern in query_lower:\r\n                logger.warning(f\"ğŸš¨ Suspicious pattern detected: {pattern}\")\r\n                return False\r\n        \r\n        return True\r\n    \r\n    def _select_best_method(\r\n        self,\r\n        query: str,\r\n        task_type: Optional[AITaskType]\r\n    ) -> tuple[AIMethodType, Optional[Dict]]:\r\n        \"\"\"\r\n        Ø§Ù†ØªØ®Ø§Ø¨ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´ Ø¨Ø§ Meta-Controller Ù‡ÙˆØ´Ù…Ù†Ø¯\r\n        \r\n        Ø§Ú¯Ø± Meta-Controller Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø² ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯\r\n        Ø¯Ø± ØºÛŒØ± Ø§ÛŒÙ† ØµÙˆØ±ØªØŒ Ø§Ø² Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒØ§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯\r\n        \"\"\"\r\n        \r\n        query_lower = query.lower()\r\n        \r\n        # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒ ØµØ±ÛŒØ­ (Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§Ù„Ø§)\r\n        explicit_methods = {\r\n            \"rag\": AIMethodType.RAG,\r\n            \"retrieval\": AIMethodType.RAG,\r\n            \"fine-tun\": AIMethodType.FINE_TUNING,\r\n            \"fine tun\": AIMethodType.FINE_TUNING,\r\n            \"lora\": AIMethodType.LORA,\r\n            \"peft\": AIMethodType.PEFT,\r\n            \"prompt\": AIMethodType.PROMPT_ENGINEERING\r\n        }\r\n        \r\n        for keyword, method in explicit_methods.items():\r\n            if keyword in query_lower:\r\n                return method, {\r\n                    \"controller\": \"Explicit Keyword\",\r\n                    \"keyword\": keyword,\r\n                    \"note\": f\"User explicitly requested {method.value}\"\r\n                }\r\n        \r\n        # Ø§Ú¯Ø± Meta-Controller Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³ØªØŒ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†\r\n        if self.meta_controller:\r\n            features = self.meta_controller.analyze_query(\r\n                query,\r\n                task_type.name if task_type else None\r\n            )\r\n            \r\n            method_name, score = self.meta_controller.select_best_method(features)\r\n            \r\n            # ØªØ¨Ø¯ÛŒÙ„ Ù†Ø§Ù… Ø¨Ù‡ enum\r\n            method_enum = self._name_to_method_enum(method_name)\r\n            \r\n            # ØªÙˆØ¶ÛŒØ­Ø§Øª ØªØµÙ…ÛŒÙ…\r\n            explanation = {\r\n                \"controller\": \"Meta-Controller (Intelligent)\",\r\n                \"selected_method\": method_name,\r\n                \"score\": f\"{score.score:.1f}\",\r\n                \"reasoning\": score.reasoning,\r\n                \"features\": {\r\n                    \"complexity\": features.complexity.value,\r\n                    \"domain\": features.domain,\r\n                    \"confidence_needed\": f\"{features.confidence_needed:.0%}\"\r\n                },\r\n                \"scores\": {\r\n                    \"speed\": f\"{score.speed_score:.1f}\",\r\n                    \"accuracy\": f\"{score.accuracy_score:.1f}\",\r\n                    \"cost\": f\"{score.cost_score:.1f}\"\r\n                }\r\n            }\r\n            \r\n            return method_enum, explanation\r\n        \r\n        # Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡ (Fallback)\r\n        return self._select_method_simple(query, task_type), {\r\n            \"controller\": \"Simple (Keyword-based)\",\r\n            \"note\": \"Meta-Controller not available\"\r\n        }\r\n    \r\n    def _select_method_simple(\r\n        self,\r\n        query: str,\r\n        task_type: Optional[AITaskType]\r\n    ) -> AIMethodType:\r\n        \"\"\"\r\n        Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ (Fallback)\r\n        \"\"\"\r\n        query_lower = query.lower()\r\n        \r\n        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ RAG (Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¯Ø§Ù†Ø´ ÙˆØ§Ù‚Ø¹ÛŒ)\r\n        rag_keywords = [\r\n            \"Ù…Ø­Ø§Ø³Ø¨Ù‡\", \"Ú†Ù‚Ø¯Ø±\", \"Ú†Ù†Ø¯\", \"Ù…Ø³Ø§Ø­Øª\", \"Ø­Ø¬Ù…\",\r\n            \"Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯\", \"Ø¶ÙˆØ§Ø¨Ø·\", \"Ù…Ø¨Ø­Ø«\", \"Ù‚Ø§Ù†ÙˆÙ†\",\r\n            \"calculate\", \"how much\", \"how many\", \"area\", \"volume\"\r\n        ]\r\n        \r\n        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Fine-Tuning (ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒÚ†ÛŒØ¯Ù‡)\r\n        fine_tuning_keywords = [\r\n            \"ØªØ­Ù„ÛŒÙ„\", \"Ø·Ø±Ø§Ø­ÛŒ\", \"Ø¨Ù‡ÛŒÙ†Ù‡\", \"Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯\",\r\n            \"analyze\", \"design\", \"optimize\", \"suggest\"\r\n        ]\r\n        \r\n        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ LoRA (ØªØ·Ø¨ÛŒÙ‚ Ø³Ø±ÛŒØ¹)\r\n        lora_keywords = [\r\n            \"Ø³Ø§Ø²Ù‡\", \"ØªØ§Ø³ÛŒØ³Ø§Øª\", \"Ø¨Ø±Ù‚\", \"Ù„ÙˆÙ„Ù‡â€ŒÚ©Ø´ÛŒ\",\r\n            \"structural\", \"mep\", \"electrical\", \"plumbing\"\r\n        ]\r\n        \r\n        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ PEFT (ÙÙ†Ø§ÙˆØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ø±Ø§Ù…ØªØ±-Ú©Ø§Ø±Ø§)\r\n        peft_keywords = [\r\n            \"peft\", \"prefix\", \"p-tuning\", \"ptuning\", \"ia3\", \"adalora\", \"qlora\", \"adapter\"\r\n        ]\r\n        \r\n        # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ\r\n        rag_score = sum(1 for kw in rag_keywords if kw in query_lower)\r\n        ft_score = sum(1 for kw in fine_tuning_keywords if kw in query_lower)\r\n        lora_score = sum(1 for kw in lora_keywords if kw in query_lower)\r\n        peft_score = sum(1 for kw in peft_keywords if kw in query_lower)\r\n        \r\n        # ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ\r\n        if rag_score >= 2:\r\n            return AIMethodType.RAG\r\n        elif ft_score >= 1 and task_type in [AITaskType.CAD_ANALYSIS, AITaskType.ARCHITECTURAL_DESIGN]:\r\n            return AIMethodType.FINE_TUNING\r\n        elif peft_score >= 1:\r\n            return AIMethodType.PEFT\r\n        elif lora_score >= 1:\r\n            return AIMethodType.LORA\r\n        else:\r\n            return AIMethodType.PROMPT_ENGINEERING\r\n    \r\n    def _name_to_method_enum(self, name: str) -> AIMethodType:\r\n        \"\"\"ØªØ¨Ø¯ÛŒÙ„ Ù†Ø§Ù… Ø±ÙˆØ´ Ø¨Ù‡ enum\"\"\"\r\n        mapping = {\r\n            \"RAG\": AIMethodType.RAG,\r\n            \"Fine-Tuning\": AIMethodType.FINE_TUNING,\r\n            \"LoRA\": AIMethodType.LORA,\r\n            \"Prompt Engineering\": AIMethodType.PROMPT_ENGINEERING,\r\n            \"PEFT\": AIMethodType.PEFT\r\n        }\r\n        return mapping.get(name, AIMethodType.PROMPT_ENGINEERING)\r\n    \r\n    def _method_enum_to_name(self, method: AIMethodType) -> str:\r\n        \"\"\"ØªØ¨Ø¯ÛŒÙ„ enum Ø¨Ù‡ Ù†Ø§Ù… Ø±ÙˆØ´\"\"\"\r\n        mapping = {\r\n            AIMethodType.RAG: \"RAG\",\r\n            AIMethodType.FINE_TUNING: \"Fine-Tuning\",\r\n            AIMethodType.LORA: \"LoRA\",\r\n            AIMethodType.PROMPT_ENGINEERING: \"Prompt Engineering\",\r\n            AIMethodType.PEFT: \"PEFT\"\r\n        }\r\n        return mapping.get(method, \"Prompt Engineering\")\r\n    \r\n    def _execute_query(\r\n        self,\r\n        query: str,\r\n        method: AIMethodType,\r\n        task_type: Optional[AITaskType],\r\n        **kwargs\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ Ù¾Ø±Ø³Ø´ Ø¨Ø§ Ø±ÙˆØ´ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡\"\"\"\r\n        \r\n        response = {\r\n            \"query\": query,\r\n            \"method\": method.value,\r\n            \"task_type\": task_type.name if task_type else None,\r\n            \"timestamp\": datetime.now().isoformat(),\r\n            \"status\": \"success\"\r\n        }\r\n        \r\n        try:\r\n            if method == AIMethodType.RAG:\r\n                result = self._execute_rag(query, **kwargs)\r\n            elif method == AIMethodType.FINE_TUNING:\r\n                result = self._execute_fine_tuning(query, **kwargs)\r\n            elif method == AIMethodType.LORA:\r\n                result = self._execute_lora(query, **kwargs)\r\n            elif method == AIMethodType.PROMPT_ENGINEERING:\r\n                result = self._execute_prompt(query, **kwargs)\r\n            elif method == AIMethodType.PEFT:\r\n                result = self._execute_peft(query, **kwargs)\r\n            else:\r\n                raise ValueError(f\"Unknown method: {method}\")\r\n            \r\n            response.update(result)\r\n            \r\n        except Exception as e:\r\n            logger.error(f\"âŒ Query execution failed: {e}\")\r\n            response[\"status\"] = \"error\"\r\n            response[\"error\"] = str(e)\r\n        \r\n        return response\r\n    \r\n    def _execute_rag(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ RAG\"\"\"\r\n        if not self.rag_system:\r\n            return {\"error\": \"RAG system not available\"}\r\n        \r\n        top_k = kwargs.get(\"top_k\", 3)\r\n        \r\n        # Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø³Ù†Ø§Ø¯\r\n        results = self.rag_system.retrieve(query, top_k=top_k)\r\n        \r\n        # ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®\r\n        rag_response = self.rag_system.generate_rag_response(query, top_k=top_k)\r\n        \r\n        return {\r\n            \"method_details\": \"RAG - Retrieval-Augmented Generation\",\r\n            \"retrieved_documents\": rag_response[\"retrieved_documents\"],\r\n            \"num_docs\": len(results),\r\n            \"prompt\": rag_response[\"prompt\"]\r\n        }\r\n    \r\n    def _execute_fine_tuning(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ Fine-Tuning\"\"\"\r\n        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Fine-Tuning\r\n        model_name = kwargs.get(\"model\", \"cad_analysis_v1\")\r\n        \r\n        return {\r\n            \"method_details\": \"Fine-Tuning - Specialized trained model\",\r\n            \"model_used\": model_name,\r\n            \"training_date\": self.fine_tuning_system[\"last_training\"],\r\n            \"note\": \"Using fine-tuned model for specialized CAD analysis\"\r\n        }\r\n    \r\n    def _execute_lora(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ LoRA\"\"\"\r\n        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ LoRA\r\n        adapter = kwargs.get(\"adapter\", \"structural_calc\")\r\n        \r\n        return {\r\n            \"method_details\": \"LoRA - Low-Rank Adaptation\",\r\n            \"adapter_used\": adapter,\r\n            \"rank\": self.lora_system[\"rank\"],\r\n            \"note\": \"Using LoRA adapter for efficient domain adaptation\"\r\n        }\r\n    \r\n    def _execute_prompt(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ Prompt Engineering\"\"\"\r\n        if not self.prompt_system:\r\n            return {\"error\": \"Prompt system not available\"}\r\n        \r\n        template_type = kwargs.get(\"template\", \"architectural_analysis\")\r\n        \r\n        # ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª\r\n        prompt_data = {\r\n            \"user_query\": query,\r\n            \"domain\": \"architecture\",\r\n            \"language\": \"fa\"\r\n        }\r\n        # Generate prompt using manager\r\n        try:\r\n            gen = self.prompt_system.generate_prompt(\r\n                query=query,\r\n                task_type=\"architectural\",\r\n                template_name=template_type,\r\n                **prompt_data\r\n            )\r\n            prompt = gen[\"prompt\"] if isinstance(gen, dict) else gen\r\n        except Exception as e:\r\n            return {\"status\": \"error\", \"error\": str(e)}\r\n        \r\n        return {\r\n            \"method_details\": \"Prompt Engineering - Carefully crafted prompts\",\r\n            \"template_used\": template_type,\r\n            \"prompt\": prompt\r\n        }\r\n    \r\n    def _execute_peft(self, query: str, **kwargs) -> Dict[str, Any]:\r\n        \"\"\"Ø§Ø¬Ø±Ø§ÛŒ PEFT (Parameter-Efficient Fine-Tuning)\"\"\"\r\n        if not self.peft_system:\r\n            return {\"error\": \"PEFT system not available\"}\r\n        adapter = kwargs.get(\"adapter\", None)\r\n        technique = kwargs.get(\"technique\", None)\r\n        task = kwargs.get(\"task\", None)\r\n        result = self.peft_system.apply(query=query, task_type=task, adapter=adapter, technique=technique)\r\n        return {\r\n            \"method_details\": \"PEFT - Parameter-Efficient Fine-Tuning\",\r\n            \"technique\": result.get(\"technique\"),\r\n            \"adapter_used\": result.get(\"adapter\"),\r\n            \"peft_available\": result.get(\"peft_available\", False),\r\n            \"note\": result.get(\"note\")\r\n        }\r\n    \r\n    def hybrid_query(\r\n        self,\r\n        query: str,\r\n        methods: List[AIMethodType],\r\n        **kwargs\r\n    ) -> Dict[str, Any]:\r\n        \"\"\"\r\n        Ù¾Ø±Ø³Ø´ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø§ Ú†Ù†Ø¯ Ø±ÙˆØ´ Ù‡Ù…Ø²Ù…Ø§Ù†\r\n        \r\n        Example: RAG + Prompt Engineering\r\n        \"\"\"\r\n        self.usage_stats[\"hybrid_calls\"] += 1\r\n        \r\n        responses = {}\r\n        for method in methods:\r\n            result = self._execute_query(query, method, None, **kwargs)\r\n            responses[method.value] = result\r\n        \r\n        return {\r\n            \"query\": query,\r\n            \"methods_used\": [m.value for m in methods],\r\n            \"timestamp\": datetime.now().isoformat(),\r\n            \"individual_responses\": responses,\r\n            \"hybrid\": True\r\n        }\r\n    \r\n    def get_system_status(self) -> Dict[str, Any]:\r\n        \"\"\"Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª Ú©Ø§Ù…Ù„ Ø³ÛŒØ³ØªÙ…\"\"\"\r\n        status = {\r\n            \"unified_ai_system\": {\r\n                \"status\": \"operational\",\r\n                \"methods_available\": []\r\n            },\r\n            \"rag\": None,\r\n            \"fine_tuning\": None,\r\n            \"lora\": None,\r\n            \"prompt_engineering\": None,\r\n            \"peft\": None,\r\n            \"security\": None,\r\n            \"usage_statistics\": self.usage_stats\r\n        }\r\n        \r\n        # RAG\r\n        if self.rag_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"RAG\")\r\n            status[\"rag\"] = self.rag_system.get_statistics()\r\n        \r\n        # Fine-Tuning\r\n        if self.fine_tuning_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"Fine-Tuning\")\r\n            status[\"fine_tuning\"] = self.fine_tuning_system\r\n        \r\n        # LoRA\r\n        if self.lora_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"LoRA\")\r\n            status[\"lora\"] = self.lora_system\r\n        \r\n        # Prompt Engineering\r\n        if self.prompt_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"Prompt Engineering\")\r\n            status[\"prompt_engineering\"] = {\"status\": \"ready\"}\r\n        \r\n        # PEFT\r\n        if self.peft_system:\r\n            status[\"unified_ai_system\"][\"methods_available\"].append(\"PEFT\")\r\n            status[\"peft\"] = self.peft_system.get_status()\r\n        \r\n        # Meta-Controller\r\n        if self.meta_controller:\r\n            status[\"meta_controller\"] = self.meta_controller.get_performance_stats()\r\n        \r\n        # Security\r\n        if self.security_dashboard:\r\n            status[\"security\"] = {\r\n                \"status\": self.security_dashboard.current_status.value,\r\n                \"mother_key_locked\": self.security_dashboard.mother_key.is_locked,\r\n                \"agents_created\": self.security_dashboard.agent_manager.total_created\r\n            }\r\n        \r\n        return status\r\n    \r\n    def compare_methods(self) -> Dict[str, Any]:\r\n        \"\"\"Ù…Ù‚Ø§ÛŒØ³Ù‡ 5 Ø±ÙˆØ´ AI\"\"\"\r\n        return {\r\n            \"comparison\": {\r\n                \"RAG\": {\r\n                    \"setup_time\": \"Minutes\",\r\n                    \"cost\": \"Low ($0-$10)\",\r\n                    \"quality\": \"Excellent for facts\",\r\n                    \"gpu_required\": False,\r\n                    \"best_for\": [\r\n                        \"Knowledge-based queries\",\r\n                        \"Frequently updated info\",\r\n                        \"Multi-document reasoning\",\r\n                        \"Transparent sources\"\r\n                    ],\r\n                    \"when_to_use\": \"Need accurate, source-backed answers\"\r\n                },\r\n                \"Fine-Tuning\": {\r\n                    \"setup_time\": \"Hours to Days\",\r\n                    \"cost\": \"Medium ($100-$1000)\",\r\n                    \"quality\": \"Excellent for specialized tasks\",\r\n                    \"gpu_required\": True,\r\n                    \"best_for\": [\r\n                        \"Domain-specific tasks\",\r\n                        \"Complex reasoning\",\r\n                        \"Consistent style\",\r\n                        \"Production deployment\"\r\n                    ],\r\n                    \"when_to_use\": \"Have labeled data, need specialized model\"\r\n                },\r\n                \"LoRA\": {\r\n                    \"setup_time\": \"Hours\",\r\n                    \"cost\": \"Low ($10-$100)\",\r\n                    \"quality\": \"Very good, efficient\",\r\n                    \"gpu_required\": True,\r\n                    \"best_for\": [\r\n                        \"Quick adaptation\",\r\n                        \"Multiple domains\",\r\n                        \"Resource-constrained\",\r\n                        \"Frequent updates\"\r\n                    ],\r\n                    \"when_to_use\": \"Need fast adaptation with less data\"\r\n                },\r\n                \"Prompt Engineering\": {\r\n                    \"setup_time\": \"Minutes\",\r\n                    \"cost\": \"Very Low ($0-$5)\",\r\n                    \"quality\": \"Good to Excellent\",\r\n                    \"gpu_required\": False,\r\n                    \"best_for\": [\r\n                        \"Quick prototyping\",\r\n                        \"General tasks\",\r\n                        \"No training data\",\r\n                        \"Flexible requirements\"\r\n                    ],\r\n                    \"when_to_use\": \"No training data, quick iteration needed\"\r\n                },\r\n                \"PEFT\": {\r\n                    \"setup_time\": \"Minutes to Hours\",\r\n                    \"cost\": \"Low ($0-$50)\",\r\n                    \"quality\": \"Very Good\",\r\n                    \"gpu_required\": False,\r\n                    \"best_for\": [\r\n                        \"Adapter-based domain updates\",\r\n                        \"Limited compute\",\r\n                        \"Multiple adapters\",\r\n                        \"Efficient updates\"\r\n                    ],\r\n                    \"when_to_use\": \"Need fast efficient fine-tuning without full retrain\"\r\n                }\r\n            },\r\n            \"recommendation\": {\r\n                \"start_with\": \"RAG + Prompt Engineering (lowest cost, fastest)\",\r\n                \"scale_to\": \"PEFT or LoRA or Fine-Tuning (better quality, specialized)\",\r\n                \"best_hybrid\": \"RAG + Prompt Engineering (knowledge + structure) + PEFT for adapters\",\r\n                \"production\": \"Fine-Tuning + RAG (specialized + updated info)\"\r\n            }\r\n        }\r\n    \r\n    def save_configuration(self, name: str = \"default\"):\r\n        \"\"\"Ø°Ø®ÛŒØ±Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ…\"\"\"\r\n        config = {\r\n            \"name\": name,\r\n            \"timestamp\": datetime.now().isoformat(),\r\n            \"auto_routing\": self.auto_routing,\r\n            \"usage_stats\": self.usage_stats,\r\n            \"systems\": {\r\n                \"rag\": self.rag_system is not None,\r\n                \"fine_tuning\": self.fine_tuning_system is not None,\r\n                \"lora\": self.lora_system is not None,\r\n                \"prompt\": self.prompt_system is not None,\r\n                \"peft\": self.peft_system is not None,\r\n                \"security\": self.security_dashboard is not None\r\n            }\r\n        }\r\n        \r\n        filepath = os.path.join(self.storage_dir, f\"{name}_config.json\")\r\n        with open(filepath, 'w', encoding='utf-8') as f:\r\n            json.dump(config, f, indent=2, ensure_ascii=False)\r\n        \r\n        logger.info(f\"âœ… Configuration saved: {filepath}\")\r\n    \r\n    def explain_selection(self, query: str, task_type: Optional[AITaskType] = None) -> Dict:\r\n        \"\"\"\r\n        ØªÙˆØ¶ÛŒØ­ Ø¯Ù„ÛŒÙ„ Ø§Ù†ØªØ®Ø§Ø¨ Ø±ÙˆØ´ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù¾Ø±Ø³Ø´ (Ø¨Ø¯ÙˆÙ† Ø§Ø¬Ø±Ø§)\r\n        \r\n        Args:\r\n            query: Ù¾Ø±Ø³Ø´ Ú©Ø§Ø±Ø¨Ø±\r\n            task_type: Ù†ÙˆØ¹ ÙˆØ¸ÛŒÙÙ‡ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)\r\n        \r\n        Returns:\r\n            ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ø§Ù…Ù„ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ\r\n        \"\"\"\r\n        if not self.meta_controller:\r\n            return {\r\n                \"error\": \"Meta-Controller not available\",\r\n                \"fallback\": \"Using simple keyword-based selection\"\r\n            }\r\n        \r\n        features = self.meta_controller.analyze_query(\r\n            query,\r\n            task_type.name if task_type else None\r\n        )\r\n        \r\n        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ù‡Ù…Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§\r\n        all_methods = [\"RAG\", \"Fine-Tuning\", \"LoRA\", \"Prompt Engineering\", \"PEFT\"]\r\n        scores = []\r\n        \r\n        for method in all_methods:\r\n            score = self.meta_controller._score_method(method, features)\r\n            scores.append(score)\r\n        \r\n        scores.sort(key=lambda x: x.score, reverse=True)\r\n        \r\n        best_method = scores[0].method\r\n        best_score = scores[0]\r\n        \r\n        return self.meta_controller.explain_decision(\r\n            query,\r\n            features,\r\n            best_method,\r\n            best_score,\r\n            scores\r\n        )\r\n    \r\n    def get_performance_stats(self) -> Dict:\r\n        \"\"\"Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ Meta-Controller\"\"\"\r\n        if not self.meta_controller:\r\n            return {\"error\": \"Meta-Controller not available\"}\r\n        \r\n        return self.meta_controller.get_performance_stats()\r\n\r\n# ===========================\r\n# Global Instance\r\n# ===========================\r\n\r\nunified_ai = UnifiedAISystem()\r\n",
    "format": "py"
  }
]