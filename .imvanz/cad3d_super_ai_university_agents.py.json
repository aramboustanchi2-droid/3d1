[
  {
    "timestamp": "2025-11-21T23:13:29.520Z",
    "fileName": "cad3d\\super_ai\\university_agents.py",
    "content": "\"\"\"\r\nUniversity Learning Agents - Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ÛŒ\r\n\r\nØ§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ Ø¨Ø±Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø¯Ø§ÙˆÙ… Ø§Ø² Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø±ØªØ±\r\n\"\"\"\r\n\r\nimport logging\r\nfrom typing import Dict, List, Optional\r\nfrom datetime import datetime, timedelta\r\nimport json\r\nfrom pathlib import Path\r\n\r\nfrom .university_scraper import UniversityResourceCollector\r\nfrom .rag_system import RAGSystem\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\nclass UniversityAgent:\r\n    \"\"\"\r\n    Ø§ÛŒØ¬Ù†Øª ØªØ®ØµØµÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\r\n    \r\n    Ù…Ø³Ø¦ÙˆÙ„ÛŒØªâ€ŒÙ‡Ø§:\r\n    - Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ Ù…Ø­ØªÙˆØ§\r\n    - Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª\r\n    - Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ RAG\r\n    - Ø±Ø¯ÛŒØ§Ø¨ÛŒ ØªØºÛŒÛŒØ±Ø§Øª Ùˆ Ù…Ø­ØªÙˆØ§ÛŒ Ø¬Ø¯ÛŒØ¯\r\n    \"\"\"\r\n    \r\n    def __init__(\r\n        self,\r\n        university_key: str,\r\n        university_info: Dict,\r\n        config: Dict,\r\n        rag_system: Optional[RAGSystem] = None\r\n    ):\r\n        self.university_key = university_key\r\n        self.university_info = university_info\r\n        self.config = config\r\n        self.rag_system = rag_system\r\n        \r\n        self.state = {\r\n            'last_update': None,\r\n            'total_documents': 0,\r\n            'total_pages_scraped': 0,\r\n            'last_successful_scrape': None,\r\n            'errors': []\r\n        }\r\n        \r\n        # State file\r\n        self.state_file = Path(config['storage']['cache_dir']) / f\"{university_key}_state.json\"\r\n        self.load_state()\r\n    \r\n    def load_state(self):\r\n        \"\"\"Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø§Ø² ÙØ§ÛŒÙ„\"\"\"\r\n        if self.state_file.exists():\r\n            with open(self.state_file, 'r', encoding='utf-8') as f:\r\n                self.state = json.load(f)\r\n    \r\n    def save_state(self):\r\n        \"\"\"Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø¯Ø± ÙØ§ÛŒÙ„\"\"\"\r\n        with open(self.state_file, 'w', encoding='utf-8') as f:\r\n            json.dump(self.state, f, ensure_ascii=False, indent=2)\r\n    \r\n    def should_update(self) -> bool:\r\n        \"\"\"\r\n        Ø¨Ø±Ø±Ø³ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ\r\n        \r\n        Returns:\r\n            True Ø§Ú¯Ø± Ø²Ù…Ø§Ù† Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø±Ø³ÛŒØ¯Ù‡ Ø¨Ø§Ø´Ø¯\r\n        \"\"\"\r\n        if self.state['last_update'] is None:\r\n            return True\r\n        \r\n        last_update = datetime.fromisoformat(self.state['last_update'])\r\n        update_frequency = self.config['learning']['update_frequency']\r\n        \r\n        if update_frequency == 'daily':\r\n            return datetime.now() - last_update > timedelta(days=1)\r\n        elif update_frequency == 'weekly':\r\n            return datetime.now() - last_update > timedelta(weeks=1)\r\n        elif update_frequency == 'monthly':\r\n            return datetime.now() - last_update > timedelta(days=30)\r\n        \r\n        return False\r\n    \r\n    def collect_content(self, collector: UniversityResourceCollector) -> Dict:\r\n        \"\"\"\r\n        Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…Ø­ØªÙˆØ§ Ø§Ø² Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\r\n        \r\n        Args:\r\n            collector: Ø´ÛŒØ¡ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒâ€ŒÚ©Ù†Ù†Ø¯Ù‡\r\n        \r\n        Returns:\r\n            Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒâ€ŒØ´Ø¯Ù‡\r\n        \"\"\"\r\n        logger.info(f\"\\n{'='*80}\")\r\n        logger.info(f\"Agent: {self.university_info['name']}\")\r\n        logger.info(f\"{'='*80}\")\r\n        \r\n        try:\r\n            max_pages = self.config['learning']['max_documents_per_session']\r\n            data = collector.collect_from_university(self.university_key, max_pages)\r\n            \r\n            self.state['last_successful_scrape'] = datetime.now().isoformat()\r\n            self.state['total_pages_scraped'] += data.get('total_pages', 0)\r\n            \r\n            return data\r\n            \r\n        except Exception as e:\r\n            error_msg = f\"Error collecting content: {str(e)}\"\r\n            logger.error(error_msg)\r\n            self.state['errors'].append({\r\n                'timestamp': datetime.now().isoformat(),\r\n                'error': error_msg\r\n            })\r\n            return {}\r\n    \r\n    def process_content(self, content: Dict) -> List[Dict]:\r\n        \"\"\"\r\n        Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØªÙˆØ§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒâ€ŒØ´Ø¯Ù‡\r\n        \r\n        Args:\r\n            content: Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù…\r\n        \r\n        Returns:\r\n            Ù„ÛŒØ³Øª Ø§Ø³Ù†Ø§Ø¯ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ RAG\r\n        \"\"\"\r\n        documents = []\r\n        \r\n        for resource_key, resource_data in content.get('resources', {}).items():\r\n            # ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ\r\n            main_page = resource_data.get('main_page')\r\n            if main_page:\r\n                doc = self._create_document(\r\n                    main_page,\r\n                    resource_key,\r\n                    resource_data['info']['description']\r\n                )\r\n                documents.append(doc)\r\n            \r\n            # ØµÙØ­Ø§Øª ÙØ±Ø¹ÛŒ\r\n            for sub_page in resource_data.get('sub_pages', []):\r\n                doc = self._create_document(\r\n                    sub_page,\r\n                    resource_key,\r\n                    f\"Sub-page from {resource_key}\"\r\n                )\r\n                documents.append(doc)\r\n        \r\n        return documents\r\n    \r\n    def _create_document(self, page_data: Dict, resource_key: str, description: str) -> Dict:\r\n        \"\"\"Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù†Ø¯ Ø¨Ø±Ø§ÛŒ RAG\"\"\"\r\n        return {\r\n            'content': page_data.get('text', ''),\r\n            'title': page_data.get('title', 'Untitled'),\r\n            'url': page_data.get('url', ''),\r\n            'metadata': {\r\n                'university': self.university_info['name'],\r\n                'university_key': self.university_key,\r\n                'resource': resource_key,\r\n                'description': description,\r\n                'focus_areas': self.university_info['focus_areas'],\r\n                'country': self.university_info['country'],\r\n                'scraped_at': datetime.now().isoformat()\r\n            }\r\n        }\r\n    \r\n    def update_rag_system(self, documents: List[Dict]) -> int:\r\n        \"\"\"\r\n        Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø³ÛŒØ³ØªÙ… RAG Ø¨Ø§ Ø§Ø³Ù†Ø§Ø¯ Ø¬Ø¯ÛŒØ¯\r\n        \r\n        Args:\r\n            documents: Ù„ÛŒØ³Øª Ø§Ø³Ù†Ø§Ø¯\r\n        \r\n        Returns:\r\n            ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³Ù†Ø§Ø¯ Ø§Ø¶Ø§ÙÙ‡â€ŒØ´Ø¯Ù‡\r\n        \"\"\"\r\n        if not self.rag_system:\r\n            logger.warning(\"RAG system not available\")\r\n            return 0\r\n        \r\n        added = 0\r\n        for doc in documents:\r\n            try:\r\n                self.rag_system.add_document(\r\n                    doc['content'],\r\n                    doc['metadata']\r\n                )\r\n                added += 1\r\n            except Exception as e:\r\n                logger.error(f\"Error adding document: {e}\")\r\n        \r\n        logger.info(f\"  Added {added} documents to RAG system\")\r\n        return added\r\n    \r\n    def learn(self, collector: UniversityResourceCollector) -> Dict:\r\n        \"\"\"\r\n        ÙØ±Ø¢ÛŒÙ†Ø¯ Ú©Ø§Ù…Ù„ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ\r\n        \r\n        1. Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…Ø­ØªÙˆØ§\r\n        2. Ù¾Ø±Ø¯Ø§Ø²Ø´\r\n        3. Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ RAG\r\n        4. Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¶Ø¹ÛŒØª\r\n        \r\n        Returns:\r\n            Ø¢Ù…Ø§Ø± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ\r\n        \"\"\"\r\n        logger.info(f\"\\nðŸŽ“ Learning from: {self.university_info['name']}\")\r\n        \r\n        # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ\r\n        content = self.collect_content(collector)\r\n        if not content:\r\n            return {'status': 'failed', 'reason': 'No content collected'}\r\n        \r\n        # Ù¾Ø±Ø¯Ø§Ø²Ø´\r\n        documents = self.process_content(content)\r\n        logger.info(f\"  Processed {len(documents)} documents\")\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ RAG\r\n        added = self.update_rag_system(documents)\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª\r\n        self.state['last_update'] = datetime.now().isoformat()\r\n        self.state['total_documents'] += added\r\n        self.save_state()\r\n        \r\n        stats = {\r\n            'status': 'success',\r\n            'university': self.university_info['name'],\r\n            'pages_scraped': content.get('total_pages', 0),\r\n            'documents_processed': len(documents),\r\n            'documents_added_to_rag': added,\r\n            'timestamp': datetime.now().isoformat()\r\n        }\r\n        \r\n        logger.info(f\"  âœ“ Learning complete: {added} documents added\")\r\n        return stats\r\n    \r\n    def get_status(self) -> Dict:\r\n        \"\"\"ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ø§ÛŒØ¬Ù†Øª\"\"\"\r\n        return {\r\n            'university': self.university_info['name'],\r\n            'country': self.university_info['country'],\r\n            'focus_areas': self.university_info['focus_areas'],\r\n            'state': self.state,\r\n            'should_update': self.should_update()\r\n        }\r\n\r\n\r\nclass UniversityAgentManager:\r\n    \"\"\"\r\n    Ù…Ø¯ÛŒØ±ÛŒØª ØªÙ…Ø§Ù… Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ÛŒ\r\n    \"\"\"\r\n    \r\n    def __init__(\r\n        self,\r\n        universities: Dict,\r\n        config: Dict,\r\n        rag_system: Optional[RAGSystem] = None\r\n    ):\r\n        self.universities = universities\r\n        self.config = config\r\n        self.rag_system = rag_system\r\n        \r\n        # Ø§ÛŒØ¬Ø§Ø¯ Ø§ÛŒØ¬Ù†Øª Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\r\n        self.agents = {}\r\n        for key, info in universities.items():\r\n            self.agents[key] = UniversityAgent(key, info, config, rag_system)\r\n        \r\n        logger.info(f\"âœ“ Initialized {len(self.agents)} university agents\")\r\n    \r\n    def learn_from_all(self) -> Dict:\r\n        \"\"\"\r\n        ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø² Ù‡Ù…Ù‡ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§\r\n        \r\n        Returns:\r\n            Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ\r\n        \"\"\"\r\n        collector = UniversityResourceCollector(self.universities, self.config)\r\n        \r\n        results = []\r\n        for agent_key, agent in self.agents.items():\r\n            if agent.should_update():\r\n                result = agent.learn(collector)\r\n                results.append(result)\r\n            else:\r\n                logger.info(f\"  Skipping {agent.university_info['name']} (not due for update)\")\r\n        \r\n        # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ\r\n        stats = {\r\n            'total_agents': len(self.agents),\r\n            'agents_updated': len(results),\r\n            'total_pages_scraped': sum(r.get('pages_scraped', 0) for r in results),\r\n            'total_documents_added': sum(r.get('documents_added_to_rag', 0) for r in results),\r\n            'results': results\r\n        }\r\n        \r\n        logger.info(f\"\\n{'='*80}\")\r\n        logger.info(f\"Learning Summary:\")\r\n        logger.info(f\"  Agents updated: {stats['agents_updated']}/{stats['total_agents']}\")\r\n        logger.info(f\"  Pages scraped: {stats['total_pages_scraped']}\")\r\n        logger.info(f\"  Documents added to RAG: {stats['total_documents_added']}\")\r\n        logger.info(f\"{'='*80}\\n\")\r\n        \r\n        return stats\r\n    \r\n    def learn_from_specific(self, university_keys: List[str]) -> Dict:\r\n        \"\"\"\r\n        ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø² Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ\r\n        \r\n        Args:\r\n            university_keys: Ù„ÛŒØ³Øª Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\r\n        \r\n        Returns:\r\n            Ø¢Ù…Ø§Ø± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ\r\n        \"\"\"\r\n        collector = UniversityResourceCollector(self.universities, self.config)\r\n        \r\n        results = []\r\n        for key in university_keys:\r\n            if key in self.agents:\r\n                result = self.agents[key].learn(collector)\r\n                results.append(result)\r\n        \r\n        return {\r\n            'agents_updated': len(results),\r\n            'results': results\r\n        }\r\n    \r\n    def get_all_statuses(self) -> List[Dict]:\r\n        \"\"\"ÙˆØ¶Ø¹ÛŒØª Ù‡Ù…Ù‡ Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§\"\"\"\r\n        return [agent.get_status() for agent in self.agents.values()]\r\n    \r\n    def get_statistics(self) -> Dict:\r\n        \"\"\"Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ Ø³ÛŒØ³ØªÙ…\"\"\"\r\n        statuses = self.get_all_statuses()\r\n        \r\n        return {\r\n            'total_agents': len(self.agents),\r\n            'agents_needing_update': sum(1 for s in statuses if s['should_update']),\r\n            'total_documents_collected': sum(s['state']['total_documents'] for s in statuses),\r\n            'total_pages_scraped': sum(s['state']['total_pages_scraped'] for s in statuses),\r\n            'by_university': {\r\n                s['university']: {\r\n                    'country': s['country'],\r\n                    'focus_areas': s['focus_areas'],\r\n                    'documents': s['state']['total_documents'],\r\n                    'pages': s['state']['total_pages_scraped'],\r\n                    'last_update': s['state']['last_update']\r\n                }\r\n                for s in statuses\r\n            }\r\n        }\r\n",
    "format": "py"
  },
  {
    "timestamp": "2025-11-21T23:24:35.291Z",
    "fileName": "cad3d\\super_ai\\university_agents.py",
    "content": "\"\"\"\r\nUniversity Learning Agents - Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ÛŒ\r\n\r\nØ§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ Ø¨Ø±Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø¯Ø§ÙˆÙ… Ø§Ø² Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø±ØªØ±\r\n\"\"\"\r\n\r\nimport logging\r\nfrom typing import Dict, List, Optional\r\nfrom datetime import datetime, timedelta\r\nimport json\r\nfrom pathlib import Path\r\n\r\nfrom .university_scraper import UniversityResourceCollector\r\nfrom .rag_system import RAGSystem\r\nfrom .agent_security import AgentSecuritySystem, SpecializationManager, ComplianceLevel\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\nclass UniversityAgent:\r\n    \"\"\"\r\n    Ø§ÛŒØ¬Ù†Øª ØªØ®ØµØµÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\r\n    \r\n    Ù…Ø³Ø¦ÙˆÙ„ÛŒØªâ€ŒÙ‡Ø§:\r\n    - Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ Ù…Ø­ØªÙˆØ§\r\n    - Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª\r\n    - Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ RAG\r\n    - Ø±Ø¯ÛŒØ§Ø¨ÛŒ ØªØºÛŒÛŒØ±Ø§Øª Ùˆ Ù…Ø­ØªÙˆØ§ÛŒ Ø¬Ø¯ÛŒØ¯\r\n    \"\"\"\r\n    \r\n    def __init__(\r\n        self,\r\n        university_key: str,\r\n        university_info: Dict,\r\n        config: Dict,\r\n        rag_system: Optional[RAGSystem] = None,\r\n        security_system: Optional[AgentSecuritySystem] = None\r\n    ):\r\n        self.university_key = university_key\r\n        self.university_info = university_info\r\n        self.config = config\r\n        self.rag_system = rag_system\r\n        self.security_system = security_system or AgentSecuritySystem()\r\n        \r\n        self.state = {\r\n            'last_update': None,\r\n            'total_documents': 0,\r\n            'total_pages_scraped': 0,\r\n            'last_successful_scrape': None,\r\n            'errors': [],\r\n            'security_violations': 0,\r\n            'compliance_score': 100.0\r\n        }\r\n        \r\n        # State file\r\n        self.state_file = Path(config['storage']['cache_dir']) / f\"{university_key}_state.json\"\r\n        self.load_state()\r\n    \r\n    def load_state(self):\r\n        \"\"\"Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø§Ø² ÙØ§ÛŒÙ„\"\"\"\r\n        if self.state_file.exists():\r\n            with open(self.state_file, 'r', encoding='utf-8') as f:\r\n                self.state = json.load(f)\r\n    \r\n    def save_state(self):\r\n        \"\"\"Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø¯Ø± ÙØ§ÛŒÙ„\"\"\"\r\n        with open(self.state_file, 'w', encoding='utf-8') as f:\r\n            json.dump(self.state, f, ensure_ascii=False, indent=2)\r\n    \r\n    def should_update(self) -> bool:\r\n        \"\"\"\r\n        Ø¨Ø±Ø±Ø³ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ\r\n        \r\n        Returns:\r\n            True Ø§Ú¯Ø± Ø²Ù…Ø§Ù† Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø±Ø³ÛŒØ¯Ù‡ Ø¨Ø§Ø´Ø¯\r\n        \"\"\"\r\n        if self.state['last_update'] is None:\r\n            return True\r\n        \r\n        last_update = datetime.fromisoformat(self.state['last_update'])\r\n        update_frequency = self.config['learning']['update_frequency']\r\n        \r\n        if update_frequency == 'daily':\r\n            return datetime.now() - last_update > timedelta(days=1)\r\n        elif update_frequency == 'weekly':\r\n            return datetime.now() - last_update > timedelta(weeks=1)\r\n        elif update_frequency == 'monthly':\r\n            return datetime.now() - last_update > timedelta(days=30)\r\n        \r\n        return False\r\n    \r\n    def collect_content(self, collector: UniversityResourceCollector) -> Dict:\r\n        \"\"\"\r\n        Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…Ø­ØªÙˆØ§ Ø§Ø² Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\r\n        \r\n        Args:\r\n            collector: Ø´ÛŒØ¡ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒâ€ŒÚ©Ù†Ù†Ø¯Ù‡\r\n        \r\n        Returns:\r\n            Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒâ€ŒØ´Ø¯Ù‡\r\n        \"\"\"\r\n        logger.info(f\"\\n{'='*80}\")\r\n        logger.info(f\"Agent: {self.university_info['name']}\")\r\n        logger.info(f\"{'='*80}\")\r\n        \r\n        try:\r\n            max_pages = self.config['learning']['max_documents_per_session']\r\n            data = collector.collect_from_university(self.university_key, max_pages)\r\n            \r\n            self.state['last_successful_scrape'] = datetime.now().isoformat()\r\n            self.state['total_pages_scraped'] += data.get('total_pages', 0)\r\n            \r\n            return data\r\n            \r\n        except Exception as e:\r\n            error_msg = f\"Error collecting content: {str(e)}\"\r\n            logger.error(error_msg)\r\n            self.state['errors'].append({\r\n                'timestamp': datetime.now().isoformat(),\r\n                'error': error_msg\r\n            })\r\n            return {}\r\n    \r\n    def process_content(self, content: Dict) -> List[Dict]:\r\n        \"\"\"\r\n        Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØªÙˆØ§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒâ€ŒØ´Ø¯Ù‡\r\n        \r\n        Args:\r\n            content: Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù…\r\n        \r\n        Returns:\r\n            Ù„ÛŒØ³Øª Ø§Ø³Ù†Ø§Ø¯ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ RAG\r\n        \"\"\"\r\n        documents = []\r\n        \r\n        for resource_key, resource_data in content.get('resources', {}).items():\r\n            # ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ\r\n            main_page = resource_data.get('main_page')\r\n            if main_page:\r\n                doc = self._create_document(\r\n                    main_page,\r\n                    resource_key,\r\n                    resource_data['info']['description']\r\n                )\r\n                documents.append(doc)\r\n            \r\n            # ØµÙØ­Ø§Øª ÙØ±Ø¹ÛŒ\r\n            for sub_page in resource_data.get('sub_pages', []):\r\n                doc = self._create_document(\r\n                    sub_page,\r\n                    resource_key,\r\n                    f\"Sub-page from {resource_key}\"\r\n                )\r\n                documents.append(doc)\r\n        \r\n        return documents\r\n    \r\n    def _create_document(self, page_data: Dict, resource_key: str, description: str) -> Dict:\r\n        \"\"\"Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù†Ø¯ Ø¨Ø±Ø§ÛŒ RAG\"\"\"\r\n        return {\r\n            'content': page_data.get('text', ''),\r\n            'title': page_data.get('title', 'Untitled'),\r\n            'url': page_data.get('url', ''),\r\n            'metadata': {\r\n                'university': self.university_info['name'],\r\n                'university_key': self.university_key,\r\n                'resource': resource_key,\r\n                'description': description,\r\n                'focus_areas': self.university_info['focus_areas'],\r\n                'country': self.university_info['country'],\r\n                'scraped_at': datetime.now().isoformat()\r\n            }\r\n        }\r\n    \r\n    def update_rag_system(self, documents: List[Dict]) -> int:\r\n        \"\"\"\r\n        Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø³ÛŒØ³ØªÙ… RAG Ø¨Ø§ Ø§Ø³Ù†Ø§Ø¯ Ø¬Ø¯ÛŒØ¯ (Ø¨Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ)\r\n        \r\n        Args:\r\n            documents: Ù„ÛŒØ³Øª Ø§Ø³Ù†Ø§Ø¯\r\n        \r\n        Returns:\r\n            ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³Ù†Ø§Ø¯ Ø§Ø¶Ø§ÙÙ‡â€ŒØ´Ø¯Ù‡\r\n        \"\"\"\r\n        if not self.rag_system:\r\n            logger.warning(\"RAG system not available\")\r\n            return 0\r\n        \r\n        added = 0\r\n        violations = 0\r\n        \r\n        for doc in documents:\r\n            try:\r\n                # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ\r\n                is_valid, compliance, reason = self.security_system.validate_document(doc)\r\n                \r\n                if not is_valid:\r\n                    violations += 1\r\n                    logger.warning(f\"  âš ï¸  Document rejected: {reason}\")\r\n                    continue\r\n                \r\n                if compliance == ComplianceLevel.WARNING:\r\n                    logger.info(f\"  âš ï¸  Document accepted with warning: {reason}\")\r\n                \r\n                # Ø§Ø¶Ø§ÙÙ‡ Ø¨Ù‡ RAG\r\n                self.rag_system.add_document(\r\n                    doc['content'],\r\n                    doc['metadata']\r\n                )\r\n                added += 1\r\n                \r\n            except Exception as e:\r\n                logger.error(f\"Error adding document: {e}\")\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø± Ø§Ù…Ù†ÛŒØªÛŒ\r\n        self.state['security_violations'] += violations\r\n        self.state['compliance_score'] = self.security_system.get_agent_score(self.university_key)\r\n        \r\n        logger.info(f\"  Added {added} documents to RAG system\")\r\n        if violations > 0:\r\n            logger.warning(f\"  âš ï¸  {violations} documents rejected due to security\")\r\n        \r\n        return added\r\n    \r\n    def learn(self, collector: UniversityResourceCollector) -> Dict:\r\n        \"\"\"\r\n        ÙØ±Ø¢ÛŒÙ†Ø¯ Ú©Ø§Ù…Ù„ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ\r\n        \r\n        1. Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…Ø­ØªÙˆØ§\r\n        2. Ù¾Ø±Ø¯Ø§Ø²Ø´\r\n        3. Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ RAG\r\n        4. Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¶Ø¹ÛŒØª\r\n        \r\n        Returns:\r\n            Ø¢Ù…Ø§Ø± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ\r\n        \"\"\"\r\n        logger.info(f\"\\nðŸŽ“ Learning from: {self.university_info['name']}\")\r\n        \r\n        # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ\r\n        content = self.collect_content(collector)\r\n        if not content:\r\n            return {'status': 'failed', 'reason': 'No content collected'}\r\n        \r\n        # Ù¾Ø±Ø¯Ø§Ø²Ø´\r\n        documents = self.process_content(content)\r\n        logger.info(f\"  Processed {len(documents)} documents\")\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ RAG\r\n        added = self.update_rag_system(documents)\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª\r\n        self.state['last_update'] = datetime.now().isoformat()\r\n        self.state['total_documents'] += added\r\n        self.save_state()\r\n        \r\n        stats = {\r\n            'status': 'success',\r\n            'university': self.university_info['name'],\r\n            'pages_scraped': content.get('total_pages', 0),\r\n            'documents_processed': len(documents),\r\n            'documents_added_to_rag': added,\r\n            'timestamp': datetime.now().isoformat()\r\n        }\r\n        \r\n        logger.info(f\"  âœ“ Learning complete: {added} documents added\")\r\n        return stats\r\n    \r\n    def get_status(self) -> Dict:\r\n        \"\"\"ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ø§ÛŒØ¬Ù†Øª\"\"\"\r\n        return {\r\n            'university': self.university_info['name'],\r\n            'country': self.university_info['country'],\r\n            'focus_areas': self.university_info['focus_areas'],\r\n            'state': self.state,\r\n            'should_update': self.should_update()\r\n        }\r\n\r\n\r\nclass UniversityAgentManager:\r\n    \"\"\"\r\n    Ù…Ø¯ÛŒØ±ÛŒØª ØªÙ…Ø§Ù… Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ÛŒ\r\n    \"\"\"\r\n    \r\n    def __init__(\r\n        self,\r\n        universities: Dict,\r\n        config: Dict,\r\n        rag_system: Optional[RAGSystem] = None\r\n    ):\r\n        self.universities = universities\r\n        self.config = config\r\n        self.rag_system = rag_system\r\n        \r\n        # Ø§ÛŒØ¬Ø§Ø¯ Ø§ÛŒØ¬Ù†Øª Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\r\n        self.agents = {}\r\n        for key, info in universities.items():\r\n            self.agents[key] = UniversityAgent(key, info, config, rag_system)\r\n        \r\n        logger.info(f\"âœ“ Initialized {len(self.agents)} university agents\")\r\n    \r\n    def learn_from_all(self) -> Dict:\r\n        \"\"\"\r\n        ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø² Ù‡Ù…Ù‡ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§\r\n        \r\n        Returns:\r\n            Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ\r\n        \"\"\"\r\n        collector = UniversityResourceCollector(self.universities, self.config)\r\n        \r\n        results = []\r\n        for agent_key, agent in self.agents.items():\r\n            if agent.should_update():\r\n                result = agent.learn(collector)\r\n                results.append(result)\r\n            else:\r\n                logger.info(f\"  Skipping {agent.university_info['name']} (not due for update)\")\r\n        \r\n        # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ\r\n        stats = {\r\n            'total_agents': len(self.agents),\r\n            'agents_updated': len(results),\r\n            'total_pages_scraped': sum(r.get('pages_scraped', 0) for r in results),\r\n            'total_documents_added': sum(r.get('documents_added_to_rag', 0) for r in results),\r\n            'results': results\r\n        }\r\n        \r\n        logger.info(f\"\\n{'='*80}\")\r\n        logger.info(f\"Learning Summary:\")\r\n        logger.info(f\"  Agents updated: {stats['agents_updated']}/{stats['total_agents']}\")\r\n        logger.info(f\"  Pages scraped: {stats['total_pages_scraped']}\")\r\n        logger.info(f\"  Documents added to RAG: {stats['total_documents_added']}\")\r\n        logger.info(f\"{'='*80}\\n\")\r\n        \r\n        return stats\r\n    \r\n    def learn_from_specific(self, university_keys: List[str]) -> Dict:\r\n        \"\"\"\r\n        ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø² Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ\r\n        \r\n        Args:\r\n            university_keys: Ù„ÛŒØ³Øª Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\r\n        \r\n        Returns:\r\n            Ø¢Ù…Ø§Ø± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ\r\n        \"\"\"\r\n        collector = UniversityResourceCollector(self.universities, self.config)\r\n        \r\n        results = []\r\n        for key in university_keys:\r\n            if key in self.agents:\r\n                result = self.agents[key].learn(collector)\r\n                results.append(result)\r\n        \r\n        return {\r\n            'agents_updated': len(results),\r\n            'results': results\r\n        }\r\n    \r\n    def get_all_statuses(self) -> List[Dict]:\r\n        \"\"\"ÙˆØ¶Ø¹ÛŒØª Ù‡Ù…Ù‡ Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§\"\"\"\r\n        return [agent.get_status() for agent in self.agents.values()]\r\n    \r\n    def get_statistics(self) -> Dict:\r\n        \"\"\"Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ Ø³ÛŒØ³ØªÙ…\"\"\"\r\n        statuses = self.get_all_statuses()\r\n        \r\n        return {\r\n            'total_agents': len(self.agents),\r\n            'agents_needing_update': sum(1 for s in statuses if s['should_update']),\r\n            'total_documents_collected': sum(s['state']['total_documents'] for s in statuses),\r\n            'total_pages_scraped': sum(s['state']['total_pages_scraped'] for s in statuses),\r\n            'by_university': {\r\n                s['university']: {\r\n                    'country': s['country'],\r\n                    'focus_areas': s['focus_areas'],\r\n                    'documents': s['state']['total_documents'],\r\n                    'pages': s['state']['total_pages_scraped'],\r\n                    'last_update': s['state']['last_update']\r\n                }\r\n                for s in statuses\r\n            }\r\n        }\r\n",
    "format": "py"
  },
  {
    "timestamp": "2025-11-21T23:24:41.686Z",
    "fileName": "cad3d\\super_ai\\university_agents.py",
    "content": "\"\"\"\r\nUniversity Learning Agents - Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ÛŒ\r\n\r\nØ§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ Ø¨Ø±Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø¯Ø§ÙˆÙ… Ø§Ø² Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø±ØªØ±\r\n\"\"\"\r\n\r\nimport logging\r\nfrom typing import Dict, List, Optional\r\nfrom datetime import datetime, timedelta\r\nimport json\r\nfrom pathlib import Path\r\n\r\nfrom .university_scraper import UniversityResourceCollector\r\nfrom .rag_system import RAGSystem\r\nfrom .agent_security import AgentSecuritySystem, SpecializationManager, ComplianceLevel\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\nclass UniversityAgent:\r\n    \"\"\"\r\n    Ø§ÛŒØ¬Ù†Øª ØªØ®ØµØµÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\r\n    \r\n    Ù…Ø³Ø¦ÙˆÙ„ÛŒØªâ€ŒÙ‡Ø§:\r\n    - Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ Ù…Ø­ØªÙˆØ§\r\n    - Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª\r\n    - Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ RAG\r\n    - Ø±Ø¯ÛŒØ§Ø¨ÛŒ ØªØºÛŒÛŒØ±Ø§Øª Ùˆ Ù…Ø­ØªÙˆØ§ÛŒ Ø¬Ø¯ÛŒØ¯\r\n    \"\"\"\r\n    \r\n    def __init__(\r\n        self,\r\n        university_key: str,\r\n        university_info: Dict,\r\n        config: Dict,\r\n        rag_system: Optional[RAGSystem] = None,\r\n        security_system: Optional[AgentSecuritySystem] = None\r\n    ):\r\n        self.university_key = university_key\r\n        self.university_info = university_info\r\n        self.config = config\r\n        self.rag_system = rag_system\r\n        self.security_system = security_system or AgentSecuritySystem()\r\n        \r\n        self.state = {\r\n            'last_update': None,\r\n            'total_documents': 0,\r\n            'total_pages_scraped': 0,\r\n            'last_successful_scrape': None,\r\n            'errors': [],\r\n            'security_violations': 0,\r\n            'compliance_score': 100.0\r\n        }\r\n        \r\n        # State file\r\n        self.state_file = Path(config['storage']['cache_dir']) / f\"{university_key}_state.json\"\r\n        self.load_state()\r\n    \r\n    def load_state(self):\r\n        \"\"\"Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø§Ø² ÙØ§ÛŒÙ„\"\"\"\r\n        if self.state_file.exists():\r\n            with open(self.state_file, 'r', encoding='utf-8') as f:\r\n                self.state = json.load(f)\r\n    \r\n    def save_state(self):\r\n        \"\"\"Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø¯Ø± ÙØ§ÛŒÙ„\"\"\"\r\n        with open(self.state_file, 'w', encoding='utf-8') as f:\r\n            json.dump(self.state, f, ensure_ascii=False, indent=2)\r\n    \r\n    def should_update(self) -> bool:\r\n        \"\"\"\r\n        Ø¨Ø±Ø±Ø³ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ\r\n        \r\n        Returns:\r\n            True Ø§Ú¯Ø± Ø²Ù…Ø§Ù† Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø±Ø³ÛŒØ¯Ù‡ Ø¨Ø§Ø´Ø¯\r\n        \"\"\"\r\n        if self.state['last_update'] is None:\r\n            return True\r\n        \r\n        last_update = datetime.fromisoformat(self.state['last_update'])\r\n        update_frequency = self.config['learning']['update_frequency']\r\n        \r\n        if update_frequency == 'daily':\r\n            return datetime.now() - last_update > timedelta(days=1)\r\n        elif update_frequency == 'weekly':\r\n            return datetime.now() - last_update > timedelta(weeks=1)\r\n        elif update_frequency == 'monthly':\r\n            return datetime.now() - last_update > timedelta(days=30)\r\n        \r\n        return False\r\n    \r\n    def collect_content(self, collector: UniversityResourceCollector) -> Dict:\r\n        \"\"\"\r\n        Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…Ø­ØªÙˆØ§ Ø§Ø² Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\r\n        \r\n        Args:\r\n            collector: Ø´ÛŒØ¡ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒâ€ŒÚ©Ù†Ù†Ø¯Ù‡\r\n        \r\n        Returns:\r\n            Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒâ€ŒØ´Ø¯Ù‡\r\n        \"\"\"\r\n        logger.info(f\"\\n{'='*80}\")\r\n        logger.info(f\"Agent: {self.university_info['name']}\")\r\n        logger.info(f\"{'='*80}\")\r\n        \r\n        try:\r\n            max_pages = self.config['learning']['max_documents_per_session']\r\n            data = collector.collect_from_university(self.university_key, max_pages)\r\n            \r\n            self.state['last_successful_scrape'] = datetime.now().isoformat()\r\n            self.state['total_pages_scraped'] += data.get('total_pages', 0)\r\n            \r\n            return data\r\n            \r\n        except Exception as e:\r\n            error_msg = f\"Error collecting content: {str(e)}\"\r\n            logger.error(error_msg)\r\n            self.state['errors'].append({\r\n                'timestamp': datetime.now().isoformat(),\r\n                'error': error_msg\r\n            })\r\n            return {}\r\n    \r\n    def process_content(self, content: Dict) -> List[Dict]:\r\n        \"\"\"\r\n        Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØªÙˆØ§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒâ€ŒØ´Ø¯Ù‡\r\n        \r\n        Args:\r\n            content: Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù…\r\n        \r\n        Returns:\r\n            Ù„ÛŒØ³Øª Ø§Ø³Ù†Ø§Ø¯ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ RAG\r\n        \"\"\"\r\n        documents = []\r\n        \r\n        for resource_key, resource_data in content.get('resources', {}).items():\r\n            # ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ\r\n            main_page = resource_data.get('main_page')\r\n            if main_page:\r\n                doc = self._create_document(\r\n                    main_page,\r\n                    resource_key,\r\n                    resource_data['info']['description']\r\n                )\r\n                documents.append(doc)\r\n            \r\n            # ØµÙØ­Ø§Øª ÙØ±Ø¹ÛŒ\r\n            for sub_page in resource_data.get('sub_pages', []):\r\n                doc = self._create_document(\r\n                    sub_page,\r\n                    resource_key,\r\n                    f\"Sub-page from {resource_key}\"\r\n                )\r\n                documents.append(doc)\r\n        \r\n        return documents\r\n    \r\n    def _create_document(self, page_data: Dict, resource_key: str, description: str) -> Dict:\r\n        \"\"\"Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù†Ø¯ Ø¨Ø±Ø§ÛŒ RAG\"\"\"\r\n        return {\r\n            'content': page_data.get('text', ''),\r\n            'title': page_data.get('title', 'Untitled'),\r\n            'url': page_data.get('url', ''),\r\n            'metadata': {\r\n                'university': self.university_info['name'],\r\n                'university_key': self.university_key,\r\n                'resource': resource_key,\r\n                'description': description,\r\n                'focus_areas': self.university_info['focus_areas'],\r\n                'country': self.university_info['country'],\r\n                'scraped_at': datetime.now().isoformat()\r\n            }\r\n        }\r\n    \r\n    def update_rag_system(self, documents: List[Dict]) -> int:\r\n        \"\"\"\r\n        Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø³ÛŒØ³ØªÙ… RAG Ø¨Ø§ Ø§Ø³Ù†Ø§Ø¯ Ø¬Ø¯ÛŒØ¯ (Ø¨Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ)\r\n        \r\n        Args:\r\n            documents: Ù„ÛŒØ³Øª Ø§Ø³Ù†Ø§Ø¯\r\n        \r\n        Returns:\r\n            ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³Ù†Ø§Ø¯ Ø§Ø¶Ø§ÙÙ‡â€ŒØ´Ø¯Ù‡\r\n        \"\"\"\r\n        if not self.rag_system:\r\n            logger.warning(\"RAG system not available\")\r\n            return 0\r\n        \r\n        added = 0\r\n        violations = 0\r\n        \r\n        for doc in documents:\r\n            try:\r\n                # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ\r\n                is_valid, compliance, reason = self.security_system.validate_document(doc)\r\n                \r\n                if not is_valid:\r\n                    violations += 1\r\n                    logger.warning(f\"  âš ï¸  Document rejected: {reason}\")\r\n                    continue\r\n                \r\n                if compliance == ComplianceLevel.WARNING:\r\n                    logger.info(f\"  âš ï¸  Document accepted with warning: {reason}\")\r\n                \r\n                # Ø§Ø¶Ø§ÙÙ‡ Ø¨Ù‡ RAG\r\n                self.rag_system.add_document(\r\n                    doc['content'],\r\n                    doc['metadata']\r\n                )\r\n                added += 1\r\n                \r\n            except Exception as e:\r\n                logger.error(f\"Error adding document: {e}\")\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø± Ø§Ù…Ù†ÛŒØªÛŒ\r\n        self.state['security_violations'] += violations\r\n        self.state['compliance_score'] = self.security_system.get_agent_score(self.university_key)\r\n        \r\n        logger.info(f\"  Added {added} documents to RAG system\")\r\n        if violations > 0:\r\n            logger.warning(f\"  âš ï¸  {violations} documents rejected due to security\")\r\n        \r\n        return added\r\n    \r\n    def learn(self, collector: UniversityResourceCollector) -> Dict:\r\n        \"\"\"\r\n        ÙØ±Ø¢ÛŒÙ†Ø¯ Ú©Ø§Ù…Ù„ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ\r\n        \r\n        1. Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…Ø­ØªÙˆØ§\r\n        2. Ù¾Ø±Ø¯Ø§Ø²Ø´\r\n        3. Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ RAG\r\n        4. Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¶Ø¹ÛŒØª\r\n        \r\n        Returns:\r\n            Ø¢Ù…Ø§Ø± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ\r\n        \"\"\"\r\n        logger.info(f\"\\nðŸŽ“ Learning from: {self.university_info['name']}\")\r\n        \r\n        # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ\r\n        content = self.collect_content(collector)\r\n        if not content:\r\n            return {'status': 'failed', 'reason': 'No content collected'}\r\n        \r\n        # Ù¾Ø±Ø¯Ø§Ø²Ø´\r\n        documents = self.process_content(content)\r\n        logger.info(f\"  Processed {len(documents)} documents\")\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ RAG\r\n        added = self.update_rag_system(documents)\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª\r\n        self.state['last_update'] = datetime.now().isoformat()\r\n        self.state['total_documents'] += added\r\n        self.save_state()\r\n        \r\n        stats = {\r\n            'status': 'success',\r\n            'university': self.university_info['name'],\r\n            'pages_scraped': content.get('total_pages', 0),\r\n            'documents_processed': len(documents),\r\n            'documents_added_to_rag': added,\r\n            'timestamp': datetime.now().isoformat()\r\n        }\r\n        \r\n        logger.info(f\"  âœ“ Learning complete: {added} documents added\")\r\n        return stats\r\n    \r\n    def get_status(self) -> Dict:\r\n        \"\"\"ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ø§ÛŒØ¬Ù†Øª\"\"\"\r\n        return {\r\n            'university': self.university_info['name'],\r\n            'country': self.university_info['country'],\r\n            'focus_areas': self.university_info['focus_areas'],\r\n            'state': self.state,\r\n            'should_update': self.should_update()\r\n        }\r\n\r\n\r\nclass UniversityAgentManager:\r\n    \"\"\"\r\n    Ù…Ø¯ÛŒØ±ÛŒØª ØªÙ…Ø§Ù… Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ÛŒ\r\n    \"\"\"\r\n    \r\n    def __init__(\r\n        self,\r\n        universities: Dict,\r\n        config: Dict,\r\n        rag_system: Optional[RAGSystem] = None\r\n    ):\r\n        self.universities = universities\r\n        self.config = config\r\n        self.rag_system = rag_system\r\n        \r\n        # Ø§ÛŒØ¬Ø§Ø¯ Ø§ÛŒØ¬Ù†Øª Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\r\n        self.agents = {}\r\n        for key, info in universities.items():\r\n            self.agents[key] = UniversityAgent(key, info, config, rag_system)\r\n        \r\n        logger.info(f\"âœ“ Initialized {len(self.agents)} university agents\")\r\n    \r\n    def learn_from_all(self) -> Dict:\r\n        \"\"\"\r\n        ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø² Ù‡Ù…Ù‡ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§\r\n        \r\n        Returns:\r\n            Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ\r\n        \"\"\"\r\n        collector = UniversityResourceCollector(self.universities, self.config)\r\n        \r\n        results = []\r\n        for agent_key, agent in self.agents.items():\r\n            if agent.should_update():\r\n                result = agent.learn(collector)\r\n                results.append(result)\r\n            else:\r\n                logger.info(f\"  Skipping {agent.university_info['name']} (not due for update)\")\r\n        \r\n        # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ\r\n        stats = {\r\n            'total_agents': len(self.agents),\r\n            'agents_updated': len(results),\r\n            'total_pages_scraped': sum(r.get('pages_scraped', 0) for r in results),\r\n            'total_documents_added': sum(r.get('documents_added_to_rag', 0) for r in results),\r\n            'results': results\r\n        }\r\n        \r\n        logger.info(f\"\\n{'='*80}\")\r\n        logger.info(f\"Learning Summary:\")\r\n        logger.info(f\"  Agents updated: {stats['agents_updated']}/{stats['total_agents']}\")\r\n        logger.info(f\"  Pages scraped: {stats['total_pages_scraped']}\")\r\n        logger.info(f\"  Documents added to RAG: {stats['total_documents_added']}\")\r\n        logger.info(f\"{'='*80}\\n\")\r\n        \r\n        return stats\r\n    \r\n    def learn_from_specific(self, university_keys: List[str]) -> Dict:\r\n        \"\"\"\r\n        ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø² Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ\r\n        \r\n        Args:\r\n            university_keys: Ù„ÛŒØ³Øª Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\r\n        \r\n        Returns:\r\n            Ø¢Ù…Ø§Ø± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ\r\n        \"\"\"\r\n        collector = UniversityResourceCollector(self.universities, self.config)\r\n        \r\n        results = []\r\n        for key in university_keys:\r\n            if key in self.agents:\r\n                result = self.agents[key].learn(collector)\r\n                results.append(result)\r\n        \r\n        return {\r\n            'agents_updated': len(results),\r\n            'results': results\r\n        }\r\n    \r\n    def get_all_statuses(self) -> List[Dict]:\r\n        \"\"\"ÙˆØ¶Ø¹ÛŒØª Ù‡Ù…Ù‡ Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§\"\"\"\r\n        return [agent.get_status() for agent in self.agents.values()]\r\n    \r\n    def get_statistics(self) -> Dict:\r\n        \"\"\"Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ Ø³ÛŒØ³ØªÙ…\"\"\"\r\n        statuses = self.get_all_statuses()\r\n        \r\n        return {\r\n            'total_agents': len(self.agents),\r\n            'agents_needing_update': sum(1 for s in statuses if s['should_update']),\r\n            'total_documents_collected': sum(s['state']['total_documents'] for s in statuses),\r\n            'total_pages_scraped': sum(s['state']['total_pages_scraped'] for s in statuses),\r\n            'by_university': {\r\n                s['university']: {\r\n                    'country': s['country'],\r\n                    'focus_areas': s['focus_areas'],\r\n                    'documents': s['state']['total_documents'],\r\n                    'pages': s['state']['total_pages_scraped'],\r\n                    'last_update': s['state']['last_update']\r\n                }\r\n                for s in statuses\r\n            }\r\n        }\r\n",
    "format": "py"
  },
  {
    "timestamp": "2025-11-21T23:24:51.302Z",
    "fileName": "cad3d\\super_ai\\university_agents.py",
    "content": "\"\"\"\r\nUniversity Learning Agents - Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ÛŒ\r\n\r\nØ§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ Ø¨Ø±Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø¯Ø§ÙˆÙ… Ø§Ø² Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø±ØªØ±\r\n\"\"\"\r\n\r\nimport logging\r\nfrom typing import Dict, List, Optional\r\nfrom datetime import datetime, timedelta\r\nimport json\r\nfrom pathlib import Path\r\n\r\nfrom .university_scraper import UniversityResourceCollector\r\nfrom .rag_system import RAGSystem\r\nfrom .agent_security import AgentSecuritySystem, SpecializationManager, ComplianceLevel\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\nclass UniversityAgent:\r\n    \"\"\"\r\n    Ø§ÛŒØ¬Ù†Øª ØªØ®ØµØµÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\r\n    \r\n    Ù…Ø³Ø¦ÙˆÙ„ÛŒØªâ€ŒÙ‡Ø§:\r\n    - Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ Ù…Ø­ØªÙˆØ§\r\n    - Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª\r\n    - Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ RAG\r\n    - Ø±Ø¯ÛŒØ§Ø¨ÛŒ ØªØºÛŒÛŒØ±Ø§Øª Ùˆ Ù…Ø­ØªÙˆØ§ÛŒ Ø¬Ø¯ÛŒØ¯\r\n    \"\"\"\r\n    \r\n    def __init__(\r\n        self,\r\n        university_key: str,\r\n        university_info: Dict,\r\n        config: Dict,\r\n        rag_system: Optional[RAGSystem] = None,\r\n        security_system: Optional[AgentSecuritySystem] = None\r\n    ):\r\n        self.university_key = university_key\r\n        self.university_info = university_info\r\n        self.config = config\r\n        self.rag_system = rag_system\r\n        self.security_system = security_system or AgentSecuritySystem()\r\n        \r\n        self.state = {\r\n            'last_update': None,\r\n            'total_documents': 0,\r\n            'total_pages_scraped': 0,\r\n            'last_successful_scrape': None,\r\n            'errors': [],\r\n            'security_violations': 0,\r\n            'compliance_score': 100.0\r\n        }\r\n        \r\n        # State file\r\n        self.state_file = Path(config['storage']['cache_dir']) / f\"{university_key}_state.json\"\r\n        self.load_state()\r\n    \r\n    def load_state(self):\r\n        \"\"\"Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø§Ø² ÙØ§ÛŒÙ„\"\"\"\r\n        if self.state_file.exists():\r\n            with open(self.state_file, 'r', encoding='utf-8') as f:\r\n                self.state = json.load(f)\r\n    \r\n    def save_state(self):\r\n        \"\"\"Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø¯Ø± ÙØ§ÛŒÙ„\"\"\"\r\n        with open(self.state_file, 'w', encoding='utf-8') as f:\r\n            json.dump(self.state, f, ensure_ascii=False, indent=2)\r\n    \r\n    def should_update(self) -> bool:\r\n        \"\"\"\r\n        Ø¨Ø±Ø±Ø³ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ\r\n        \r\n        Returns:\r\n            True Ø§Ú¯Ø± Ø²Ù…Ø§Ù† Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø±Ø³ÛŒØ¯Ù‡ Ø¨Ø§Ø´Ø¯\r\n        \"\"\"\r\n        if self.state['last_update'] is None:\r\n            return True\r\n        \r\n        last_update = datetime.fromisoformat(self.state['last_update'])\r\n        update_frequency = self.config['learning']['update_frequency']\r\n        \r\n        if update_frequency == 'daily':\r\n            return datetime.now() - last_update > timedelta(days=1)\r\n        elif update_frequency == 'weekly':\r\n            return datetime.now() - last_update > timedelta(weeks=1)\r\n        elif update_frequency == 'monthly':\r\n            return datetime.now() - last_update > timedelta(days=30)\r\n        \r\n        return False\r\n    \r\n    def collect_content(self, collector: UniversityResourceCollector) -> Dict:\r\n        \"\"\"\r\n        Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…Ø­ØªÙˆØ§ Ø§Ø² Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\r\n        \r\n        Args:\r\n            collector: Ø´ÛŒØ¡ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒâ€ŒÚ©Ù†Ù†Ø¯Ù‡\r\n        \r\n        Returns:\r\n            Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒâ€ŒØ´Ø¯Ù‡\r\n        \"\"\"\r\n        logger.info(f\"\\n{'='*80}\")\r\n        logger.info(f\"Agent: {self.university_info['name']}\")\r\n        logger.info(f\"{'='*80}\")\r\n        \r\n        try:\r\n            max_pages = self.config['learning']['max_documents_per_session']\r\n            data = collector.collect_from_university(self.university_key, max_pages)\r\n            \r\n            self.state['last_successful_scrape'] = datetime.now().isoformat()\r\n            self.state['total_pages_scraped'] += data.get('total_pages', 0)\r\n            \r\n            return data\r\n            \r\n        except Exception as e:\r\n            error_msg = f\"Error collecting content: {str(e)}\"\r\n            logger.error(error_msg)\r\n            self.state['errors'].append({\r\n                'timestamp': datetime.now().isoformat(),\r\n                'error': error_msg\r\n            })\r\n            return {}\r\n    \r\n    def process_content(self, content: Dict) -> List[Dict]:\r\n        \"\"\"\r\n        Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØªÙˆØ§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒâ€ŒØ´Ø¯Ù‡\r\n        \r\n        Args:\r\n            content: Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù…\r\n        \r\n        Returns:\r\n            Ù„ÛŒØ³Øª Ø§Ø³Ù†Ø§Ø¯ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ RAG\r\n        \"\"\"\r\n        documents = []\r\n        \r\n        for resource_key, resource_data in content.get('resources', {}).items():\r\n            # ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ\r\n            main_page = resource_data.get('main_page')\r\n            if main_page:\r\n                doc = self._create_document(\r\n                    main_page,\r\n                    resource_key,\r\n                    resource_data['info']['description']\r\n                )\r\n                documents.append(doc)\r\n            \r\n            # ØµÙØ­Ø§Øª ÙØ±Ø¹ÛŒ\r\n            for sub_page in resource_data.get('sub_pages', []):\r\n                doc = self._create_document(\r\n                    sub_page,\r\n                    resource_key,\r\n                    f\"Sub-page from {resource_key}\"\r\n                )\r\n                documents.append(doc)\r\n        \r\n        return documents\r\n    \r\n    def _create_document(self, page_data: Dict, resource_key: str, description: str) -> Dict:\r\n        \"\"\"Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù†Ø¯ Ø¨Ø±Ø§ÛŒ RAG\"\"\"\r\n        return {\r\n            'content': page_data.get('text', ''),\r\n            'title': page_data.get('title', 'Untitled'),\r\n            'url': page_data.get('url', ''),\r\n            'metadata': {\r\n                'university': self.university_info['name'],\r\n                'university_key': self.university_key,\r\n                'resource': resource_key,\r\n                'description': description,\r\n                'focus_areas': self.university_info['focus_areas'],\r\n                'country': self.university_info['country'],\r\n                'scraped_at': datetime.now().isoformat()\r\n            }\r\n        }\r\n    \r\n    def update_rag_system(self, documents: List[Dict]) -> int:\r\n        \"\"\"\r\n        Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø³ÛŒØ³ØªÙ… RAG Ø¨Ø§ Ø§Ø³Ù†Ø§Ø¯ Ø¬Ø¯ÛŒØ¯ (Ø¨Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ)\r\n        \r\n        Args:\r\n            documents: Ù„ÛŒØ³Øª Ø§Ø³Ù†Ø§Ø¯\r\n        \r\n        Returns:\r\n            ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³Ù†Ø§Ø¯ Ø§Ø¶Ø§ÙÙ‡â€ŒØ´Ø¯Ù‡\r\n        \"\"\"\r\n        if not self.rag_system:\r\n            logger.warning(\"RAG system not available\")\r\n            return 0\r\n        \r\n        added = 0\r\n        violations = 0\r\n        \r\n        for doc in documents:\r\n            try:\r\n                # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ\r\n                is_valid, compliance, reason = self.security_system.validate_document(doc)\r\n                \r\n                if not is_valid:\r\n                    violations += 1\r\n                    logger.warning(f\"  âš ï¸  Document rejected: {reason}\")\r\n                    continue\r\n                \r\n                if compliance == ComplianceLevel.WARNING:\r\n                    logger.info(f\"  âš ï¸  Document accepted with warning: {reason}\")\r\n                \r\n                # Ø§Ø¶Ø§ÙÙ‡ Ø¨Ù‡ RAG\r\n                self.rag_system.add_document(\r\n                    doc['content'],\r\n                    doc['metadata']\r\n                )\r\n                added += 1\r\n                \r\n            except Exception as e:\r\n                logger.error(f\"Error adding document: {e}\")\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø± Ø§Ù…Ù†ÛŒØªÛŒ\r\n        self.state['security_violations'] += violations\r\n        self.state['compliance_score'] = self.security_system.get_agent_score(self.university_key)\r\n        \r\n        logger.info(f\"  Added {added} documents to RAG system\")\r\n        if violations > 0:\r\n            logger.warning(f\"  âš ï¸  {violations} documents rejected due to security\")\r\n        \r\n        return added\r\n    \r\n    def learn(self, collector: UniversityResourceCollector) -> Dict:\r\n        \"\"\"\r\n        ÙØ±Ø¢ÛŒÙ†Ø¯ Ú©Ø§Ù…Ù„ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ\r\n        \r\n        1. Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…Ø­ØªÙˆØ§\r\n        2. Ù¾Ø±Ø¯Ø§Ø²Ø´\r\n        3. Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ RAG\r\n        4. Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¶Ø¹ÛŒØª\r\n        \r\n        Returns:\r\n            Ø¢Ù…Ø§Ø± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ\r\n        \"\"\"\r\n        logger.info(f\"\\nðŸŽ“ Learning from: {self.university_info['name']}\")\r\n        \r\n        # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ\r\n        content = self.collect_content(collector)\r\n        if not content:\r\n            return {'status': 'failed', 'reason': 'No content collected'}\r\n        \r\n        # Ù¾Ø±Ø¯Ø§Ø²Ø´\r\n        documents = self.process_content(content)\r\n        logger.info(f\"  Processed {len(documents)} documents\")\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ RAG\r\n        added = self.update_rag_system(documents)\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª\r\n        self.state['last_update'] = datetime.now().isoformat()\r\n        self.state['total_documents'] += added\r\n        self.save_state()\r\n        \r\n        stats = {\r\n            'status': 'success',\r\n            'university': self.university_info['name'],\r\n            'pages_scraped': content.get('total_pages', 0),\r\n            'documents_processed': len(documents),\r\n            'documents_added_to_rag': added,\r\n            'timestamp': datetime.now().isoformat()\r\n        }\r\n        \r\n        logger.info(f\"  âœ“ Learning complete: {added} documents added\")\r\n        return stats\r\n    \r\n    def get_status(self) -> Dict:\r\n        \"\"\"ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ø§ÛŒØ¬Ù†Øª\"\"\"\r\n        return {\r\n            'university': self.university_info['name'],\r\n            'country': self.university_info['country'],\r\n            'focus_areas': self.university_info['focus_areas'],\r\n            'state': self.state,\r\n            'should_update': self.should_update()\r\n        }\r\n\r\n\r\nclass UniversityAgentManager:\r\n    \"\"\"\r\n    Ù…Ø¯ÛŒØ±ÛŒØª ØªÙ…Ø§Ù… Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ÛŒ\r\n    \"\"\"\r\n    \r\n    def __init__(\r\n        self,\r\n        universities: Dict,\r\n        config: Dict,\r\n        rag_system: Optional[RAGSystem] = None,\r\n        security_system: Optional[AgentSecuritySystem] = None\r\n    ):\r\n        self.universities = universities\r\n        self.config = config\r\n        self.rag_system = rag_system\r\n        self.security_system = security_system or AgentSecuritySystem()\r\n        self.specialization_manager = SpecializationManager()\r\n        \r\n        # Ø§ÛŒØ¬Ø§Ø¯ Ø§ÛŒØ¬Ù†Øª Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\r\n        self.agents = {}\r\n        for key, info in universities.items():\r\n            self.agents[key] = UniversityAgent(\r\n                key, info, config, rag_system, self.security_system\r\n            )\r\n        \r\n        logger.info(f\"âœ“ Initialized {len(self.agents)} university agents with security\")\r\n    \r\n    def learn_from_all(self) -> Dict:\r\n        \"\"\"\r\n        ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø² Ù‡Ù…Ù‡ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§\r\n        \r\n        Returns:\r\n            Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ\r\n        \"\"\"\r\n        collector = UniversityResourceCollector(self.universities, self.config)\r\n        \r\n        results = []\r\n        for agent_key, agent in self.agents.items():\r\n            if agent.should_update():\r\n                result = agent.learn(collector)\r\n                results.append(result)\r\n            else:\r\n                logger.info(f\"  Skipping {agent.university_info['name']} (not due for update)\")\r\n        \r\n        # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ\r\n        stats = {\r\n            'total_agents': len(self.agents),\r\n            'agents_updated': len(results),\r\n            'total_pages_scraped': sum(r.get('pages_scraped', 0) for r in results),\r\n            'total_documents_added': sum(r.get('documents_added_to_rag', 0) for r in results),\r\n            'results': results\r\n        }\r\n        \r\n        logger.info(f\"\\n{'='*80}\")\r\n        logger.info(f\"Learning Summary:\")\r\n        logger.info(f\"  Agents updated: {stats['agents_updated']}/{stats['total_agents']}\")\r\n        logger.info(f\"  Pages scraped: {stats['total_pages_scraped']}\")\r\n        logger.info(f\"  Documents added to RAG: {stats['total_documents_added']}\")\r\n        logger.info(f\"{'='*80}\\n\")\r\n        \r\n        return stats\r\n    \r\n    def learn_from_specific(self, university_keys: List[str]) -> Dict:\r\n        \"\"\"\r\n        ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø² Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ\r\n        \r\n        Args:\r\n            university_keys: Ù„ÛŒØ³Øª Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\r\n        \r\n        Returns:\r\n            Ø¢Ù…Ø§Ø± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ\r\n        \"\"\"\r\n        collector = UniversityResourceCollector(self.universities, self.config)\r\n        \r\n        results = []\r\n        for key in university_keys:\r\n            if key in self.agents:\r\n                result = self.agents[key].learn(collector)\r\n                results.append(result)\r\n        \r\n        return {\r\n            'agents_updated': len(results),\r\n            'results': results\r\n        }\r\n    \r\n    def get_all_statuses(self) -> List[Dict]:\r\n        \"\"\"ÙˆØ¶Ø¹ÛŒØª Ù‡Ù…Ù‡ Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§\"\"\"\r\n        return [agent.get_status() for agent in self.agents.values()]\r\n    \r\n    def get_statistics(self) -> Dict:\r\n        \"\"\"Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ Ø³ÛŒØ³ØªÙ…\"\"\"\r\n        statuses = self.get_all_statuses()\r\n        \r\n        return {\r\n            'total_agents': len(self.agents),\r\n            'agents_needing_update': sum(1 for s in statuses if s['should_update']),\r\n            'total_documents_collected': sum(s['state']['total_documents'] for s in statuses),\r\n            'total_pages_scraped': sum(s['state']['total_pages_scraped'] for s in statuses),\r\n            'by_university': {\r\n                s['university']: {\r\n                    'country': s['country'],\r\n                    'focus_areas': s['focus_areas'],\r\n                    'documents': s['state']['total_documents'],\r\n                    'pages': s['state']['total_pages_scraped'],\r\n                    'last_update': s['state']['last_update']\r\n                }\r\n                for s in statuses\r\n            }\r\n        }\r\n",
    "format": "py"
  },
  {
    "timestamp": "2025-11-21T23:24:53.008Z",
    "fileName": "cad3d\\super_ai\\university_agents.py",
    "content": "\"\"\"\r\nUniversity Learning Agents - Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ÛŒ\r\n\r\nØ§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ Ø¨Ø±Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø¯Ø§ÙˆÙ… Ø§Ø² Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø±ØªØ±\r\n\"\"\"\r\n\r\nimport logging\r\nfrom typing import Dict, List, Optional\r\nfrom datetime import datetime, timedelta\r\nimport json\r\nfrom pathlib import Path\r\n\r\nfrom .university_scraper import UniversityResourceCollector\r\nfrom .rag_system import RAGSystem\r\nfrom .agent_security import AgentSecuritySystem, SpecializationManager, ComplianceLevel\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\nclass UniversityAgent:\r\n    \"\"\"\r\n    Ø§ÛŒØ¬Ù†Øª ØªØ®ØµØµÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\r\n    \r\n    Ù…Ø³Ø¦ÙˆÙ„ÛŒØªâ€ŒÙ‡Ø§:\r\n    - Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ Ù…Ø­ØªÙˆØ§\r\n    - Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª\r\n    - Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ RAG\r\n    - Ø±Ø¯ÛŒØ§Ø¨ÛŒ ØªØºÛŒÛŒØ±Ø§Øª Ùˆ Ù…Ø­ØªÙˆØ§ÛŒ Ø¬Ø¯ÛŒØ¯\r\n    \"\"\"\r\n    \r\n    def __init__(\r\n        self,\r\n        university_key: str,\r\n        university_info: Dict,\r\n        config: Dict,\r\n        rag_system: Optional[RAGSystem] = None,\r\n        security_system: Optional[AgentSecuritySystem] = None\r\n    ):\r\n        self.university_key = university_key\r\n        self.university_info = university_info\r\n        self.config = config\r\n        self.rag_system = rag_system\r\n        self.security_system = security_system or AgentSecuritySystem()\r\n        \r\n        self.state = {\r\n            'last_update': None,\r\n            'total_documents': 0,\r\n            'total_pages_scraped': 0,\r\n            'last_successful_scrape': None,\r\n            'errors': [],\r\n            'security_violations': 0,\r\n            'compliance_score': 100.0\r\n        }\r\n        \r\n        # State file\r\n        self.state_file = Path(config['storage']['cache_dir']) / f\"{university_key}_state.json\"\r\n        self.load_state()\r\n    \r\n    def load_state(self):\r\n        \"\"\"Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø§Ø² ÙØ§ÛŒÙ„\"\"\"\r\n        if self.state_file.exists():\r\n            with open(self.state_file, 'r', encoding='utf-8') as f:\r\n                self.state = json.load(f)\r\n    \r\n    def save_state(self):\r\n        \"\"\"Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø¯Ø± ÙØ§ÛŒÙ„\"\"\"\r\n        with open(self.state_file, 'w', encoding='utf-8') as f:\r\n            json.dump(self.state, f, ensure_ascii=False, indent=2)\r\n    \r\n    def should_update(self) -> bool:\r\n        \"\"\"\r\n        Ø¨Ø±Ø±Ø³ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ\r\n        \r\n        Returns:\r\n            True Ø§Ú¯Ø± Ø²Ù…Ø§Ù† Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø±Ø³ÛŒØ¯Ù‡ Ø¨Ø§Ø´Ø¯\r\n        \"\"\"\r\n        if self.state['last_update'] is None:\r\n            return True\r\n        \r\n        last_update = datetime.fromisoformat(self.state['last_update'])\r\n        update_frequency = self.config['learning']['update_frequency']\r\n        \r\n        if update_frequency == 'daily':\r\n            return datetime.now() - last_update > timedelta(days=1)\r\n        elif update_frequency == 'weekly':\r\n            return datetime.now() - last_update > timedelta(weeks=1)\r\n        elif update_frequency == 'monthly':\r\n            return datetime.now() - last_update > timedelta(days=30)\r\n        \r\n        return False\r\n    \r\n    def collect_content(self, collector: UniversityResourceCollector) -> Dict:\r\n        \"\"\"\r\n        Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…Ø­ØªÙˆØ§ Ø§Ø² Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\r\n        \r\n        Args:\r\n            collector: Ø´ÛŒØ¡ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒâ€ŒÚ©Ù†Ù†Ø¯Ù‡\r\n        \r\n        Returns:\r\n            Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒâ€ŒØ´Ø¯Ù‡\r\n        \"\"\"\r\n        logger.info(f\"\\n{'='*80}\")\r\n        logger.info(f\"Agent: {self.university_info['name']}\")\r\n        logger.info(f\"{'='*80}\")\r\n        \r\n        try:\r\n            max_pages = self.config['learning']['max_documents_per_session']\r\n            data = collector.collect_from_university(self.university_key, max_pages)\r\n            \r\n            self.state['last_successful_scrape'] = datetime.now().isoformat()\r\n            self.state['total_pages_scraped'] += data.get('total_pages', 0)\r\n            \r\n            return data\r\n            \r\n        except Exception as e:\r\n            error_msg = f\"Error collecting content: {str(e)}\"\r\n            logger.error(error_msg)\r\n            self.state['errors'].append({\r\n                'timestamp': datetime.now().isoformat(),\r\n                'error': error_msg\r\n            })\r\n            return {}\r\n    \r\n    def process_content(self, content: Dict) -> List[Dict]:\r\n        \"\"\"\r\n        Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØªÙˆØ§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒâ€ŒØ´Ø¯Ù‡\r\n        \r\n        Args:\r\n            content: Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù…\r\n        \r\n        Returns:\r\n            Ù„ÛŒØ³Øª Ø§Ø³Ù†Ø§Ø¯ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ RAG\r\n        \"\"\"\r\n        documents = []\r\n        \r\n        for resource_key, resource_data in content.get('resources', {}).items():\r\n            # ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ\r\n            main_page = resource_data.get('main_page')\r\n            if main_page:\r\n                doc = self._create_document(\r\n                    main_page,\r\n                    resource_key,\r\n                    resource_data['info']['description']\r\n                )\r\n                documents.append(doc)\r\n            \r\n            # ØµÙØ­Ø§Øª ÙØ±Ø¹ÛŒ\r\n            for sub_page in resource_data.get('sub_pages', []):\r\n                doc = self._create_document(\r\n                    sub_page,\r\n                    resource_key,\r\n                    f\"Sub-page from {resource_key}\"\r\n                )\r\n                documents.append(doc)\r\n        \r\n        return documents\r\n    \r\n    def _create_document(self, page_data: Dict, resource_key: str, description: str) -> Dict:\r\n        \"\"\"Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù†Ø¯ Ø¨Ø±Ø§ÛŒ RAG\"\"\"\r\n        return {\r\n            'content': page_data.get('text', ''),\r\n            'title': page_data.get('title', 'Untitled'),\r\n            'url': page_data.get('url', ''),\r\n            'metadata': {\r\n                'university': self.university_info['name'],\r\n                'university_key': self.university_key,\r\n                'resource': resource_key,\r\n                'description': description,\r\n                'focus_areas': self.university_info['focus_areas'],\r\n                'country': self.university_info['country'],\r\n                'scraped_at': datetime.now().isoformat()\r\n            }\r\n        }\r\n    \r\n    def update_rag_system(self, documents: List[Dict]) -> int:\r\n        \"\"\"\r\n        Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø³ÛŒØ³ØªÙ… RAG Ø¨Ø§ Ø§Ø³Ù†Ø§Ø¯ Ø¬Ø¯ÛŒØ¯ (Ø¨Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ)\r\n        \r\n        Args:\r\n            documents: Ù„ÛŒØ³Øª Ø§Ø³Ù†Ø§Ø¯\r\n        \r\n        Returns:\r\n            ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³Ù†Ø§Ø¯ Ø§Ø¶Ø§ÙÙ‡â€ŒØ´Ø¯Ù‡\r\n        \"\"\"\r\n        if not self.rag_system:\r\n            logger.warning(\"RAG system not available\")\r\n            return 0\r\n        \r\n        added = 0\r\n        violations = 0\r\n        \r\n        for doc in documents:\r\n            try:\r\n                # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ\r\n                is_valid, compliance, reason = self.security_system.validate_document(doc)\r\n                \r\n                if not is_valid:\r\n                    violations += 1\r\n                    logger.warning(f\"  âš ï¸  Document rejected: {reason}\")\r\n                    continue\r\n                \r\n                if compliance == ComplianceLevel.WARNING:\r\n                    logger.info(f\"  âš ï¸  Document accepted with warning: {reason}\")\r\n                \r\n                # Ø§Ø¶Ø§ÙÙ‡ Ø¨Ù‡ RAG\r\n                self.rag_system.add_document(\r\n                    doc['content'],\r\n                    doc['metadata']\r\n                )\r\n                added += 1\r\n                \r\n            except Exception as e:\r\n                logger.error(f\"Error adding document: {e}\")\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø± Ø§Ù…Ù†ÛŒØªÛŒ\r\n        self.state['security_violations'] += violations\r\n        self.state['compliance_score'] = self.security_system.get_agent_score(self.university_key)\r\n        \r\n        logger.info(f\"  Added {added} documents to RAG system\")\r\n        if violations > 0:\r\n            logger.warning(f\"  âš ï¸  {violations} documents rejected due to security\")\r\n        \r\n        return added\r\n    \r\n    def learn(self, collector: UniversityResourceCollector) -> Dict:\r\n        \"\"\"\r\n        ÙØ±Ø¢ÛŒÙ†Ø¯ Ú©Ø§Ù…Ù„ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ\r\n        \r\n        1. Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…Ø­ØªÙˆØ§\r\n        2. Ù¾Ø±Ø¯Ø§Ø²Ø´\r\n        3. Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ RAG\r\n        4. Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¶Ø¹ÛŒØª\r\n        \r\n        Returns:\r\n            Ø¢Ù…Ø§Ø± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ\r\n        \"\"\"\r\n        logger.info(f\"\\nðŸŽ“ Learning from: {self.university_info['name']}\")\r\n        \r\n        # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ\r\n        content = self.collect_content(collector)\r\n        if not content:\r\n            return {'status': 'failed', 'reason': 'No content collected'}\r\n        \r\n        # Ù¾Ø±Ø¯Ø§Ø²Ø´\r\n        documents = self.process_content(content)\r\n        logger.info(f\"  Processed {len(documents)} documents\")\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ RAG\r\n        added = self.update_rag_system(documents)\r\n        \r\n        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª\r\n        self.state['last_update'] = datetime.now().isoformat()\r\n        self.state['total_documents'] += added\r\n        self.save_state()\r\n        \r\n        stats = {\r\n            'status': 'success',\r\n            'university': self.university_info['name'],\r\n            'pages_scraped': content.get('total_pages', 0),\r\n            'documents_processed': len(documents),\r\n            'documents_added_to_rag': added,\r\n            'timestamp': datetime.now().isoformat()\r\n        }\r\n        \r\n        logger.info(f\"  âœ“ Learning complete: {added} documents added\")\r\n        return stats\r\n    \r\n    def get_status(self) -> Dict:\r\n        \"\"\"ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ø§ÛŒØ¬Ù†Øª\"\"\"\r\n        return {\r\n            'university': self.university_info['name'],\r\n            'country': self.university_info['country'],\r\n            'focus_areas': self.university_info['focus_areas'],\r\n            'state': self.state,\r\n            'should_update': self.should_update()\r\n        }\r\n\r\n\r\nclass UniversityAgentManager:\r\n    \"\"\"\r\n    Ù…Ø¯ÛŒØ±ÛŒØª ØªÙ…Ø§Ù… Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ÛŒ\r\n    \"\"\"\r\n    \r\n    def __init__(\r\n        self,\r\n        universities: Dict,\r\n        config: Dict,\r\n        rag_system: Optional[RAGSystem] = None,\r\n        security_system: Optional[AgentSecuritySystem] = None\r\n    ):\r\n        self.universities = universities\r\n        self.config = config\r\n        self.rag_system = rag_system\r\n        self.security_system = security_system or AgentSecuritySystem()\r\n        self.specialization_manager = SpecializationManager()\r\n        \r\n        # Ø§ÛŒØ¬Ø§Ø¯ Ø§ÛŒØ¬Ù†Øª Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\r\n        self.agents = {}\r\n        for key, info in universities.items():\r\n            self.agents[key] = UniversityAgent(\r\n                key, info, config, rag_system, self.security_system\r\n            )\r\n        \r\n        logger.info(f\"âœ“ Initialized {len(self.agents)} university agents with security\")\r\n    \r\n    def learn_from_all(self) -> Dict:\r\n        \"\"\"\r\n        ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø² Ù‡Ù…Ù‡ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§\r\n        \r\n        Returns:\r\n            Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ\r\n        \"\"\"\r\n        collector = UniversityResourceCollector(self.universities, self.config)\r\n        \r\n        results = []\r\n        for agent_key, agent in self.agents.items():\r\n            if agent.should_update():\r\n                result = agent.learn(collector)\r\n                results.append(result)\r\n            else:\r\n                logger.info(f\"  Skipping {agent.university_info['name']} (not due for update)\")\r\n        \r\n        # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ\r\n        stats = {\r\n            'total_agents': len(self.agents),\r\n            'agents_updated': len(results),\r\n            'total_pages_scraped': sum(r.get('pages_scraped', 0) for r in results),\r\n            'total_documents_added': sum(r.get('documents_added_to_rag', 0) for r in results),\r\n            'results': results\r\n        }\r\n        \r\n        logger.info(f\"\\n{'='*80}\")\r\n        logger.info(f\"Learning Summary:\")\r\n        logger.info(f\"  Agents updated: {stats['agents_updated']}/{stats['total_agents']}\")\r\n        logger.info(f\"  Pages scraped: {stats['total_pages_scraped']}\")\r\n        logger.info(f\"  Documents added to RAG: {stats['total_documents_added']}\")\r\n        logger.info(f\"{'='*80}\\n\")\r\n        \r\n        return stats\r\n    \r\n    def learn_from_specific(self, university_keys: List[str]) -> Dict:\r\n        \"\"\"\r\n        ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø² Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ\r\n        \r\n        Args:\r\n            university_keys: Ù„ÛŒØ³Øª Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡\r\n        \r\n        Returns:\r\n            Ø¢Ù…Ø§Ø± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ\r\n        \"\"\"\r\n        collector = UniversityResourceCollector(self.universities, self.config)\r\n        \r\n        results = []\r\n        for key in university_keys:\r\n            if key in self.agents:\r\n                result = self.agents[key].learn(collector)\r\n                results.append(result)\r\n        \r\n        return {\r\n            'agents_updated': len(results),\r\n            'results': results\r\n        }\r\n    \r\n    def get_all_statuses(self) -> List[Dict]:\r\n        \"\"\"ÙˆØ¶Ø¹ÛŒØª Ù‡Ù…Ù‡ Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§\"\"\"\r\n        return [agent.get_status() for agent in self.agents.values()]\r\n    \r\n    def get_statistics(self) -> Dict:\r\n        \"\"\"Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ Ø³ÛŒØ³ØªÙ…\"\"\"\r\n        statuses = self.get_all_statuses()\r\n        \r\n        return {\r\n            'total_agents': len(self.agents),\r\n            'agents_needing_update': sum(1 for s in statuses if s['should_update']),\r\n            'total_documents_collected': sum(s['state']['total_documents'] for s in statuses),\r\n            'total_pages_scraped': sum(s['state']['total_pages_scraped'] for s in statuses),\r\n            'by_university': {\r\n                s['university']: {\r\n                    'country': s['country'],\r\n                    'focus_areas': s['focus_areas'],\r\n                    'documents': s['state']['total_documents'],\r\n                    'pages': s['state']['total_pages_scraped'],\r\n                    'last_update': s['state']['last_update']\r\n                }\r\n                for s in statuses\r\n            }\r\n        }\r\n",
    "format": "py"
  }
]