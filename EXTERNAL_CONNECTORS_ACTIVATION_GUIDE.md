# KURDO-AI External Connectors - Complete Activation Guide

# Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„ ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø§ØªØµØ§Ù„Ø§Øª Ø®Ø§Ø±Ø¬ÛŒ KURDO-AI

---

## ğŸŒ Overview / Ù†Ù…Ø§ÛŒ Ú©Ù„ÛŒ

KURDO-AI now supports permanent connection to **15+ major AI platforms and services** for continuous learning and real-world operation. This guide covers complete activation.

KURDO-AI Ø§Ú©Ù†ÙˆÙ† Ø§Ø² Ø§ØªØµØ§Ù„ Ø¯Ø§Ø¦Ù…ÛŒ Ø¨Ù‡ **Ø¨ÛŒØ´ Ø§Ø² Û±Ûµ Ù¾Ù„ØªÙØ±Ù… Ùˆ Ø³Ø±ÙˆÛŒØ³ Ø§ØµÙ„ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ** Ø¨Ø±Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø³ØªÙ…Ø± Ùˆ Ø¹Ù…Ù„ÛŒØ§Øª ÙˆØ§Ù‚Ø¹ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

---

## ğŸ“‹ Supported Services / Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒâ€ŒØ´Ø¯Ù‡

### Translation Services / Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ ØªØ±Ø¬Ù…Ù‡

1. **Google Translate** - Google Cloud Translation API
2. **Microsoft Translator** - Azure Cognitive Services
3. **DeepL** - High-quality translation (highest priority)
4. **Amazon Translate** - AWS translation service
5. **LibreTranslate** - Free/self-hosted option
6. **Argos Translate** - Offline translation (no API key needed)

### Chat & LLM Services / Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ú¯ÙØªÚ¯Ùˆ Ùˆ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ

1. **OpenAI** - GPT-4o, GPT-4, GPT-3.5
2. **Anthropic** - Claude-3 (Opus, Sonnet, Haiku)
3. **Google AI Studio** - Gemini Pro, Gemini Ultra
4. **Grok** - X AI's language model
5. **DeepSeek** - DeepSeek-V2
6. **HuggingFace** - Access to 100,000+ models via Inference API

### Search Services / Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ

1. **Google Custom Search** - For online research and context enrichment

### Local Models (Offline) / Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ù„ÛŒ (Ø¢ÙÙ„Ø§ÛŒÙ†)

1. **Flan-T5** - Google's instruction-tuned T5
2. **mT5** - Multilingual T5
3. **BERT** - Text understanding and classification
4. **Gemma** - Google's open model
5. **Argos Translate** - Offline translation

---

## ğŸ”§ Installation / Ù†ØµØ¨

### Step 1: Install Required Packages / Ù…Ø±Ø­Ù„Ù‡ Û±: Ù†ØµØ¨ Ø¨Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²

```bash
# Basic requirements (already installed)
pip install requests beautifulsoup4 python-dotenv

# Optional: For local models
pip install transformers torch sentencepiece argostranslate
```

### Step 2: Configure API Keys / Ù…Ø±Ø­Ù„Ù‡ Û²: ØªÙ†Ø¸ÛŒÙ… Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ API

1. Copy `.env.example` to `.env`:

   ```bash
   cp .env.example .env
   ```

2. Open `.env` and add your API keys (see below for how to obtain them)

---

## ğŸ”‘ Obtaining API Keys / Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ API

### Google Services

#### Google Translate API

1. Go to [Google Cloud Console](https://console.cloud.google.com/)
2. Create a new project or select existing
3. Enable "Cloud Translation API"
4. Create credentials â†’ API Key
5. Copy to `.env` as `GOOGLE_TRANSLATE_API_KEY`

#### Google AI Studio (Gemini)

1. Visit [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Click "Create API Key"
3. Copy to `.env` as `GOOGLE_AI_STUDIO_KEY`

#### Google Custom Search (for research)

1. Get API key from [Google Cloud Console](https://console.cloud.google.com/)
2. Enable "Custom Search API"
3. Create Search Engine at [Programmable Search](https://programmablesearchengine.google.com/)
4. Copy Search Engine ID as `GOOGLE_SEARCH_CX`
5. Copy API key as `GOOGLE_SEARCH_API_KEY`

### Microsoft Azure

#### Azure Translator

1. Go to [Azure Portal](https://portal.azure.com/)
2. Create "Translator" resource
3. Copy Key 1 to `.env` as `AZURE_TRANSLATOR_KEY`
4. Copy Region (e.g., "westus2") as `AZURE_TRANSLATOR_REGION`

### OpenAI

1. Visit [OpenAI Platform](https://platform.openai.com/api-keys)
2. Create new API key
3. Copy to `.env` as `OPENAI_API_KEY`

### Anthropic (Claude)

1. Visit [Anthropic Console](https://console.anthropic.com/)
2. Create API key
3. Copy to `.env` as `ANTHROPIC_API_KEY`

### Grok (X AI)

1. Visit [X AI Console](https://console.x.ai/)
2. Generate API key
3. Copy to `.env` as `GROK_API_KEY`

### DeepSeek

1. Visit [DeepSeek Platform](https://platform.deepseek.com/)
2. Create API key
3. Copy to `.env` as `DEEPSEEK_API_KEY`

### DeepL

1. Visit [DeepL API](https://www.deepl.com/pro-api)
2. Sign up for Free or Pro plan
3. Copy Authentication Key to `.env` as `DEEPL_API_KEY`

### Amazon Translate

1. Go to [AWS Console](https://console.aws.amazon.com/)
2. Create IAM user with "TranslateFullAccess" policy
3. Generate access keys
4. Copy to `.env` as `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`

### LibreTranslate (Free)

1. Use public instance: `https://libretranslate.com/translate` (no key needed)
2. Or self-host: [LibreTranslate GitHub](https://github.com/LibreTranslate/LibreTranslate)
3. Optional: Get API key from [LibreTranslate](https://libretranslate.com/)

### HuggingFace

1. Visit [HuggingFace Settings](https://huggingface.co/settings/tokens)
2. Create new token (read access)
3. Copy to `.env` as `HUGGINGFACE_API_KEY`

---

## âš™ï¸ Configuration / Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ

### Enabling Services / ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§

Edit `cad3d/super_ai/connectors_config.json`:

```json
{
  "google_translate": {
    "enabled": true,  // Set to true to enable
    "api_key_env": "GOOGLE_TRANSLATE_API_KEY"
  },
  "openai": {
    "enabled": true,
    "api_key_env": "OPENAI_API_KEY",
    "model": "gpt-4o"
  }
  // ... etc
}
```

**Important:** Only enable services you have valid API keys for!

---

## ğŸš€ Usage / Ø§Ø³ØªÙØ§Ø¯Ù‡

### Automatic Cascading Fallback / Ø³Ù‚ÙˆØ· Ø®ÙˆØ¯Ú©Ø§Ø± Ù¾Ù„Ú©Ø§Ù†ÛŒ

The system automatically tries providers in priority order:

#### Translation Priority

1. **DeepL** (highest quality)
2. Microsoft Translator
3. Google Translate
4. LibreTranslate (free)
5. Argos Translate (offline)

#### Chat/LLM Priority

1. **Anthropic Claude** (highest quality)
2. OpenAI GPT-4o
3. Google Gemini
4. DeepSeek
5. Grok
6. HuggingFace API
7. Local models (offline)

### Example Code / Ú©Ø¯ Ù†Ù…ÙˆÙ†Ù‡

```python
from cad3d.super_ai.external_connectors import unified_connector

# Translation with automatic fallback
result = unified_connector.translate("Hello world", "fa")
print(result)  # "Ø³Ù„Ø§Ù… Ø¯Ù†ÛŒØ§"

# Chat with automatic fallback
response = unified_connector.chat_with_fallback(
    prompt="Explain feasibility analysis",
    system_prompt="You are an architectural AI expert."
)
print(response['content'][0]['text'])

# Online research
search_results = unified_connector.search("modern architecture trends", num_results=5)
```

### Using in KURDO-AI Brain / Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ù…ØºØ² KURDO-AI

The brain automatically uses external connectors when processing requests:

```python
from cad3d.super_ai.brain import SuperAIBrain

brain = SuperAIBrain()

# Process in Persian - automatically translates using external APIs
result = brain.process_request("Ø§Ù…Ú©Ø§Ù†â€ŒØ³Ù†Ø¬ÛŒ ÛŒÚ© Ø¨Ø±Ø¬ Û²Û° Ø·Ø¨Ù‚Ù‡ Ø¯Ø± Ø²Ù…ÛŒÙ† Û±Û°Û°Û° Ù…ØªØ±ÛŒ")

# Brain will:
# 1. Detect Persian language
# 2. Translate to English using cascading fallback
# 3. Perform online research if enabled
# 4. Generate AI-enhanced response
# 5. Translate back to Persian
```

---

## ğŸ“Š Testing Services / ØªØ³Øª Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§

Create a test script `test_connectors.py`:

```python
from cad3d.super_ai.external_connectors import unified_connector

# Test translation
print("Testing Translation...")
result = unified_connector.translate("Hello", "fa")
print(f"Result: {result}")

# Test chat
print("\nTesting Chat...")
response = unified_connector.chat_with_fallback(
    prompt="Hello, who are you?",
    system_prompt="You are KURDO-AI."
)
print(f"Response: {response.get('content', [{}])[0].get('text', 'N/A')}")

# Test search
if unified_connector.is_enabled("google_search"):
    print("\nTesting Search...")
    results = unified_connector.search("AI architecture", num_results=3)
    print(f"Found {len(results.get('items', []))} results")
```

Run:

```bash
python test_connectors.py
```

---

## ğŸ” Monitoring & Debugging / Ù†Ø¸Ø§Ø±Øª Ùˆ Ø§Ø´Ú©Ø§Ù„â€ŒØ²Ø¯Ø§ÛŒÛŒ

### Check Service Status / Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§

```python
from cad3d.super_ai.external_connectors import unified_connector

# Check which services are enabled
for service in ["google_translate", "openai", "anthropic", "deepl"]:
    status = "âœ… Enabled" if unified_connector.is_enabled(service) else "âŒ Disabled"
    print(f"{service}: {status}")
```

### Enable Console Logging / ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù„Ø§Ú¯ Ú©Ù†Ø³ÙˆÙ„

The system automatically prints status messages:

```
[TRANSLATION] Attempting deepl...
[TRANSLATION] Success with deepl
```

```
[CHAT] Attempting anthropic...
[CHAT] Success with anthropic
```

---

## ğŸ’¡ Best Practices / Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´â€ŒÙ‡Ø§

### Cost Management / Ù…Ø¯ÛŒØ±ÛŒØª Ù‡Ø²ÛŒÙ†Ù‡

1. **Start with Free Tiers**: LibreTranslate (free), HuggingFace (generous limits)
2. **Use Local Models**: Install transformers for offline fallback
3. **Enable Strategic Services**: Only enable what you need
4. **Monitor Usage**: Check provider dashboards regularly

### Quality Optimization / Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©ÛŒÙÛŒØª

1. **DeepL for Translation**: Best quality, enable if available
2. **Claude for Critical Tasks**: Most accurate LLM
3. **Gemini for Speed**: Fast and cost-effective
4. **Local Models for Testing**: Free and private

### Security / Ø§Ù…Ù†ÛŒØª

1. **Never commit `.env`**: Already in `.gitignore`
2. **Rotate keys regularly**: Monthly recommended
3. **Use IAM roles in production**: For AWS services
4. **Restrict API key permissions**: Minimum required only

---

## ğŸ› Troubleshooting / Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ

### Issue: "Translation unavailable"

- Check `.env` file exists and has correct keys
- Verify service is enabled in `connectors_config.json`
- Test API key directly using provider's console

### Issue: "All chat providers failed"

- At least one chat provider must be enabled
- Check API key format (some require prefixes)
- Verify internet connection

### Issue: Local models fail to load

- Install transformers: `pip install transformers torch`
- First run downloads models (~500MB-2GB)
- Check disk space and internet connection

### Issue: Rate limiting errors

- Reduce request frequency
- Upgrade to paid tier
- Enable more fallback providers

---

## ğŸ“¦ Local Models Setup / Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ù„ÛŒ

### For Offline Translation (Argos)

```bash
pip install argostranslate
python -c "import argostranslate.package; argostranslate.package.update_package_index(); argostranslate.package.install_from_path('en_fa')"
```

### For Chat/LLM (Flan-T5)

```bash
pip install transformers torch

# First use will download ~800MB model
python -c "from transformers import AutoModelForSeq2SeqLM; AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-base')"
```

---

## ğŸ¯ Next Steps / Ù…Ø±Ø§Ø­Ù„ Ø¨Ø¹Ø¯ÛŒ

1. âœ… Install packages: `pip install requests beautifulsoup4 python-dotenv`
2. âœ… Create `.env` from `.env.example`
3. âœ… Add API keys for desired services
4. âœ… Enable services in `connectors_config.json`
5. âœ… Test with `test_connectors.py`
6. âœ… Run KURDO-AI with external intelligence!

---

## ğŸ“ Support / Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ

For issues or questions:

- Review this guide carefully
- Check provider documentation
- Test services individually
- Enable verbose logging for debugging

**KURDO-AI is now connected to the world's leading AI platforms! ğŸŒğŸ¤–**

---

*Last updated: 2024*
*Version: 2.0 (Multi-Provider Cascade)*
