# ğŸ“ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ØªØ´Ø®ÛŒØµ CAD

Ø§ÛŒÙ† Ø±Ø§Ù‡Ù†Ù…Ø§ Ù†Ø­ÙˆÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³ÛŒØ³ØªÙ… Ø¢Ù…ÙˆØ²Ø´ (Training System) Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®Øª Dataset Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´ÛŒ ØªØ´Ø®ÛŒØµ CAD Ø±Ø§ ØªÙˆØ¶ÛŒØ­ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.

## ğŸ“‹ ÙÙ‡Ø±Ø³Øª Ù…Ø·Ø§Ù„Ø¨

1. [Ù†ØµØ¨ Dependencies](#Ù†ØµØ¨-dependencies)
2. [Ø³Ø§Ø®Øª Dataset Ø§Ø² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ DXF](#Ø³Ø§Ø®Øª-dataset-Ø§Ø²-ÙØ§ÛŒÙ„Ù‡Ø§ÛŒ-dxf)
3. [Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„](#Ø¢Ù…ÙˆØ²Ø´-Ù…Ø¯Ù„)
4. [Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡](#Ø§Ø³ØªÙØ§Ø¯Ù‡-Ø§Ø²-Ù…Ø¯Ù„-Ø¢Ù…ÙˆØ²Ø´Ø¯ÛŒØ¯Ù‡)
5. [Ù†Ú©Ø§Øª Ùˆ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§](#Ù†Ú©Ø§Øª-Ùˆ-ØªÙˆØµÛŒÙ‡Ù‡Ø§)

---

## Ù†ØµØ¨ Dependencies

```bash
# Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Neural Network
pip install -r requirements-neural.txt

# Ù†ØµØ¨ PyTorch (Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´)
# CPU version:
pip install torch torchvision torchaudio

# GPU version (CUDA 11.8):
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

---

## Ø³Ø§Ø®Øª Dataset Ø§Ø² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ DXF

### Ø±ÙˆØ´ Ø§ÙˆÙ„: CLI

```bash
# Ø³Ø§Ø®Øª Dataset Ø¨Ø§ ÙØ±Ù…Øª COCO
python -m cad3d.cli build-dataset \
  --input-dir ./my_dxf_files \
  --output-dir ./training_dataset \
  --format coco \
  --visualize

# Ø³Ø§Ø®Øª Ø¨Ø§ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø²ÛŒØ±Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ Ùˆ ÙØ±Ù…Øª YOLO
python -m cad3d.cli build-dataset \
  --input-dir ./my_dxf_files \
  --output-dir ./training_dataset \
  --format yolo \
  --recurse \
  --visualize

# Ø³Ø§Ø®Øª Ø¨Ø§ Ù‡Ø± Ø¯Ùˆ ÙØ±Ù…Øª COCO Ùˆ YOLO
python -m cad3d.cli build-dataset \
  --input-dir ./my_dxf_files \
  --output-dir ./training_dataset \
  --format both \
  --image-size 1024 1024 \
  --recurse \
  --visualize
```

**Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:**

- `--input-dir`: Ù¾ÙˆØ´Ù‡ Ø­Ø§ÙˆÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ DXF
- `--output-dir`: Ù¾ÙˆØ´Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø±Ø§ÛŒ Dataset
- `--format`: ÙØ±Ù…Øª Ø®Ø±ÙˆØ¬ÛŒ (`coco`, `yolo`, `both`)
- `--image-size WIDTH HEIGHT`: Ø§Ù†Ø¯Ø§Ø²Ù‡ ØªØµØ§ÙˆÛŒØ± (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 1024 1024)
- `--recurse`: Ø¬Ø³ØªØ¬ÙˆÛŒ Ø²ÛŒØ±Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§
- `--visualize`: Ø°Ø®ÛŒØ±Ù‡ ØªØµØ§ÙˆÛŒØ± Ø¨Ø±Ø±Ø³ÛŒ annotation

### Ø±ÙˆØ´ Ø¯ÙˆÙ…: Python API

```python
from cad3d.training_dataset_builder import CADDatasetBuilder

# Ø³Ø§Ø®Øª builder
builder = CADDatasetBuilder(output_dir="./training_dataset")

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ DXF
builder.add_dxf_to_dataset("floor_plan_1.dxf", image_size=(1024, 1024))
builder.add_dxf_to_dataset("floor_plan_2.dxf", image_size=(1024, 1024))
builder.add_dxf_to_dataset("floor_plan_3.dxf", image_size=(1024, 1024))

# Export Ø¨Ù‡ ÙØ±Ù…Øª COCO
builder.export_coco_format()

# Export Ø¨Ù‡ ÙØ±Ù…Øª YOLO
builder.export_yolo_format()

# ØªÙˆÙ„ÛŒØ¯ ØªØµØ§ÙˆÛŒØ± Ø¨Ø±Ø±Ø³ÛŒ annotation
builder.visualize_annotations()

print(f"âœ… Dataset Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª!")
print(f"   ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ±: {len(builder.images)}")
print(f"   ØªØ¹Ø¯Ø§Ø¯ annotation: {len(builder.annotations)}")
```

### Ø³Ø§Ø®ØªØ§Ø± Dataset (COCO Format)

```
training_dataset/
â”œâ”€â”€ images/                 # ØªØµØ§ÙˆÛŒØ± PNG ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø§Ø² DXF
â”‚   â”œâ”€â”€ floor_plan_1.png
â”‚   â”œâ”€â”€ floor_plan_2.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ annotations.json        # ÙØ±Ù…Øª COCO
â”œâ”€â”€ labels/                 # ÙØ±Ù…Øª YOLO (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
â”‚   â”œâ”€â”€ floor_plan_1.txt
â”‚   â”œâ”€â”€ floor_plan_2.txt
â”‚   â””â”€â”€ ...
â””â”€â”€ visualizations/         # ØªØµØ§ÙˆÛŒØ± Ø¨Ø±Ø±Ø³ÛŒ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
    â”œâ”€â”€ floor_plan_1_annotated.png
    â””â”€â”€ ...
```

---

## Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„

### Ø±ÙˆØ´ Ø§ÙˆÙ„: CLI

```bash
# Ø¢Ù…ÙˆØ²Ø´ Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶
python -m cad3d.cli train \
  --dataset-dir ./training_dataset \
  --output-dir ./models \
  --epochs 50 \
  --batch-size 4 \
  --device cuda

# Ø¢Ù…ÙˆØ²Ø´ Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡
python -m cad3d.cli train \
  --dataset-dir ./training_dataset \
  --output-dir ./models \
  --epochs 100 \
  --batch-size 8 \
  --lr 0.005 \
  --device cuda \
  --workers 8 \
  --optimizer adam \
  --pretrained

# Ø§Ø¯Ø§Ù…Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ø§Ø² checkpoint
python -m cad3d.cli train \
  --dataset-dir ./training_dataset \
  --output-dir ./models \
  --epochs 50 \
  --resume ./models/checkpoint_epoch_30.pth \
  --device cuda
```

**Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:**

- `--dataset-dir`: Ù¾ÙˆØ´Ù‡ Dataset (COCO format)
- `--output-dir`: Ù¾ÙˆØ´Ù‡ Ø®Ø±ÙˆØ¬ÛŒ checkpoints
- `--epochs`: ØªØ¹Ø¯Ø§Ø¯ epochs (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 50)
- `--batch-size`: Ø§Ù†Ø¯Ø§Ø²Ù‡ batch (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 4)
- `--lr`: learning rate (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 0.001)
- `--device`: `cuda` ÛŒØ§ `cpu` (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: cuda)
- `--workers`: ØªØ¹Ø¯Ø§Ø¯ data loader workers (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 4)
- `--optimizer`: `sgd` ÛŒØ§ `adam` (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: sgd)
- `--resume`: Ù…Ø³ÛŒØ± checkpoint Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡ Ø¢Ù…ÙˆØ²Ø´
- `--pretrained`: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² pre-trained weights

### Ø±ÙˆØ´ Ø¯ÙˆÙ…: Python API

```python
from cad3d.training_pipeline import CADDetectionTrainer
import torch

# ØªÙ†Ø¸ÛŒÙ… device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Ø³Ø§Ø®Øª trainer
trainer = CADDetectionTrainer(
    data_dir="./training_dataset",
    output_dir="./models",
    batch_size=4,
    num_workers=4,
    device=device,
    pretrained=True
)

# ØªÙ†Ø¸ÛŒÙ… optimizer
trainer.setup_optimizer(
    optimizer_type="sgd",
    learning_rate=0.001
)

# Ø¢Ù…ÙˆØ²Ø´
trainer.train(num_epochs=50)

print("âœ… Ø¢Ù…ÙˆØ²Ø´ ØªÙ…Ø§Ù… Ø´Ø¯!")
```

### Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´

```
models/
â”œâ”€â”€ best_model.pth              # Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ (Ú©Ù…ØªØ±ÛŒÙ† validation loss)
â”œâ”€â”€ checkpoint_epoch_10.pth     # Checkpoint Ù‡Ø± 10 epoch
â”œâ”€â”€ checkpoint_epoch_20.pth
â”œâ”€â”€ checkpoint_epoch_30.pth
â””â”€â”€ ...
```

---

## Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡

### Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø³ÙØ§Ø±Ø´ÛŒ Ø¯Ø± NeuralCADDetector

```python
from cad3d.neural_cad_detector import NeuralCADDetector
import torch

# Ø³Ø§Ø®Øª detector Ø¨Ø§ Ù…Ø¯Ù„ Ø³ÙØ§Ø±Ø´ÛŒ
detector = NeuralCADDetector(device="cuda")

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ weights Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡
checkpoint = torch.load("./models/best_model.pth")
detector.detection_model.load_state_dict(checkpoint['model_state_dict'])
detector.detection_model.eval()

# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ
image_path = "scanned_floor_plan.jpg"
elements = detector.detect_from_image(image_path, confidence_threshold=0.5)

print(f"âœ… {len(elements)} Ø¹Ù†ØµØ± ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯:")
for elem in elements:
    print(f"   - {elem.element_type}: {elem.confidence:.2%}")
```

### Ù…Ø«Ø§Ù„ Ú©Ø§Ù…Ù„: PDF â†’ DXF Ø¨Ø§ Ù…Ø¯Ù„ Ø³ÙØ§Ø±Ø´ÛŒ

```python
from cad3d.neural_cad_detector import NeuralCADDetector
from cad3d.pdf_processor import PDFToImageConverter, CADPipeline
import torch

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø³ÙØ§Ø±Ø´ÛŒ
detector = NeuralCADDetector(device="cuda")
checkpoint = torch.load("./models/best_model.pth")
detector.detection_model.load_state_dict(checkpoint['model_state_dict'])
detector.detection_model.eval()

# Ø³Ø§Ø®Øª pipeline
pdf_converter = PDFToImageConverter(dpi=300)
pipeline = CADPipeline(
    neural_detector=detector,
    pdf_converter=pdf_converter
)

# ØªØ¨Ø¯ÛŒÙ„ PDF Ø¨Ù‡ DXF
pipeline.process_pdf_to_dxf(
    pdf_path="architectural_plan.pdf",
    output_dxf="output_plan.dxf",
    confidence_threshold=0.6
)

print("âœ… ØªØ¨Ø¯ÛŒÙ„ Ø¨Ø§ Ù…Ø¯Ù„ Ø³ÙØ§Ø±Ø´ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!")
```

---

## Ù†Ú©Ø§Øª Ùˆ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§

### 1ï¸âƒ£ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§

**âœ… Ú©ÛŒÙÛŒØª Ø¯Ø§Ø¯Ù‡:**

- Ø§Ø² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ DXF ØªÙ…ÛŒØ² Ùˆ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
- Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ (Layers) Ø¨Ø§ÛŒØ¯ Ù†Ø§Ù…â€ŒÚ¯Ø°Ø§Ø±ÛŒ ØµØ­ÛŒØ­ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯:
  - `WALLS`, `WALL`, `Ø¯ÛŒÙˆØ§Ø±` â†’ wall
  - `DOORS`, `DOOR`, `Ø¯Ø±Ø¨` â†’ door
  - `WINDOWS`, `WINDOW`, `Ù¾Ù†Ø¬Ø±Ù‡` â†’ window
  - Ùˆ ØºÛŒØ±Ù‡...
- Ø­Ø¯Ø§Ù‚Ù„ 100-200 ÙØ§ÛŒÙ„ DXF Ù…ØªÙ†ÙˆØ¹ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ù†Ø§Ø³Ø¨

**âœ… ØªÙ†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡:**

- Ø³Ø§Ø®ØªÙ…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù (Ù…Ø³Ú©ÙˆÙ†ÛŒØŒ ØªØ¬Ø§Ø±ÛŒØŒ ØµÙ†Ø¹ØªÛŒ)
- Ø³Ø¨Ú©â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù…ØªÙØ§ÙˆØª
- Ù…Ù‚ÛŒØ§Ø³â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
- Ù†Ù‚Ø´Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø¯Ù‡ Ùˆ Ù¾ÛŒÚ†ÛŒØ¯Ù‡

### 2ï¸âƒ£ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¢Ù…ÙˆØ²Ø´

**ğŸ’¡ Batch Size:**

- GPU 6GB: `batch_size=2`
- GPU 8GB: `batch_size=4`
- GPU 12GB+: `batch_size=8`

**ğŸ’¡ Learning Rate:**

- Ø´Ø±ÙˆØ¹ Ø¨Ø§ `lr=0.001` (Ù¾ÛŒØ´â€ŒÙØ±Ø¶)
- Ø§Ú¯Ø± loss Ø®ÛŒÙ„ÛŒ Ø³Ø±ÛŒØ¹ Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØª: `lr=0.005`
- Ø§Ú¯Ø± loss Ø¨ÛŒâ€ŒØ«Ø¨Ø§Øª Ø§Ø³Øª: `lr=0.0001`

**ğŸ’¡ Epochs:**

- Ø­Ø¯Ø§Ù‚Ù„ 50 epochs Ø¨Ø±Ø§ÛŒ Ù†ØªØ§ÛŒØ¬ Ø®ÙˆØ¨
- 100 epochs Ø¨Ø±Ø§ÛŒ Ù†ØªØ§ÛŒØ¬ Ø¹Ø§Ù„ÛŒ
- Ø¨Ø§ validation loss Ø¨Ù‡ØªØ±ÛŒÙ† epoch Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ú©Ù†ÛŒØ¯

**ğŸ’¡ Pretrained Weights:**

- Ù‡Ù…ÛŒØ´Ù‡ Ø§Ø² `--pretrained` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
- Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ COCO pretrained Ø¨Ø³ÛŒØ§Ø± Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯
- Ø²Ù…Ø§Ù† Ø¢Ù…ÙˆØ²Ø´ Ø±Ø§ Ú©Ø§Ù‡Ø´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯

### 3ï¸âƒ£ Ù†Ø¸Ø§Ø±Øª Ø¨Ø± Ø¢Ù…ÙˆØ²Ø´

```python
# Ø¯Ø± Ø­ÛŒÙ† Ø¢Ù…ÙˆØ²Ø´:
# Epoch 1/50: loss=1.234 | val_loss=1.456
# Epoch 2/50: loss=0.987 | val_loss=1.123
# ...

# Ù†Ø´Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¨:
âœ… loss Ú©Ø§Ù‡Ø´ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯
âœ… val_loss Ú©Ø§Ù‡Ø´ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯
âœ… ØªÙØ§ÙˆØª loss Ùˆ val_loss Ú©Ù… Ø§Ø³Øª

# Ù†Ø´Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ú©Ù„:
âŒ loss Ú©Ø§Ù‡Ø´ Ù†Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯ â†’ learning rate Ø¨Ø§Ù„Ø§Ø³Øª
âŒ val_loss Ø§ÙØ²Ø§ÛŒØ´ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯ â†’ overfitting
âŒ ØªÙØ§ÙˆØª Ø²ÛŒØ§Ø¯ loss Ùˆ val_loss â†’ Ø¯Ø§Ø¯Ù‡ Ú©Ù… Ø§Ø³Øª
```

### 4ï¸âƒ£ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„

```python
from cad3d.training_pipeline import CADDetectionTrainer
import torch

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„
trainer = CADDetectionTrainer(
    data_dir="./training_dataset",
    output_dir="./models",
    device=torch.device("cuda")
)

# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
val_loss = trainer.validate()
print(f"Validation Loss: {val_loss:.4f}")

# Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ
# Ù‡Ø± Ú†Ù‡ val_loss Ú©Ù…ØªØ±ØŒ Ù…Ø¯Ù„ Ø¨Ù‡ØªØ±
```

### 5ï¸âƒ£ Fine-tuning Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ø®Ø§Øµ

```bash
# Ù…Ø«Ø§Ù„ 1: Ù†Ù‚Ø´Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø³Ú©ÙˆÙ†ÛŒ
python -m cad3d.cli train \
  --dataset-dir ./residential_plans \
  --output-dir ./models/residential \
  --pretrained \
  --epochs 50

# Ù…Ø«Ø§Ù„ 2: Ù†Ù‚Ø´Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø³ÛŒØ³Ø§Øª
python -m cad3d.cli train \
  --dataset-dir ./mep_plans \
  --output-dir ./models/mep \
  --pretrained \
  --epochs 50

# Ù…Ø«Ø§Ù„ 3: Ø³Ø¨Ú© Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø³Ù†ØªÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ
python -m cad3d.cli train \
  --dataset-dir ./iranian_architecture \
  --output-dir ./models/iranian \
  --pretrained \
  --epochs 100 \
  --lr 0.005
```

### 6ï¸âƒ£ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ ØªØ´Ø®ÛŒØµ (15 Ø¯Ø³ØªÙ‡)

```python
# Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ CAD Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒâ€ŒØ´Ø¯Ù‡:
categories = [
    "wall",         # Ø¯ÛŒÙˆØ§Ø±
    "door",         # Ø¯Ø±Ø¨
    "window",       # Ù¾Ù†Ø¬Ø±Ù‡
    "column",       # Ø³ØªÙˆÙ†
    "beam",         # ØªÛŒØ±
    "slab",         # Ø³Ù‚Ù
    "hvac",         # ØªÙ‡ÙˆÛŒÙ‡ Ù…Ø·Ø¨ÙˆØ¹
    "plumbing",     # Ù„ÙˆÙ„Ù‡â€ŒÚ©Ø´ÛŒ
    "electrical",   # Ø¨Ø±Ù‚
    "furniture",    # Ù…Ø¨Ù„Ù…Ø§Ù†
    "equipment",    # ØªØ¬Ù‡ÛŒØ²Ø§Øª
    "dimension",    # Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ
    "text",         # Ù…ØªÙ†
    "symbol",       # Ø³Ù…Ø¨Ù„
    "grid_line"     # Ø®Ø·ÙˆØ· Ø´Ø¨Ú©Ù‡
]

# Ø¨Ø±Ø§ÛŒ Ø§ÙØ²ÙˆØ¯Ù† Ú©Ù„Ø§Ø³ Ø¬Ø¯ÛŒØ¯:
# 1. Ø¯Ø± training_dataset_builder.py: categories Ùˆ category_to_id Ø±Ø§ ÙˆÛŒØ±Ø§ÛŒØ´ Ú©Ù†ÛŒØ¯
# 2. Ø¯Ø± _classify_entity(): Ù…Ù†Ø·Ù‚ classification Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯
# 3. Dataset Ø¬Ø¯ÛŒØ¯ Ø¨Ø³Ø§Ø²ÛŒØ¯
# 4. Ù…Ø¯Ù„ Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ù‡ÛŒØ¯
```

---

## ğŸ¯ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ

### Ù…Ø«Ø§Ù„ 1: Ø¢Ù…ÙˆØ²Ø´ Ø§Ø² ØµÙØ±

```bash
# 1. Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ 200 ÙØ§ÛŒÙ„ DXF
mkdir my_cad_library
# ... Ú©Ù¾ÛŒ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ DXF

# 2. Ø³Ø§Ø®Øª Dataset
python -m cad3d.cli build-dataset \
  --input-dir ./my_cad_library \
  --output-dir ./dataset \
  --format coco \
  --recurse \
  --visualize

# 3. Ø¨Ø±Ø±Ø³ÛŒ ØªØµØ§ÙˆÛŒØ± annotation Ø¯Ø± dataset/visualizations/

# 4. Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
python -m cad3d.cli train \
  --dataset-dir ./dataset \
  --output-dir ./models \
  --epochs 50 \
  --batch-size 4 \
  --device cuda \
  --pretrained

# 5. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡
python -c "
from cad3d.neural_cad_detector import NeuralCADDetector
import torch

detector = NeuralCADDetector(device='cuda')
checkpoint = torch.load('./models/best_model.pth')
detector.detection_model.load_state_dict(checkpoint['model_state_dict'])

elements = detector.detect_from_image('test_image.jpg')
print(f'âœ… ØªØ´Ø®ÛŒØµ {len(elements)} Ø¹Ù†ØµØ±')
"
```

### Ù…Ø«Ø§Ù„ 2: Ø¨Ù‡Ø¨ÙˆØ¯ Ù…Ø¯Ù„ Ù…ÙˆØ¬ÙˆØ¯

```bash
# Ø§Ø¯Ø§Ù…Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ±
python -m cad3d.cli build-dataset \
  --input-dir ./new_dxf_files \
  --output-dir ./extended_dataset \
  --format coco

# Fine-tune Ù…Ø¯Ù„ Ù‚Ø¨Ù„ÛŒ
python -m cad3d.cli train \
  --dataset-dir ./extended_dataset \
  --output-dir ./models_v2 \
  --resume ./models/best_model.pth \
  --epochs 30 \
  --lr 0.0001 \
  --device cuda
```

### Ù…Ø«Ø§Ù„ 3: Transfer Learning Ø¨Ø±Ø§ÛŒ Ø­ÙˆØ²Ù‡ Ø®Ø§Øµ

```python
"""
Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ù†Ù‚Ø´Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒÙ…Ø§Ø±Ø³ØªØ§Ù†ÛŒ Ø¨Ø§ Transfer Learning
"""
from cad3d.training_dataset_builder import CADDatasetBuilder
from cad3d.training_pipeline import CADDetectionTrainer
import torch

# 1. Ø³Ø§Ø®Øª Dataset Ø§Ø² Ù†Ù‚Ø´Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒÙ…Ø§Ø±Ø³ØªØ§Ù†ÛŒ
builder = CADDatasetBuilder(output_dir="./hospital_dataset")

hospital_plans = [
    "emergency_room.dxf",
    "surgery_room.dxf",
    "patient_room.dxf",
    "icu_ward.dxf",
    # ... 100+ files
]

for plan in hospital_plans:
    builder.add_dxf_to_dataset(plan, image_size=(1024, 1024))

builder.export_coco_format()

# 2. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø¹Ù…ÙˆÙ…ÛŒ
device = torch.device("cuda")
trainer = CADDetectionTrainer(
    data_dir="./hospital_dataset",
    output_dir="./models/hospital_specialist",
    batch_size=4,
    device=device,
    pretrained=True
)

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ weights Ø§Ø² Ù…Ø¯Ù„ Ø¹Ù…ÙˆÙ…ÛŒ
general_checkpoint = torch.load("./models/general/best_model.pth")
trainer.model.load_state_dict(general_checkpoint['model_state_dict'])

# 3. Fine-tuning Ø¨Ø§ learning rate Ú©Ù…
trainer.setup_optimizer(
    optimizer_type="adam",
    learning_rate=0.0001  # Ú©Ù… Ø¨Ø±Ø§ÛŒ Ø­ÙØ¸ Ø¯Ø§Ù†Ø´ Ù‚Ø¨Ù„ÛŒ
)

# 4. Ø¢Ù…ÙˆØ²Ø´
trainer.train(num_epochs=30)

print("âœ… Ù…Ø¯Ù„ ØªØ®ØµØµÛŒ Ø¨ÛŒÙ…Ø§Ø±Ø³ØªØ§Ù†ÛŒ Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª!")
```

---

## ğŸ› Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ

### Ù…Ø´Ú©Ù„: Out of Memory (OOM)

```bash
# Ø±Ø§Ù‡ Ø­Ù„ 1: Ú©Ø§Ù‡Ø´ batch size
--batch-size 2

# Ø±Ø§Ù‡ Ø­Ù„ 2: Ú©Ø§Ù‡Ø´ Ø§Ù†Ø¯Ø§Ø²Ù‡ ØªØµÙˆÛŒØ±
--image-size 512 512

# Ø±Ø§Ù‡ Ø­Ù„ 3: Ú©Ø§Ù‡Ø´ workers
--workers 2
```

### Ù…Ø´Ú©Ù„: Loss Ú©Ø§Ù‡Ø´ Ù†Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯

```bash
# Ø±Ø§Ù‡ Ø­Ù„ 1: Ú©Ø§Ù‡Ø´ learning rate
--lr 0.0001

# Ø±Ø§Ù‡ Ø­Ù„ 2: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² pretrained weights
--pretrained

# Ø±Ø§Ù‡ Ø­Ù„ 3: Ø§ÙØ²Ø§ÛŒØ´ epochs
--epochs 100
```

### Ù…Ø´Ú©Ù„: Overfitting

```python
# Ù†Ø´Ø§Ù†Ù‡: val_loss >> train_loss

# Ø±Ø§Ù‡ Ø­Ù„ 1: Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡
# Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ DXF Ø¨ÛŒØ´ØªØ±

# Ø±Ø§Ù‡ Ø­Ù„ 2: Data Augmentation
from torchvision import transforms

transform = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1)
])

# Ø±Ø§Ù‡ Ø­Ù„ 3: Early Stopping
# ØªÙˆÙ‚Ù Ø¢Ù…ÙˆØ²Ø´ ÙˆÙ‚ØªÛŒ val_loss Ø§ÙØ²Ø§ÛŒØ´ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯
```

---

## ğŸ“š Ù…Ù†Ø§Ø¨Ø¹ Ø¨ÛŒØ´ØªØ±

- [NEURAL_README.md](NEURAL_README.md) - Ù…Ø¹Ù…Ø§Ø±ÛŒ Neural Network
- [.github/copilot-instructions.md](.github/copilot-instructions.md) - Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ ØªÙˆØ³Ø¹Ù‡
- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)
- [COCO Dataset Format](https://cocodataset.org/#format-data)
- [Faster R-CNN Paper](https://arxiv.org/abs/1506.01497)

---

**âœ¨ Ø¢Ù…ÙˆØ²Ø´ Ù…ÙˆÙÙ‚!**
