# ğŸ¤– Ø³ÛŒØ³ØªÙ… Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¢Ù…ÙˆØ²Ø´ ØªØ±Ú©ÛŒØ¨ÛŒ KURDO-AI

## Ø®Ù„Ø§ØµÙ‡

KURDO-AI Ø­Ø§Ù„Ø§ ÛŒÚ© Ø³ÛŒØ³ØªÙ… Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¯Ø§Ø±Ø¯ Ú©Ù‡ **Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´ Ø¢Ù…ÙˆØ²Ø´** Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø´Ù…Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒâ€ŒÚ©Ù†Ø¯!

Ø§ÛŒÙ† Ø³ÛŒØ³ØªÙ… **Ø³Ù‡ Ø±ÙˆØ´ Ù…Ú©Ù…Ù„** Ø±Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯:

1. **Fine-Tuning Ú©Ø§Ù…Ù„** (OpenAI, HuggingFace, Anthropic)
2. **LoRA** (Ú©Ø§Ø±Ø¢Ù…Ø¯ Ùˆ Ø³Ø±ÛŒØ¹)
3. **Prompt Engineering** (Ø¨Ø¯ÙˆÙ† Ø¢Ù…ÙˆØ²Ø´ØŒ ÙÙˆØ±ÛŒ) â­ Ø¬Ø¯ÛŒØ¯!

---

## ğŸ“Š Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´

| Ø±ÙˆØ´ | Ø²Ù…Ø§Ù† | Ù‡Ø²ÛŒÙ†Ù‡ | GPU Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² | Ú©ÛŒÙÛŒØª | Ø­Ø¬Ù… ÙØ§ÛŒÙ„ |
|-----|------|--------|--------------|--------|---------|
| **Prompt Engineering** â­ | ÙÙˆØ±ÛŒ | $0 | Ù‡ÛŒÚ† | â­â­â­ | Ù‡ÛŒÚ† |
| **LoRA (8-bit)** | Û°.Ûµ-Û² Ø³Ø§Ø¹Øª | $0 | RTX 3060 12GB | â­â­â­â­ | ~50MB |
| **LoRA (4-bit)** | Û±-Û³ Ø³Ø§Ø¹Øª | $0 | RTX 2060 6GB | â­â­â­ | ~50MB |
| **Fine-Tuning Ú©Ø§Ù…Ù„** | Û²-Û±Û° Ø³Ø§Ø¹Øª | $10-50 | A100 40GB | â­â­â­â­â­ | ~14GB |
| **OpenAI Fine-Tuning** | Û°.Ûµ-Û± Ø³Ø§Ø¹Øª | $5-20 | Ù‡ÛŒÚ† (Ø§Ø¨Ø±ÛŒ) | â­â­â­â­ | Ø§Ø¨Ø±ÛŒ |

---

## ğŸ¯ Ú©Ø¯Ø§Ù… Ø±ÙˆØ´ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†Ù…ØŸ

### â­ **Prompt Engineering** - Ø´Ø±ÙˆØ¹ Ø³Ø±ÛŒØ¹ Ø¨Ø¯ÙˆÙ† Ø¢Ù…ÙˆØ²Ø´! (Ø¬Ø¯ÛŒØ¯)

- **Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ:** Ù‡Ù…Ù‡! Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ GPU Ù†Ø¯Ø§Ø±Ø¯
- **Ù…Ø²Ø§ÛŒØ§:**
  - ÙÙˆØ±ÛŒ (Ø¨Ø¯ÙˆÙ† Ø¢Ù…ÙˆØ²Ø´!)
  - Ø±Ø§ÛŒÚ¯Ø§Ù† Ú©Ø§Ù…Ù„ (ÙÙ‚Ø· Ù‡Ø²ÛŒÙ†Ù‡ inference)
  - Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ GPU
  - Ø§Ù†Ø¹Ø·Ø§Ù Ø¨Ø³ÛŒØ§Ø± Ø¨Ø§Ù„Ø§
  - Ø¹Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ
  - Ú©Ø§Ø± Ø¨Ø§ Ù‡Ø± Ù…Ø¯Ù„/API
- **Ù…Ø¹Ø§ÛŒØ¨:**
  - Ù…Ø­Ø¯ÙˆØ¯ÛŒØª context window
  - Ú©Ù…ØªØ± Ø«Ø§Ø¨Øª Ø§Ø² fine-tuning
  - Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù…Ù‡Ø§Ø±Øª prompt engineering
- **ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§:**
  - Zero-shot prompting
  - Few-shot learning
  - Chain-of-thought reasoning
  - Prompt templates
  - Cached system prompts

### âœ… **LoRA (8-bit)** - ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´

- **Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ:** GPU Ù‡Ø§ÛŒ Ù…ØªÙˆØ³Ø· (RTX 3060 Ùˆ Ø¨Ù‡ØªØ±)
- **Ù…Ø²Ø§ÛŒØ§:**
  - Û¹Û°-Û¹Û¹Ùª Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ú©Ù…ØªØ±
  - Û³-Û±Û° Ø¨Ø±Ø§Ø¨Ø± Ø³Ø±ÛŒØ¹â€ŒØªØ± Ø§Ø² Fine-Tuning Ú©Ø§Ù…Ù„
  - ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Adapter Ú©ÙˆÚ†Ú© (~50MB)
  - Ú©ÛŒÙÛŒØª ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ Ù…Ø´Ø§Ø¨Ù‡ Fine-Tuning Ú©Ø§Ù…Ù„
- **Ù…Ø¹Ø§ÛŒØ¨:**
  - Ù†ÛŒØ§Ø² Ø¨Ù‡ GPU Ø¯Ø§Ø±Ø¯
  - Ú©Ù…ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡â€ŒØªØ± Ø§Ø² OpenAI

### ğŸ’ª **Fine-Tuning Ú©Ø§Ù…Ù„ (HuggingFace)**

- **Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ:** GPU Ù‡Ø§ÛŒ Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯ (A100, H100)
- **Ù…Ø²Ø§ÛŒØ§:**
  - Ø¨Ù‡ØªØ±ÛŒÙ† Ú©ÛŒÙÛŒØª
  - Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ú©Ø§Ù…Ù„ Ø¨Ø§ Ù…Ø¯Ù„
  - Ú©Ù†ØªØ±Ù„ Ú©Ø§Ù…Ù„ Ø¨Ø± Ø¢Ù…ÙˆØ²Ø´
- **Ù…Ø¹Ø§ÛŒØ¨:**
  - Ù†ÛŒØ§Ø² Ø¨Ù‡ GPU Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯ (40GB+)
  - Ú©Ù†Ø¯ (Ø³Ø§Ø¹Øªâ€ŒÙ‡Ø§)
  - ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ (~14GB)

### âš¡ **LoRA (4-bit)** - Ø¨Ø±Ø§ÛŒ GPU Ù‡Ø§ÛŒ Ø¶Ø¹ÛŒÙ

- **Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ:** GPU Ù‡Ø§ÛŒ Ú©ÙˆÚ†Ú© (RTX 2060 6GB+)
- **Ù…Ø²Ø§ÛŒØ§:**
  - Ø±ÙˆÛŒ 6GB GPU Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯!
  - Ø¨Ø³ÛŒØ§Ø± Ø³Ø±ÛŒØ¹
  - Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ø¨Ø³ÛŒØ§Ø± Ú©Ù…
- **Ù…Ø¹Ø§ÛŒØ¨:**
  - Ú©ÛŒÙÛŒØª Ú©Ù…ÛŒ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ø§Ø² 8-bit
  - Ø§Ø² Ø¯Ù‚Øª Ú©Ø§Ø³ØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯

### â˜ï¸ **OpenAI Fine-Tuning** - Ø¨Ø¯ÙˆÙ† GPU

- **Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ:** Ø¨Ø¯ÙˆÙ† GPU Ù…Ø­Ù„ÛŒ
- **Ù…Ø²Ø§ÛŒØ§:**
  - Ù‡ÛŒÚ† GPU Ù†ÛŒØ§Ø² Ù†ÛŒØ³Øª
  - Ø³Ø±ÙˆÛŒØ³ Ù…Ø¯ÛŒØ±ÛŒØª Ø´Ø¯Ù‡ (Ø¢Ø³Ø§Ù†)
  - Ø³Ø±ÛŒØ¹ (Û³Û°-Û¶Û° Ø¯Ù‚ÛŒÙ‚Ù‡)
- **Ù…Ø¹Ø§ÛŒØ¨:**
  - Ù‡Ø²ÛŒÙ†Ù‡ Ø¯Ø§Ø±Ø¯ ($5-20)
  - Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ OpenAI ÙØ±Ø³ØªØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
  - ÙÙ‚Ø· GPT-3.5/4o-mini

### ğŸ”„ **Prompt Caching (Anthropic)** - Ø¨Ø¯ÙˆÙ† Ø¢Ù…ÙˆØ²Ø´

- **Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ:** Ù†Ù…ÙˆÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø±ÛŒØ¹ØŒ Ø¨ÙˆØ¯Ø¬Ù‡ Ú©Ù…
- **Ù…Ø²Ø§ÛŒØ§:**
  - Ø¨Ø¯ÙˆÙ† Ø¢Ù…ÙˆØ²Ø´
  - ÙÙˆØ±ÛŒ
  - Ø¨Ø³ÛŒØ§Ø± Ø§Ø±Ø²Ø§Ù†
- **Ù…Ø¹Ø§ÛŒØ¨:**
  - Fine-Tuning ÙˆØ§Ù‚Ø¹ÛŒ Ù†ÛŒØ³Øª
  - Ø§Ø«Ø±Ø¨Ø®Ø´ÛŒ Ù…Ø­Ø¯ÙˆØ¯
  - ÙÙ‚Ø· Ø¨Ø§ Claude Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯

---

## ğŸš€ Ù†Ø­ÙˆÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡

### 1ï¸âƒ£ Ø¯Ø±ÛŒØ§ÙØª ØªÙˆØµÛŒÙ‡ Ù‡ÙˆØ´Ù…Ù†Ø¯

```python
from cad3d.super_ai.brain import SuperAIBrain

brain = SuperAIBrain()

# Ø³ÛŒØ³ØªÙ… Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´ Ø±Ø§ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯
recommendation = brain.recommend_training_method(
    model_size_gb=7.0,           # Ù…Ø¯Ù„ 7 Ù…ÛŒÙ„ÛŒØ§Ø±Ø¯ Ù¾Ø§Ø±Ø§Ù…ØªØ±
    dataset_size=100,             # 100 Ù†Ù…ÙˆÙ†Ù‡ Ø¢Ù…ÙˆØ²Ø´ÛŒ
    gpu_memory_gb=12.0,           # RTX 3060 12GB
    provider="local"              # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø­Ù„ÛŒ
)

print(recommendation)
```

**Ø®Ø±ÙˆØ¬ÛŒ:**

```json
{
  "recommended_method": "lora_8bit",
  "confidence": 0.95,
  "reasoning": [
    "LoRA uses 90% fewer parameters",
    "8-bit quantization fits in GPU",
    "3-10x faster than full fine-tuning",
    "Quality nearly as good as full FT"
  ],
  "estimated_time_hours": 1.5,
  "estimated_cost_usd": 0,
  "requirements": ["GPU: 6GB+ VRAM (e.g., RTX 3060)"]
}
```

### 2ï¸âƒ£ Ø¢Ù…ÙˆØ²Ø´ Ø®ÙˆØ¯Ú©Ø§Ø± (Ø³ÛŒØ³ØªÙ… ØªØµÙ…ÛŒÙ… Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯)

```python
# Ø³ÛŒØ³ØªÙ… Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ùˆ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
result = brain.auto_train(
    training_data=my_data,
    adapter_name="kurdo-arch-v1",
    model_name="meta-llama/Llama-2-7b-hf",
    provider="local"
)

print(result)
```

### 3ï¸âƒ£ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡Ù…Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§

```python
# Ù…Ù‚Ø§ÛŒØ³Ù‡ Ú©Ø§Ù…Ù„ Ù‡Ù…Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§
comparison = brain.compare_all_training_methods(
    model_name="meta-llama/Llama-2-7b-hf",
    dataset_size=100
)

# Ù†Ù…Ø§ÛŒØ´ Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§ÛŒØ³Ù‡
for method, details in comparison["methods"].items():
    print(f"\n{method}:")
    print(f"  Time: {details['estimated_time']}")
    print(f"  Cost: {details['estimated_cost']}")
    print(f"  GPU: {details['gpu_required']}")
    print(f"  Pros: {', '.join(details['pros'])}")
```

---

## ğŸ“ˆ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ

### Ø³Ù†Ø§Ø±ÛŒÙˆ Û±: Ø¯Ø§Ù†Ø´Ø¬ÙˆÛŒ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø¨Ø§ RTX 3060 12GB

```python
recommendation = brain.recommend_training_method(
    model_size_gb=7.0,
    dataset_size=50,
    gpu_memory_gb=12.0,
    provider="local"
)
# ØªÙˆØµÛŒÙ‡: LoRA 8-bit âœ…
# Ø²Ù…Ø§Ù†: ~1 Ø³Ø§Ø¹Øª
# Ù‡Ø²ÛŒÙ†Ù‡: Ø±Ø§ÛŒÚ¯Ø§Ù†
```

### Ø³Ù†Ø§Ø±ÛŒÙˆ Û²: Ø§Ø³ØªØ§Ø±ØªØ§Ù¾ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø¨Ø¯ÙˆÙ† GPU

```python
recommendation = brain.recommend_training_method(
    model_size_gb=0,
    dataset_size=100,
    budget_usd=20.0,
    provider="openai"
)
# ØªÙˆØµÛŒÙ‡: OpenAI Fine-Tuning âœ…
# Ø²Ù…Ø§Ù†: ~30 Ø¯Ù‚ÛŒÙ‚Ù‡
# Ù‡Ø²ÛŒÙ†Ù‡: $10-15
```

### Ø³Ù†Ø§Ø±ÛŒÙˆ Û³: Ù…Ø­Ù‚Ù‚ Ø¨Ø§ A100 40GB

```python
recommendation = brain.recommend_training_method(
    model_size_gb=7.0,
    dataset_size=500,
    gpu_memory_gb=40.0,
    provider="local"
)
# ØªÙˆØµÛŒÙ‡: Full Fine-Tuning âœ…
# Ø²Ù…Ø§Ù†: ~4 Ø³Ø§Ø¹Øª
# Ù‡Ø²ÛŒÙ†Ù‡: Ø±Ø§ÛŒÚ¯Ø§Ù† (Ù…Ø­Ù„ÛŒ)
```

### Ø³Ù†Ø§Ø±ÛŒÙˆ Û´: Ø¯Ø§Ù†Ø´Ø¬ÙˆÛŒ Ø¨Ø§ RTX 2060 6GB

```python
recommendation = brain.recommend_training_method(
    model_size_gb=7.0,
    dataset_size=30,
    gpu_memory_gb=6.0,
    provider="local"
)
# ØªÙˆØµÛŒÙ‡: LoRA 4-bit âœ…
# Ø²Ù…Ø§Ù†: ~2 Ø³Ø§Ø¹Øª
# Ù‡Ø²ÛŒÙ†Ù‡: Ø±Ø§ÛŒÚ¯Ø§Ù†
```

---

## ğŸ§ª Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øªâ€ŒÙ‡Ø§

### Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§

```bash
pip install peft bitsandbytes accelerate transformers torch
```

### Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ

```bash
python cad3d/super_ai/test_hybrid_training.py
```

**Ù…Ù†ÙˆÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ:**

```
1. ğŸ¤– Intelligent Training Recommendation (4 scenarios)
2. ğŸ“Š Comprehensive Methods Comparison Table
3. âš–ï¸  LoRA vs Full Fine-Tuning (Technical Details)
4. ğŸ§  KURDO-AI Brain Status
5. ğŸ¯ List Trained LoRA Adapters
6. ğŸ“‹ List Fine-Tuned Models
7. ğŸš€ Run All Tests
8. âŒ Exit
```

### Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øª Ø®Ø§Øµ

```bash
# ÙÙ‚Ø· Ø³ÛŒØ³ØªÙ… ØªÙˆØµÛŒÙ‡
python cad3d/super_ai/test_hybrid_training.py --recommend

# Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§ÛŒØ³Ù‡
python cad3d/super_ai/test_hybrid_training.py --compare

# LoRA Ø¯Ø± Ù…Ù‚Ø§Ø¨Ù„ Fine-Tuning Ú©Ø§Ù…Ù„
python cad3d/super_ai/test_hybrid_training.py --lora-vs-ft

# ÙˆØ¶Ø¹ÛŒØª Brain
python cad3d/super_ai/test_hybrid_training.py --status

# Ù‡Ù…Ù‡ ØªØ³Øªâ€ŒÙ‡Ø§
python cad3d/super_ai/test_hybrid_training.py --all
```

---

## ğŸ’¡ Ù†Ú©Ø§Øª Ù…Ù‡Ù…

### 1. Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± GPU

Ø³ÛŒØ³ØªÙ… Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ø­Ø§ÙØ¸Ù‡ GPU Ø±Ø§ ØªØ´Ø®ÛŒØµ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯:

```python
recommendation = brain.recommend_training_method(
    dataset_size=100,
    # gpu_memory_gb Ø®ÙˆØ¯Ú©Ø§Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯
    provider="local"
)
```

### 2. Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ùˆ Ø¨ÙˆØ¯Ø¬Ù‡

```python
recommendation = brain.recommend_training_method(
    dataset_size=100,
    training_time_hours=1.0,  # Ø­Ø¯Ø§Ú©Ø«Ø± Û± Ø³Ø§Ø¹Øª
    budget_usd=10.0,          # Ø­Ø¯Ø§Ú©Ø«Ø± $10
    provider="local"
)
```

### 3. Ú†Ù†Ø¯ÛŒÙ† Adapter Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù

Ø¨Ø§ LoRA Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ú†Ù†Ø¯ÛŒÙ† Adapter Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¢Ù…ÙˆØ²Ø´ Ø¯Ù‡ÛŒØ¯:

```python
# Adapter Ø¨Ø±Ø§ÛŒ Ù†Ù‚Ø´Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ù…Ø§Ø±ÛŒ
brain.auto_train(
    training_data=arch_data,
    adapter_name="kurdo-arch-plans"
)

# Adapter Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø³Ø§Ø®ØªØ§Ø±ÛŒ
brain.auto_train(
    training_data=struct_data,
    adapter_name="kurdo-structural"
)

# Adapter Ø¨Ø±Ø§ÛŒ ØªØ®Ù…ÛŒÙ† Ù‡Ø²ÛŒÙ†Ù‡
brain.auto_train(
    training_data=cost_data,
    adapter_name="kurdo-cost-estimation"
)

# Ù„ÛŒØ³Øª Ù‡Ù…Ù‡ Adapter Ù‡Ø§
adapters = brain.list_lora_adapters()
print(adapters)
```

---

## ğŸ”§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡

### ØªÙ†Ø¸ÛŒÙ…Ø§Øª LoRA

```python
# LoRA Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¯Ù„Ø®ÙˆØ§Ù‡
result = brain.train_lora_adapter(
    training_data=data,
    adapter_name="custom-adapter",
    base_model="meta-llama/Llama-2-7b-hf",
    r=32,                    # Rank (4-64)
    lora_alpha=64,           # Alpha (Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ 2*r)
    lora_dropout=0.1,        # Dropout (0.0-0.2)
    load_in_8bit=True,       # 8-bit quantization
    num_train_epochs=3,      # ØªØ¹Ø¯Ø§Ø¯ Epoch Ù‡Ø§
    learning_rate=2e-4       # Ù†Ø±Ø® ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ
)
```

### ØªÙ†Ø¸ÛŒÙ…Ø§Øª Fine-Tuning Ú©Ø§Ù…Ù„

```python
# Fine-Tuning Ø¨Ø§ HuggingFace
result = brain.full_fine_tune_workflow(
    provider="huggingface",
    training_data=data,
    base_model="meta-llama/Llama-2-7b-hf",
    num_train_epochs=5,
    learning_rate=2e-5,
    batch_size=4
)
```

---

## ğŸ“Š Ù…Ù‚Ø§ÛŒØ³Ù‡ ØªÚ©Ù†ÛŒÚ©ÛŒ Ø¯Ù‚ÛŒÙ‚

### Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ (Ù…Ø¯Ù„ 7B)

| Ø±ÙˆØ´ | Ø­Ø§ÙØ¸Ù‡ GPU | Ø­Ø§ÙØ¸Ù‡ RAM | Ø­Ø§ÙØ¸Ù‡ Ø¯ÛŒØ³Ú© |
|-----|-----------|-----------|-------------|
| Full FT | ~28GB | ~16GB | ~14GB |
| LoRA 8-bit | ~8GB | ~8GB | ~50MB |
| LoRA 4-bit | ~4GB | ~4GB | ~50MB |

### Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ø¢Ù…ÙˆØ²Ø´ (Ù…Ø¯Ù„ 7B)

| Ø±ÙˆØ´ | Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ | Ø¯Ø±ØµØ¯ |
|-----|-------------------|------|
| Full FT | 7,000,000,000 | 100% |
| LoRA (r=16) | ~16,777,216 | 0.24% |
| LoRA (r=8) | ~8,388,608 | 0.12% |

### Ø³Ø±Ø¹Øª Ø¢Ù…ÙˆØ²Ø´ (100 Ù†Ù…ÙˆÙ†Ù‡ØŒ GPU A100)

| Ø±ÙˆØ´ | Ø²Ù…Ø§Ù† ÙˆØ§Ù‚Ø¹ÛŒ | Ø³Ø±Ø¹Øª Ù†Ø³Ø¨ÛŒ |
|-----|-----------|-----------|
| Full FT | ~600 Ø¯Ù‚ÛŒÙ‚Ù‡ | 1x |
| LoRA 8-bit | ~60 Ø¯Ù‚ÛŒÙ‚Ù‡ | 10x âš¡ |
| LoRA 4-bit | ~90 Ø¯Ù‚ÛŒÙ‚Ù‡ | 7x âš¡ |

---

## ğŸ“ Ù…Ø«Ø§Ù„ Ú©Ø§Ù…Ù„: Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ù…Ø¹Ù…Ø§Ø±ÛŒ

```python
from cad3d.super_ai.brain import SuperAIBrain

# Ø§ÛŒØ¬Ø§Ø¯ Brain
brain = SuperAIBrain()

# Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ù…Ø¹Ù…Ø§Ø±ÛŒ
training_data = [
    {
        "prompt": "Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø³Ø§Ø­Øª ÛŒÚ© Ø§ØªØ§Ù‚ Ø¨Ø§ Ø§Ø¨Ø¹Ø§Ø¯ 5x4 Ù…ØªØ±",
        "completion": "Ù…Ø³Ø§Ø­Øª = Ø·ÙˆÙ„ Ã— Ø¹Ø±Ø¶ = 5 Ã— 4 = 20 Ù…ØªØ± Ù…Ø±Ø¨Ø¹"
    },
    {
        "prompt": "Ú†Ù†Ø¯ Ø¢Ø¬Ø± Ø¨Ø±Ø§ÛŒ Ø¯ÛŒÙˆØ§Ø± 10 Ù…ØªØ±ÛŒ Ù†ÛŒØ§Ø² Ø§Ø³ØªØŸ",
        "completion": "Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù…ØªØ± Ù…Ø±Ø¨Ø¹ Ø¯ÛŒÙˆØ§Ø± ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ 60 Ø¢Ø¬Ø± Ù†ÛŒØ§Ø² Ø§Ø³Øª. Ø¨Ø±Ø§ÛŒ Ø¯ÛŒÙˆØ§Ø± 10 Ù…ØªØ±ÛŒ (Ø¨Ø§ Ø§Ø±ØªÙØ§Ø¹ 3 Ù…ØªØ±): 10 Ã— 3 Ã— 60 = 1800 Ø¢Ø¬Ø±"
    },
    # ... Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ±
]

# Ú¯Ø§Ù… 1: Ø¯Ø±ÛŒØ§ÙØª ØªÙˆØµÛŒÙ‡
print("ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´ Ø¢Ù…ÙˆØ²Ø´...")
recommendation = brain.recommend_training_method(
    dataset_size=len(training_data),
    provider="local"
)

print(f"âœ… Ø±ÙˆØ´ ØªÙˆØµÛŒÙ‡ Ø´Ø¯Ù‡: {recommendation['recommended_method']}")
print(f"â±ï¸  Ø²Ù…Ø§Ù† ØªØ®Ù…ÛŒÙ†ÛŒ: {recommendation['estimated_time_hours']:.1f} Ø³Ø§Ø¹Øª")
print(f"ğŸ’° Ù‡Ø²ÛŒÙ†Ù‡ ØªØ®Ù…ÛŒÙ†ÛŒ: ${recommendation['estimated_cost_usd']:.2f}")
print(f"ğŸ“ Ø¯Ù„Ø§ÛŒÙ„: {', '.join(recommendation['reasoning'])}")

# Ú¯Ø§Ù… 2: Ø¢Ù…ÙˆØ²Ø´ Ø®ÙˆØ¯Ú©Ø§Ø±
print("\nğŸš€ Ø´Ø±ÙˆØ¹ Ø¢Ù…ÙˆØ²Ø´ Ø®ÙˆØ¯Ú©Ø§Ø±...")
result = brain.auto_train(
    training_data=training_data,
    adapter_name="kurdo-arch-v1",
    model_name="meta-llama/Llama-2-7b-hf"
)

if result.get("status") == "success":
    print("âœ… Ø¢Ù…ÙˆØ²Ø´ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!")
    print(f"ğŸ“ Adapter: {result.get('adapter_name')}")
    print(f"ğŸ“Š Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´:")
    if "metrics" in result:
        for key, value in result["metrics"].items():
            print(f"  - {key}: {value}")
else:
    print(f"âŒ Ø®Ø·Ø§: {result.get('message')}")

# Ú¯Ø§Ù… 3: Ù„ÛŒØ³Øª Ù‡Ù…Ù‡ Adapter Ù‡Ø§
print("\nğŸ¯ Adapter Ù‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡:")
adapters = brain.list_lora_adapters()
for adapter in adapters.get("adapters", []):
    print(f"  - {adapter}")

print("\nâœ… ØªÙ…Ø§Ù…!")
```

---

## ğŸ†˜ Ø±ÙØ¹ Ù…Ø´Ú©Ù„Ø§Øª

### Ø®Ø·Ø§: "LoRA module not available"

```bash
pip install peft bitsandbytes accelerate
```

### Ø®Ø·Ø§: "CUDA out of memory"

Ø¯Ùˆ Ø±Ø§Ù‡ Ø­Ù„:

1. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² LoRA 4-bit:

```python
recommendation = brain.recommend_training_method(
    gpu_memory_gb=6.0,  # GPU Ú©ÙˆÚ†Ú©
    provider="local"
)
```

2. ÛŒØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² OpenAI:

```python
recommendation = brain.recommend_training_method(
    budget_usd=20.0,
    provider="openai"
)
```

### Ø®Ø·Ø§: "No GPU available"

Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Fine-Tuning Ø§Ø¨Ø±ÛŒ:

```python
# OpenAI
result = brain.auto_train(
    training_data=data,
    provider="openai"
)

# ÛŒØ§ Anthropic Prompt Caching
result = brain.auto_train(
    training_data=data,
    provider="anthropic"
)
```

---

## ğŸ“š Ù…Ù†Ø§Ø¨Ø¹ Ø¨ÛŒØ´ØªØ±

### Ú©Ø¯Ù‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·

- `cad3d/super_ai/fine_tuning.py` - Fine-Tuning Ú©Ø§Ù…Ù„
- `cad3d/super_ai/lora_training.py` - LoRA
- `cad3d/super_ai/hybrid_training.py` - Ø³ÛŒØ³ØªÙ… Ù‡ÙˆØ´Ù…Ù†Ø¯
- `cad3d/super_ai/brain.py` - Brain Ø§ØµÙ„ÛŒ

### Ù…Ø³ØªÙ†Ø¯Ø§Øª

- LoRA: <https://arxiv.org/abs/2106.09685>
- PEFT: <https://github.com/huggingface/peft>
- Transformers: <https://huggingface.co/docs/transformers>

---

## ğŸ‰ Ø®Ù„Ø§ØµÙ‡

KURDO-AI Ø­Ø§Ù„Ø§ ÛŒÚ© Ø³ÛŒØ³ØªÙ… **Ù‡ÙˆØ´Ù…Ù†Ø¯ Ùˆ Ø®ÙˆØ¯Ú©Ø§Ø±** Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¯Ø§Ø±Ø¯!

**ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ:**

- âœ… **Ø§Ù†ØªØ®Ø§Ø¨ Ø®ÙˆØ¯Ú©Ø§Ø±** Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´ Ø¢Ù…ÙˆØ²Ø´
- âœ… **Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±** Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ GPU
- âœ… **Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¬Ø§Ù…Ø¹** Ù‡Ù…Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§
- âœ… **Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² 5 Ø±ÙˆØ´** Ø¢Ù…ÙˆØ²Ø´ Ù…Ø®ØªÙ„Ù
- âœ… **Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù‡Ø²ÛŒÙ†Ù‡ Ùˆ Ø²Ù…Ø§Ù†**

**Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹:**

```python
from cad3d.super_ai.brain import SuperAIBrain
brain = SuperAIBrain()

# Ø¯Ø±ÛŒØ§ÙØª ØªÙˆØµÛŒÙ‡
rec = brain.recommend_training_method(dataset_size=100)

# Ø¢Ù…ÙˆØ²Ø´ Ø®ÙˆØ¯Ú©Ø§Ø±
result = brain.auto_train(training_data=my_data)
```

**Ù…ÙˆÙÙ‚ Ø¨Ø§Ø´ÛŒØ¯! ğŸš€**
