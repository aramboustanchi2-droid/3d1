# ğŸš€ Vision Transformer for CAD Conversion

ÛŒÚ© Ø³ÛŒØ³ØªÙ… Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ù†Ù‚Ø´Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² **Vision Transformer**

## ğŸ“‹ ÙÙ‡Ø±Ø³Øª

- [ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§](#-ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§)
- [Ù†ØµØ¨](#-Ù†ØµØ¨)
- [Ø´Ø±ÙˆØ¹ Ø³Ø±ÛŒØ¹](#-Ø´Ø±ÙˆØ¹-Ø³Ø±ÛŒØ¹)
- [Ø§Ø³ØªÙØ§Ø¯Ù‡](#-Ø§Ø³ØªÙØ§Ø¯Ù‡)
- [Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„](#-Ø¢Ù…ÙˆØ²Ø´-Ù…Ø¯Ù„)
- [Ù…Ø¹Ù…Ø§Ø±ÛŒ](#-Ù…Ø¹Ù…Ø§Ø±ÛŒ)
- [Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§](#-Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§)
- [Ù…Ø³ØªÙ†Ø¯Ø§Øª](#-Ù…Ø³ØªÙ†Ø¯Ø§Øª)

---

## âœ¨ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§

### ğŸ¯ ØªØ­Ù„ÛŒÙ„ Ø¹Ù…ÛŒÙ‚ Ùˆ Ù‡ÙˆØ´Ù…Ù†Ø¯

- **Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ**: ØªØ´Ø®ÛŒØµ 50+ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø§Ù† Ø³Ø§Ø®ØªÙ…Ø§Ù†ÛŒ (Ø¯ÛŒÙˆØ§Ø±ØŒ Ø¯Ø±ØŒ Ù¾Ù†Ø¬Ø±Ù‡ØŒ Ø³ØªÙˆÙ†ØŒ ØªÛŒØ±ØŒ Ø³Ù‚ÙØŒ Ù¾Ù„Ù‡ØŒ ...)
- **Ø¯Ø±Ú© Ø±ÙˆØ§Ø¨Ø·**: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Self-Attention Ø¨Ø±Ø§ÛŒ ÙÙ‡Ù… Ø±ÙˆØ§Ø¨Ø· Ø¨ÛŒÙ† Ø§Ø¬Ø²Ø§ÛŒ Ù†Ù‚Ø´Ù‡
- **Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø±ØªÙØ§Ø¹**: ØªØ®Ù…ÛŒÙ† Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø±ØªÙØ§Ø¹ Ù‡Ø± Ø§Ù„Ù…Ø§Ù†
- **Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¹Ù…Ù‚**: Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù‚Ø´Ù‡ Ø¹Ù…Ù‚ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ 3D
- **Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…ÙˆØ§Ø¯**: ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ù…ØµØ§Ù„Ø­ (Ø¨ØªÙ†ØŒ ÙÙ„Ø²ØŒ Ú†ÙˆØ¨ØŒ ...)

### ğŸ—ï¸ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ø³Ù‡â€ŒØ¨Ø¹Ø¯ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡

- **ØªØ¨Ø¯ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚ 2Dâ†’3D**: Ø­ÙØ¸ Ù…Ø¹Ù†Ø§ÛŒ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ùˆ Ù…Ù‡Ù†Ø¯Ø³ÛŒ
- **Ù„Ø§ÛŒÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±**: Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ Ø§Ø¬Ø²Ø§Ø¡ Ø¯Ø± Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
- **Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯**: Ø±Ù†Ú¯â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø§Ù†
- **ØªØ´Ø®ÛŒØµ Ù…Ù‚ÛŒØ§Ø³ Ø®ÙˆØ¯Ú©Ø§Ø±**: ÛŒØ§ÙØªÙ† Ù…Ù‚ÛŒØ§Ø³ Ø§Ø² Ø§Ø¨Ø¹Ø§Ø¯ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ ÛŒØ§ scale bar

### ğŸ§  Ù…Ø¹Ù…Ø§Ø±ÛŒ Vision Transformer

- **Patch-based Processing**: ØªÙ‚Ø³ÛŒÙ… ØªØµÙˆÛŒØ± Ø¨Ù‡ Ù¾Ú†â€ŒÙ‡Ø§ÛŒ 16Ã—16
- **Multi-Head Self-Attention**: 12 attention head Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ú© Ø±ÙˆØ§Ø¨Ø·
- **Deep Architecture**: 12 Ù„Ø§ÛŒÙ‡ Transformer
- **Multi-Task Learning**: ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù‡Ù…Ø²Ù…Ø§Ù† 4 task (semantic, height, depth, material)

---

## ğŸ“¦ Ù†ØµØ¨

### Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²Ù‡Ø§

- Python 3.8+
- pip

### Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ

```bash
pip install -r requirements.txt
pip install matplotlib scipy
```

### Ù†ØµØ¨ PyTorch

**Ø¨Ø±Ø§ÛŒ CPU:**

```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
```

**Ø¨Ø±Ø§ÛŒ GPU (CUDA 11.8):**

```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

**Ø¨Ø±Ø§ÛŒ GPU (CUDA 12.1):**

```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
```

### ØªØ³Øª Ù†ØµØ¨

```bash
python quickstart_vit.py
```

Ø§ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª ØªÙ…Ø§Ù… Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ Ø±Ø§ ØªØ³Øª Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ù†ØªÛŒØ¬Ù‡ Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.

---

## ğŸš€ Ø´Ø±ÙˆØ¹ Ø³Ø±ÛŒØ¹

### 1. ØªØ¨Ø¯ÛŒÙ„ Ø³Ø§Ø¯Ù‡ ØªØµÙˆÛŒØ± Ø¨Ù‡ 3D DXF

```python
from cad3d.vit_integration import get_vit_service

# Ø§ÛŒØ¬Ø§Ø¯ Ø³Ø±ÙˆÛŒØ³
service = get_vit_service(device="cpu")  # ÛŒØ§ "cuda" Ø¨Ø±Ø§ÛŒ GPU

# ØªØ¨Ø¯ÛŒÙ„
stats = service.convert_image_to_3d_dxf(
    image_path="floor_plan.jpg",
    output_dxf="floor_plan_3d.dxf",
    auto_scale=True
)

print(f"âœ“ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯: {stats['total_entities']} entity")
```

### 2. ØªØ­Ù„ÛŒÙ„ Ù†Ù‚Ø´Ù‡ Ø¨Ø¯ÙˆÙ† ØªØ¨Ø¯ÛŒÙ„

```python
# ØªØ­Ù„ÛŒÙ„
analysis = service.analyze_image("drawing.png")

print(f"ØªØ¹Ø¯Ø§Ø¯ Ø§Ø¬Ø²Ø§Ø¡: {analysis['num_elements']}")
for elem in analysis['elements'][:5]:
    print(f"  {elem['class']}: {elem['confidence']:.2%}")
```

### 3. Ø§ÛŒØ¬Ø§Ø¯ ØªØµÙˆÛŒØ±Ø³Ø§Ø²ÛŒ

```python
# Ø§ÛŒØ¬Ø§Ø¯ visualization (Ø´Ø§Ù…Ù„ semantic map, height map, depth map, attention)
service.create_visualization(
    image_path="floor_plan.jpg",
    output_path="analysis.png"
)
```

---

## ğŸ“– Ø§Ø³ØªÙØ§Ø¯Ù‡

### Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù¾Ø§ÛŒÙ‡

```python
from cad3d.vision_transformer_cad import CADVisionAnalyzer
import cv2

# Ø§ÛŒØ¬Ø§Ø¯ analyzer
analyzer = CADVisionAnalyzer(device="cpu")

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ±
image = cv2.imread("plan.jpg")
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# ØªØ­Ù„ÛŒÙ„
results = analyzer.analyze_image(image)

# Ù†ØªØ§ÛŒØ¬
print(f"Elements: {len(results['elements'])}")
print(f"Semantic map: {results['semantic_map'].shape}")
print(f"Height map: {results['height_map'].shape}")
print(f"Depth map: {results['depth_map'].shape}")
```

### ØªØ¨Ø¯ÛŒÙ„ 3D Ú©Ø§Ù…Ù„

```python
from cad3d.advanced_3d_reconstructor import Advanced3DReconstructor
import cv2

# Ø§ÛŒØ¬Ø§Ø¯ reconstructor
reconstructor = Advanced3DReconstructor(device="cpu")

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ±
image = cv2.imread("plan.jpg")
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ 3D
stats = reconstructor.reconstruct_from_image(
    image,
    output_dxf="plan_3d.dxf",
    auto_scale=True,
    min_confidence=0.6
)

print(f"Entities: {stats['total_entities']}")
print(f"Layers: {stats['total_layers']}")
print(f"Elements: {stats['elements_by_class']}")
```

### ØªÙ†Ø¸ÛŒÙ… Ù…Ù‚ÛŒØ§Ø³ Ø¯Ø³ØªÛŒ

```python
# Ø§Ú¯Ø± Ù…Ù‚ÛŒØ§Ø³ Ø±Ø§ Ù…ÛŒâ€ŒØ¯Ø§Ù†ÛŒØ¯
reconstructor.set_scale(pixels=100, real_mm=1000)  # 100 pixel = 1000mm

# Ø³Ù¾Ø³ ØªØ¨Ø¯ÛŒÙ„
stats = reconstructor.reconstruct_from_image(
    image,
    output_dxf="plan_3d.dxf",
    auto_scale=False  # Ù…Ù‚ÛŒØ§Ø³ Ø¯Ø³ØªÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´ÙˆØ¯
)
```

---

## ğŸ“ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„

### Ø³Ø§Ø®ØªØ§Ø± Ø¯ÛŒØªØ§Ø³Øª

```
data/
  train/
    images/
      drawing_001.png
      drawing_002.png
    annotations/
      drawing_001.json
      drawing_002.json
  val/
    images/
    annotations/
```

### ÙØ±Ù…Øª Annotation

```json
{
  "semantic_map": [[0, 1, 1, ...], ...],
  "height_map": [[0, 3000, 3000, ...], ...],
  "depth_map": [[0, 0.5, 0.3, ...], ...],
  "material_map": [[0, 1, 1, ...], ...],
  "metadata": {
    "scale": 10.0,
    "drawing_type": "architectural"
  }
}
```

### Ú©Ø¯ Ø¢Ù…ÙˆØ²Ø´

```python
from cad3d.vit_trainer import VisionTransformerTrainer, TrainingConfig, CADDataset
from cad3d.vision_transformer_cad import VisionTransformerConfig

# Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù…Ø¯Ù„
model_config = VisionTransformerConfig(
    image_size=512,
    patch_size=16,
    num_classes=50,
    dim=768,
    depth=12,
    heads=12
)

# Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø¢Ù…ÙˆØ²Ø´
train_config = TrainingConfig(
    train_data_dir="data/train",
    val_data_dir="data/val",
    batch_size=4,
    num_epochs=50,
    learning_rate=1e-4,
    device="cuda"
)

# Ø¯ÛŒØªØ§Ø³Øª
train_dataset = CADDataset("data/train", augment=True)
val_dataset = CADDataset("data/val", augment=False)

# Ø¢Ù…ÙˆØ²Ø´
trainer = VisionTransformerTrainer(model_config, train_config)
trainer.train(train_dataset, val_dataset)
```

### Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡

```python
from cad3d.vit_integration import get_vit_service

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡
service = get_vit_service(
    model_path="checkpoints/best_model.pth",
    device="cuda"
)

# Ø§Ø³ØªÙØ§Ø¯Ù‡
stats = service.convert_image_to_3d_dxf(
    "your_drawing.jpg",
    "output_3d.dxf"
)
```

---

## ğŸ›ï¸ Ù…Ø¹Ù…Ø§Ø±ÛŒ

### Vision Transformer Architecture

```
Input Image (512Ã—512Ã—3)
    â†“
Patch Embedding (32Ã—32 patches Ã— 768 dim)
    â†“
Positional Encoding
    â†“
[CLS] Token + Patch Tokens (1024 tokens)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Transformer Encoder (Ã—12 layers)â”‚
â”‚  â”œâ”€ Multi-Head Self-Attention   â”‚
â”‚  â”œâ”€ Layer Normalization         â”‚
â”‚  â”œâ”€ Feed-Forward Network        â”‚
â”‚  â””â”€ Residual Connections        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Output Embeddings (1024 Ã— 768)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prediction Heads        â”‚
â”‚  â”œâ”€ Semantic (50 class) â”‚
â”‚  â”œâ”€ Height (mm)         â”‚
â”‚  â”œâ”€ Depth (normalized)  â”‚
â”‚  â””â”€ Material (10 types) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Model Sizes

| Configuration | Parameters | Size | Speed (CPU) | Speed (GPU) |
|--------------|-----------|------|-------------|-------------|
| **Small** | ~22M | 88 MB | Slow | Fast |
| **Base** | ~86M | 344 MB | Very Slow | Fast |
| **Large** | ~300M | 1.2 GB | Extremely Slow | Medium |

---

## ğŸ¨ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§

### Ù…Ø«Ø§Ù„ 1: Pipeline Ú©Ø§Ù…Ù„

```python
import cv2
from cad3d.vit_integration import get_vit_service

# 1. Ø³Ø±ÙˆÛŒØ³
service = get_vit_service(device="cpu")

# 2. ØªØ­Ù„ÛŒÙ„
analysis = service.analyze_image("complex_plan.jpg")
print(f"ğŸ“Š Detected {analysis['num_elements']} elements")

# 3. ØªØ¨Ø¯ÛŒÙ„ 3D
stats = service.convert_image_to_3d_dxf(
    "complex_plan.jpg",
    "complex_plan_3d.dxf",
    auto_scale=True
)
print(f"âœ“ Created {stats['total_entities']} 3D entities")

# 4. Visualization
service.create_visualization(
    "complex_plan.jpg",
    "analysis_result.png"
)
print("âœ“ Visualization saved")
```

### Ù…Ø«Ø§Ù„ 2: Batch Processing

```python
from pathlib import Path
from cad3d.vit_integration import get_vit_service

service = get_vit_service()

input_dir = Path("input_drawings")
output_dir = Path("output_3d")
output_dir.mkdir(exist_ok=True)

for image_file in input_dir.glob("*.jpg"):
    print(f"Processing {image_file.name}...")
    
    output_dxf = output_dir / f"{image_file.stem}_3d.dxf"
    
    try:
        stats = service.convert_image_to_3d_dxf(
            str(image_file),
            str(output_dxf)
        )
        print(f"  âœ“ {stats['total_entities']} entities")
    except Exception as e:
        print(f"  âœ— Error: {e}")
```

### Ù…Ø«Ø§Ù„ 3: Custom Element Detection

```python
from cad3d.vision_transformer_cad import CADVisionAnalyzer
import cv2

analyzer = CADVisionAnalyzer()
image = cv2.imread("plan.jpg")
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

results = analyzer.analyze_image(image)

# ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† ÙÙ‚Ø· Ø¯ÛŒÙˆØ§Ø±Ù‡Ø§
walls = [e for e in results['elements'] if e['class'] == 'wall']
print(f"Found {len(walls)} walls")

# ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø§Ø¬Ø²Ø§Ø¡ Ø¨Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø¨Ø§Ù„Ø§
confident = [e for e in results['elements'] if e['confidence'] > 0.8]
print(f"High confidence elements: {len(confident)}")

# Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹
from collections import Counter
class_counts = Counter(e['class'] for e in results['elements'])
for cls, count in class_counts.most_common(10):
    print(f"  {cls}: {count}")
```

---

## ğŸ“š Ù…Ø³ØªÙ†Ø¯Ø§Øª

### ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ

- **`vision_transformer_cad.py`**: Ù…Ø¹Ù…Ø§Ø±ÛŒ Vision Transformer Ùˆ CADVisionAnalyzer
- **`advanced_3d_reconstructor.py`**: Ø³ÛŒØ³ØªÙ… Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ø³Ù‡â€ŒØ¨Ø¹Ø¯ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
- **`vit_trainer.py`**: Ø³ÛŒØ³ØªÙ… Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
- **`vit_integration.py`**: API Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ø³Ø±ÙˆØ±

### Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§ÛŒ Ú©Ù…Ú©ÛŒ

- **`quickstart_vit.py`**: ØªØ³Øª Ø³Ø±ÛŒØ¹ Ù†ØµØ¨ Ùˆ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§
- **`demo_vit.py`**: Ù†Ù…Ø§ÛŒØ´ Ú©Ø§Ù…Ù„ ØªÙ…Ø§Ù… Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§

### Ø±Ø§Ù‡Ù†Ù…Ø§Ù‡Ø§

- **`VISION_TRANSFORMER_GUIDE.md`**: Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¬Ø§Ù…Ø¹ ÙØ§Ø±Ø³ÛŒ
- Ø§ÛŒÙ† ÙØ§ÛŒÙ„ (`README_VIT.md`): Ø®Ù„Ø§ØµÙ‡ Ùˆ Ù…Ø±Ø¬Ø¹ Ø³Ø±ÛŒØ¹

---

## ğŸ”§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª

### Ø§Ù†ØªØ®Ø§Ø¨ Device

```python
# CPU (Ú©Ù†Ø¯ Ø§Ù…Ø§ Ù‡Ù…ÛŒØ´Ù‡ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯)
service = get_vit_service(device="cpu")

# GPU (Ø³Ø±ÛŒØ¹ Ø§Ù…Ø§ Ù†ÛŒØ§Ø² Ø¨Ù‡ CUDA)
service = get_vit_service(device="cuda")

# Auto (Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ù‡ØªØ±ÛŒÙ† Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒâ€ŒÚ©Ù†Ø¯)
service = get_vit_service(device="auto")
```

### ØªÙ†Ø¸ÛŒÙ… Confidence Threshold

```python
# ÙÙ‚Ø· Ø§Ø¬Ø²Ø§Ø¡ Ø¨Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø¨Ø§Ù„Ø§
stats = service.convert_image_to_3d_dxf(
    "plan.jpg",
    "plan_3d.dxf",
    min_confidence=0.7  # 70% confidence
)

# Ù‡Ù…Ù‡ Ø§Ø¬Ø²Ø§Ø¡ (Ø­ØªÛŒ Ø¨Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ù¾Ø§ÛŒÛŒÙ†)
stats = service.convert_image_to_3d_dxf(
    "plan.jpg",
    "plan_3d.dxf",
    min_confidence=0.3  # 30% confidence
)
```

---

## ğŸ› Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ

### PyTorch Ù†ØµØ¨ Ù†ÛŒØ³Øª

```bash
pip install torch torchvision
```

### Out of Memory

```python
# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ú©ÙˆÚ†Ú©â€ŒØªØ±
config = VisionTransformerConfig(
    image_size=256,
    dim=384,
    depth=6
)

# ÛŒØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² CPU
service = get_vit_service(device="cpu")
```

### Ø¯Ù‚Øª Ù¾Ø§ÛŒÛŒÙ†

1. Ø§ÙØ²Ø§ÛŒØ´ confidence threshold
2. Ø¢Ù…ÙˆØ²Ø´ Ø±ÙˆÛŒ Ø¯ÛŒØªØ§Ø³Øª Ø¨ÛŒØ´ØªØ±
3. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø¨Ø²Ø±Ú¯â€ŒØªØ±
4. ØªÙ†Ø¸ÛŒÙ… Ø¯Ø³ØªÛŒ Ù…Ù‚ÛŒØ§Ø³

---

## ğŸ“ˆ Performance

### CPU (Intel i7-12700)

- Small model: ~5 seconds per image
- Base model: ~15 seconds per image
- Large model: ~45 seconds per image

### GPU (RTX 3080)

- Small model: ~0.5 seconds per image
- Base model: ~1 second per image
- Large model: ~3 seconds per image

---

## ğŸ“„ License

MIT License - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¢Ø²Ø§Ø¯ Ø¨Ø±Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ¬Ø§Ø±ÛŒ Ùˆ ØºÛŒØ±ØªØ¬Ø§Ø±ÛŒ

---

## ğŸ™ ØªØ´Ú©Ø±

Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ Ø§Ø² ØªØ­Ù‚ÛŒÙ‚Ø§Øª Ø²ÛŒØ± Ø§Ù„Ù‡Ø§Ù… Ú¯Ø±ÙØªÙ‡:

- [Vision Transformer (ViT)](https://arxiv.org/abs/2010.11929)
- [DETR: End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872)
- [Segment Anything Model (SAM)](https://arxiv.org/abs/2304.02643)

---

**Ù†Ø³Ø®Ù‡**: 1.0.0  
**ØªØ§Ø±ÛŒØ®**: 2025-01-16  
**ØªÙˆØ³Ø¹Ù‡â€ŒØ¯Ù‡Ù†Ø¯Ù‡**: CAD3D Team

---

## ğŸš€ Ø´Ø±ÙˆØ¹ Ú©Ù†ÛŒØ¯

```bash
# Ù†ØµØ¨
pip install torch torchvision matplotlib scipy

# ØªØ³Øª
python quickstart_vit.py

# Ø¯Ù…Ùˆ
python demo_vit.py

# Ø§Ø³ØªÙØ§Ø¯Ù‡
python
>>> from cad3d.vit_integration import get_vit_service
>>> service = get_vit_service()
>>> service.convert_image_to_3d_dxf("plan.jpg", "plan_3d.dxf")
```

**Ù…ÙˆÙÙ‚ Ø¨Ø§Ø´ÛŒØ¯! ğŸ‰**
